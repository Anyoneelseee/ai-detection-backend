{
  "best_global_step": 53790,
  "best_metric": 0.017218004912137985,
  "best_model_checkpoint": "D:\\PycharmProjects\\pythonProject1\\models\\codebert-detector\\fine_tuned\\checkpoint-53790",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 53790,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002788622420524261,
      "grad_norm": 24.261465072631836,
      "learning_rate": 1.9982152816508646e-05,
      "loss": 0.4266,
      "step": 50
    },
    {
      "epoch": 0.005577244841048522,
      "grad_norm": 0.2831195592880249,
      "learning_rate": 1.9963933816694555e-05,
      "loss": 0.1701,
      "step": 100
    },
    {
      "epoch": 0.008365867261572783,
      "grad_norm": 47.51095199584961,
      "learning_rate": 1.99460866332032e-05,
      "loss": 0.1451,
      "step": 150
    },
    {
      "epoch": 0.011154489682097044,
      "grad_norm": 45.674598693847656,
      "learning_rate": 1.9927867633389106e-05,
      "loss": 0.1006,
      "step": 200
    },
    {
      "epoch": 0.013943112102621304,
      "grad_norm": 0.025273993611335754,
      "learning_rate": 1.990927681725228e-05,
      "loss": 0.0902,
      "step": 250
    },
    {
      "epoch": 0.016731734523145567,
      "grad_norm": 0.12582911550998688,
      "learning_rate": 1.9890686001115452e-05,
      "loss": 0.1331,
      "step": 300
    },
    {
      "epoch": 0.019520356943669825,
      "grad_norm": 1.2579994201660156,
      "learning_rate": 1.987209518497862e-05,
      "loss": 0.0924,
      "step": 350
    },
    {
      "epoch": 0.022308979364194088,
      "grad_norm": 72.99189758300781,
      "learning_rate": 1.9853504368841794e-05,
      "loss": 0.1277,
      "step": 400
    },
    {
      "epoch": 0.02509760178471835,
      "grad_norm": 0.007705035153776407,
      "learning_rate": 1.9834913552704967e-05,
      "loss": 0.018,
      "step": 450
    },
    {
      "epoch": 0.02788622420524261,
      "grad_norm": 0.012603305280208588,
      "learning_rate": 1.9816322736568137e-05,
      "loss": 0.0815,
      "step": 500
    },
    {
      "epoch": 0.03067484662576687,
      "grad_norm": 0.03538190573453903,
      "learning_rate": 1.979773192043131e-05,
      "loss": 0.1485,
      "step": 550
    },
    {
      "epoch": 0.03346346904629113,
      "grad_norm": 0.02415875717997551,
      "learning_rate": 1.977914110429448e-05,
      "loss": 0.0921,
      "step": 600
    },
    {
      "epoch": 0.03625209146681539,
      "grad_norm": 0.9671728610992432,
      "learning_rate": 1.9760550288157653e-05,
      "loss": 0.0851,
      "step": 650
    },
    {
      "epoch": 0.03904071388733965,
      "grad_norm": 0.018459687009453773,
      "learning_rate": 1.9741959472020826e-05,
      "loss": 0.0373,
      "step": 700
    },
    {
      "epoch": 0.04182933630786392,
      "grad_norm": 18.192394256591797,
      "learning_rate": 1.9723368655883995e-05,
      "loss": 0.0652,
      "step": 750
    },
    {
      "epoch": 0.044617958728388175,
      "grad_norm": 0.009496936574578285,
      "learning_rate": 1.9704777839747168e-05,
      "loss": 0.0747,
      "step": 800
    },
    {
      "epoch": 0.047406581148912434,
      "grad_norm": 0.004041501320898533,
      "learning_rate": 1.9686187023610338e-05,
      "loss": 0.0655,
      "step": 850
    },
    {
      "epoch": 0.0501952035694367,
      "grad_norm": 0.0031229115556925535,
      "learning_rate": 1.966759620747351e-05,
      "loss": 0.0499,
      "step": 900
    },
    {
      "epoch": 0.05298382598996096,
      "grad_norm": 0.007479401770979166,
      "learning_rate": 1.964900539133668e-05,
      "loss": 0.0962,
      "step": 950
    },
    {
      "epoch": 0.05577244841048522,
      "grad_norm": 0.01809714175760746,
      "learning_rate": 1.9630414575199853e-05,
      "loss": 0.0711,
      "step": 1000
    },
    {
      "epoch": 0.05856107083100948,
      "grad_norm": 2.0948092937469482,
      "learning_rate": 1.9611823759063023e-05,
      "loss": 0.0557,
      "step": 1050
    },
    {
      "epoch": 0.06134969325153374,
      "grad_norm": 0.04255317524075508,
      "learning_rate": 1.9593232942926196e-05,
      "loss": 0.1073,
      "step": 1100
    },
    {
      "epoch": 0.06413831567205801,
      "grad_norm": 36.31170654296875,
      "learning_rate": 1.9574642126789366e-05,
      "loss": 0.0632,
      "step": 1150
    },
    {
      "epoch": 0.06692693809258227,
      "grad_norm": 0.15863128006458282,
      "learning_rate": 1.955605131065254e-05,
      "loss": 0.0832,
      "step": 1200
    },
    {
      "epoch": 0.06971556051310653,
      "grad_norm": 0.009663216769695282,
      "learning_rate": 1.9537460494515708e-05,
      "loss": 0.0592,
      "step": 1250
    },
    {
      "epoch": 0.07250418293363078,
      "grad_norm": 0.033924736082553864,
      "learning_rate": 1.951886967837888e-05,
      "loss": 0.0485,
      "step": 1300
    },
    {
      "epoch": 0.07529280535415504,
      "grad_norm": 0.011440286412835121,
      "learning_rate": 1.9500278862242054e-05,
      "loss": 0.01,
      "step": 1350
    },
    {
      "epoch": 0.0780814277746793,
      "grad_norm": 0.013624492101371288,
      "learning_rate": 1.9481688046105224e-05,
      "loss": 0.0634,
      "step": 1400
    },
    {
      "epoch": 0.08087005019520357,
      "grad_norm": 0.043809156864881516,
      "learning_rate": 1.9463097229968397e-05,
      "loss": 0.0437,
      "step": 1450
    },
    {
      "epoch": 0.08365867261572783,
      "grad_norm": 0.008019896224141121,
      "learning_rate": 1.944450641383157e-05,
      "loss": 0.0302,
      "step": 1500
    },
    {
      "epoch": 0.08644729503625209,
      "grad_norm": 0.006213599815964699,
      "learning_rate": 1.942591559769474e-05,
      "loss": 0.0472,
      "step": 1550
    },
    {
      "epoch": 0.08923591745677635,
      "grad_norm": 0.010023804381489754,
      "learning_rate": 1.9407324781557912e-05,
      "loss": 0.059,
      "step": 1600
    },
    {
      "epoch": 0.09202453987730061,
      "grad_norm": 0.0077830711379647255,
      "learning_rate": 1.9388733965421082e-05,
      "loss": 0.0195,
      "step": 1650
    },
    {
      "epoch": 0.09481316229782487,
      "grad_norm": 0.05247562751173973,
      "learning_rate": 1.9370143149284255e-05,
      "loss": 0.047,
      "step": 1700
    },
    {
      "epoch": 0.09760178471834914,
      "grad_norm": 0.020957911387085915,
      "learning_rate": 1.9351552333147428e-05,
      "loss": 0.0383,
      "step": 1750
    },
    {
      "epoch": 0.1003904071388734,
      "grad_norm": 0.007091931067407131,
      "learning_rate": 1.9332961517010598e-05,
      "loss": 0.0763,
      "step": 1800
    },
    {
      "epoch": 0.10317902955939766,
      "grad_norm": 0.007165979128330946,
      "learning_rate": 1.931437070087377e-05,
      "loss": 0.0614,
      "step": 1850
    },
    {
      "epoch": 0.10596765197992192,
      "grad_norm": 0.1326364129781723,
      "learning_rate": 1.9295779884736944e-05,
      "loss": 0.0241,
      "step": 1900
    },
    {
      "epoch": 0.10875627440044618,
      "grad_norm": 0.007248950190842152,
      "learning_rate": 1.9277189068600113e-05,
      "loss": 0.0449,
      "step": 1950
    },
    {
      "epoch": 0.11154489682097044,
      "grad_norm": 0.004674852825701237,
      "learning_rate": 1.9258598252463286e-05,
      "loss": 0.0449,
      "step": 2000
    },
    {
      "epoch": 0.11433351924149471,
      "grad_norm": 0.11129036545753479,
      "learning_rate": 1.9240007436326456e-05,
      "loss": 0.0349,
      "step": 2050
    },
    {
      "epoch": 0.11712214166201897,
      "grad_norm": 6.950783729553223,
      "learning_rate": 1.922141662018963e-05,
      "loss": 0.0593,
      "step": 2100
    },
    {
      "epoch": 0.11991076408254323,
      "grad_norm": 0.011038810946047306,
      "learning_rate": 1.92028258040528e-05,
      "loss": 0.0295,
      "step": 2150
    },
    {
      "epoch": 0.12269938650306748,
      "grad_norm": 0.004677110817283392,
      "learning_rate": 1.918423498791597e-05,
      "loss": 0.0129,
      "step": 2200
    },
    {
      "epoch": 0.12548800892359174,
      "grad_norm": 0.012659535743296146,
      "learning_rate": 1.9165644171779144e-05,
      "loss": 0.0548,
      "step": 2250
    },
    {
      "epoch": 0.12827663134411602,
      "grad_norm": 2.110793352127075,
      "learning_rate": 1.9147053355642314e-05,
      "loss": 0.0013,
      "step": 2300
    },
    {
      "epoch": 0.13106525376464026,
      "grad_norm": 0.020459376275539398,
      "learning_rate": 1.9128462539505487e-05,
      "loss": 0.0301,
      "step": 2350
    },
    {
      "epoch": 0.13385387618516453,
      "grad_norm": 0.00881191436201334,
      "learning_rate": 1.9109871723368656e-05,
      "loss": 0.0679,
      "step": 2400
    },
    {
      "epoch": 0.13664249860568878,
      "grad_norm": 0.01467534713447094,
      "learning_rate": 1.909128090723183e-05,
      "loss": 0.0337,
      "step": 2450
    },
    {
      "epoch": 0.13943112102621305,
      "grad_norm": 0.0026657653506845236,
      "learning_rate": 1.9072690091095002e-05,
      "loss": 0.0105,
      "step": 2500
    },
    {
      "epoch": 0.14221974344673732,
      "grad_norm": 0.002394704381003976,
      "learning_rate": 1.9054099274958172e-05,
      "loss": 0.0019,
      "step": 2550
    },
    {
      "epoch": 0.14500836586726157,
      "grad_norm": 0.02646235190331936,
      "learning_rate": 1.9035508458821345e-05,
      "loss": 0.0457,
      "step": 2600
    },
    {
      "epoch": 0.14779698828778584,
      "grad_norm": 0.013974585570394993,
      "learning_rate": 1.9016917642684515e-05,
      "loss": 0.0617,
      "step": 2650
    },
    {
      "epoch": 0.15058561070831009,
      "grad_norm": 0.0014810499269515276,
      "learning_rate": 1.8998326826547688e-05,
      "loss": 0.0179,
      "step": 2700
    },
    {
      "epoch": 0.15337423312883436,
      "grad_norm": 0.01044989563524723,
      "learning_rate": 1.8979736010410857e-05,
      "loss": 0.0413,
      "step": 2750
    },
    {
      "epoch": 0.1561628555493586,
      "grad_norm": 0.27930474281311035,
      "learning_rate": 1.896114519427403e-05,
      "loss": 0.0836,
      "step": 2800
    },
    {
      "epoch": 0.15895147796988288,
      "grad_norm": 0.034375663846731186,
      "learning_rate": 1.89425543781372e-05,
      "loss": 0.0297,
      "step": 2850
    },
    {
      "epoch": 0.16174010039040715,
      "grad_norm": 0.0075371358543634415,
      "learning_rate": 1.8923963562000373e-05,
      "loss": 0.1164,
      "step": 2900
    },
    {
      "epoch": 0.1645287228109314,
      "grad_norm": 2.8189213275909424,
      "learning_rate": 1.8905372745863542e-05,
      "loss": 0.0139,
      "step": 2950
    },
    {
      "epoch": 0.16731734523145567,
      "grad_norm": 0.0029742687474936247,
      "learning_rate": 1.8886781929726715e-05,
      "loss": 0.0274,
      "step": 3000
    },
    {
      "epoch": 0.1701059676519799,
      "grad_norm": 0.0028203490655869246,
      "learning_rate": 1.886819111358989e-05,
      "loss": 0.0376,
      "step": 3050
    },
    {
      "epoch": 0.17289459007250418,
      "grad_norm": 0.012139670550823212,
      "learning_rate": 1.8849600297453058e-05,
      "loss": 0.0426,
      "step": 3100
    },
    {
      "epoch": 0.17568321249302846,
      "grad_norm": 0.009087441489100456,
      "learning_rate": 1.883100948131623e-05,
      "loss": 0.0591,
      "step": 3150
    },
    {
      "epoch": 0.1784718349135527,
      "grad_norm": 0.004050749354064465,
      "learning_rate": 1.8812418665179404e-05,
      "loss": 0.0385,
      "step": 3200
    },
    {
      "epoch": 0.18126045733407697,
      "grad_norm": 0.005346041172742844,
      "learning_rate": 1.8793827849042574e-05,
      "loss": 0.0631,
      "step": 3250
    },
    {
      "epoch": 0.18404907975460122,
      "grad_norm": 0.007429087534546852,
      "learning_rate": 1.8775237032905747e-05,
      "loss": 0.0348,
      "step": 3300
    },
    {
      "epoch": 0.1868377021751255,
      "grad_norm": 0.0547337532043457,
      "learning_rate": 1.8756646216768916e-05,
      "loss": 0.0457,
      "step": 3350
    },
    {
      "epoch": 0.18962632459564974,
      "grad_norm": 0.02328675240278244,
      "learning_rate": 1.873805540063209e-05,
      "loss": 0.0255,
      "step": 3400
    },
    {
      "epoch": 0.192414947016174,
      "grad_norm": 20.00051498413086,
      "learning_rate": 1.8719464584495262e-05,
      "loss": 0.015,
      "step": 3450
    },
    {
      "epoch": 0.19520356943669828,
      "grad_norm": 0.0022769335191696882,
      "learning_rate": 1.8700873768358432e-05,
      "loss": 0.0031,
      "step": 3500
    },
    {
      "epoch": 0.19799219185722253,
      "grad_norm": 0.008748335763812065,
      "learning_rate": 1.8682282952221605e-05,
      "loss": 0.0581,
      "step": 3550
    },
    {
      "epoch": 0.2007808142777468,
      "grad_norm": 0.010875220410525799,
      "learning_rate": 1.8663692136084778e-05,
      "loss": 0.0559,
      "step": 3600
    },
    {
      "epoch": 0.20356943669827104,
      "grad_norm": 0.01623426377773285,
      "learning_rate": 1.8645101319947947e-05,
      "loss": 0.0006,
      "step": 3650
    },
    {
      "epoch": 0.20635805911879532,
      "grad_norm": 0.026959819719195366,
      "learning_rate": 1.862651050381112e-05,
      "loss": 0.0633,
      "step": 3700
    },
    {
      "epoch": 0.2091466815393196,
      "grad_norm": 62.84211730957031,
      "learning_rate": 1.860791968767429e-05,
      "loss": 0.0567,
      "step": 3750
    },
    {
      "epoch": 0.21193530395984383,
      "grad_norm": 5.496819496154785,
      "learning_rate": 1.8589328871537463e-05,
      "loss": 0.0878,
      "step": 3800
    },
    {
      "epoch": 0.2147239263803681,
      "grad_norm": 0.028853263705968857,
      "learning_rate": 1.8570738055400636e-05,
      "loss": 0.0559,
      "step": 3850
    },
    {
      "epoch": 0.21751254880089235,
      "grad_norm": 0.007402467541396618,
      "learning_rate": 1.8552147239263806e-05,
      "loss": 0.0189,
      "step": 3900
    },
    {
      "epoch": 0.22030117122141663,
      "grad_norm": 0.011746162548661232,
      "learning_rate": 1.853355642312698e-05,
      "loss": 0.0089,
      "step": 3950
    },
    {
      "epoch": 0.22308979364194087,
      "grad_norm": 0.0047529698349535465,
      "learning_rate": 1.8514965606990148e-05,
      "loss": 0.0678,
      "step": 4000
    },
    {
      "epoch": 0.22587841606246514,
      "grad_norm": 0.01965978555381298,
      "learning_rate": 1.849637479085332e-05,
      "loss": 0.0188,
      "step": 4050
    },
    {
      "epoch": 0.22866703848298942,
      "grad_norm": 0.008287381380796432,
      "learning_rate": 1.847778397471649e-05,
      "loss": 0.0326,
      "step": 4100
    },
    {
      "epoch": 0.23145566090351366,
      "grad_norm": 0.004147302359342575,
      "learning_rate": 1.8459193158579664e-05,
      "loss": 0.0297,
      "step": 4150
    },
    {
      "epoch": 0.23424428332403793,
      "grad_norm": 0.051728505641222,
      "learning_rate": 1.8440602342442833e-05,
      "loss": 0.008,
      "step": 4200
    },
    {
      "epoch": 0.23703290574456218,
      "grad_norm": 0.0014375988394021988,
      "learning_rate": 1.8422383342628742e-05,
      "loss": 0.0051,
      "step": 4250
    },
    {
      "epoch": 0.23982152816508645,
      "grad_norm": 0.001227162778377533,
      "learning_rate": 1.8403792526491915e-05,
      "loss": 0.0409,
      "step": 4300
    },
    {
      "epoch": 0.2426101505856107,
      "grad_norm": 0.031813766807317734,
      "learning_rate": 1.8385201710355085e-05,
      "loss": 0.0701,
      "step": 4350
    },
    {
      "epoch": 0.24539877300613497,
      "grad_norm": 0.06138021498918533,
      "learning_rate": 1.8366610894218258e-05,
      "loss": 0.0235,
      "step": 4400
    },
    {
      "epoch": 0.24818739542665924,
      "grad_norm": 0.0061559476889669895,
      "learning_rate": 1.834802007808143e-05,
      "loss": 0.0349,
      "step": 4450
    },
    {
      "epoch": 0.2509760178471835,
      "grad_norm": 0.004065494053065777,
      "learning_rate": 1.83294292619446e-05,
      "loss": 0.0021,
      "step": 4500
    },
    {
      "epoch": 0.25376464026770773,
      "grad_norm": 0.0073451935313642025,
      "learning_rate": 1.8310838445807773e-05,
      "loss": 0.0822,
      "step": 4550
    },
    {
      "epoch": 0.25655326268823203,
      "grad_norm": 0.005774666089564562,
      "learning_rate": 1.8292247629670946e-05,
      "loss": 0.0458,
      "step": 4600
    },
    {
      "epoch": 0.2593418851087563,
      "grad_norm": 0.002714243484660983,
      "learning_rate": 1.8273656813534116e-05,
      "loss": 0.0009,
      "step": 4650
    },
    {
      "epoch": 0.2621305075292805,
      "grad_norm": 0.002389800501987338,
      "learning_rate": 1.825506599739729e-05,
      "loss": 0.0393,
      "step": 4700
    },
    {
      "epoch": 0.2649191299498048,
      "grad_norm": 0.003074109321460128,
      "learning_rate": 1.823647518126046e-05,
      "loss": 0.0536,
      "step": 4750
    },
    {
      "epoch": 0.26770775237032907,
      "grad_norm": 0.012920832261443138,
      "learning_rate": 1.821788436512363e-05,
      "loss": 0.0216,
      "step": 4800
    },
    {
      "epoch": 0.2704963747908533,
      "grad_norm": 0.001942338771186769,
      "learning_rate": 1.81992935489868e-05,
      "loss": 0.0164,
      "step": 4850
    },
    {
      "epoch": 0.27328499721137756,
      "grad_norm": 0.002996183466166258,
      "learning_rate": 1.8180702732849974e-05,
      "loss": 0.0139,
      "step": 4900
    },
    {
      "epoch": 0.27607361963190186,
      "grad_norm": 0.0031256063375622034,
      "learning_rate": 1.8162111916713144e-05,
      "loss": 0.0155,
      "step": 4950
    },
    {
      "epoch": 0.2788622420524261,
      "grad_norm": 0.006774867884814739,
      "learning_rate": 1.8143521100576317e-05,
      "loss": 0.0295,
      "step": 5000
    },
    {
      "epoch": 0.28165086447295035,
      "grad_norm": 0.0034688415471464396,
      "learning_rate": 1.8124930284439486e-05,
      "loss": 0.0281,
      "step": 5050
    },
    {
      "epoch": 0.28443948689347465,
      "grad_norm": 0.00389401288703084,
      "learning_rate": 1.810633946830266e-05,
      "loss": 0.0471,
      "step": 5100
    },
    {
      "epoch": 0.2872281093139989,
      "grad_norm": 0.004120934754610062,
      "learning_rate": 1.808774865216583e-05,
      "loss": 0.031,
      "step": 5150
    },
    {
      "epoch": 0.29001673173452314,
      "grad_norm": 0.007100636605173349,
      "learning_rate": 1.8069157836029002e-05,
      "loss": 0.0296,
      "step": 5200
    },
    {
      "epoch": 0.2928053541550474,
      "grad_norm": 0.12453101575374603,
      "learning_rate": 1.8050567019892175e-05,
      "loss": 0.0295,
      "step": 5250
    },
    {
      "epoch": 0.2955939765755717,
      "grad_norm": 0.0020842882804572582,
      "learning_rate": 1.8031976203755345e-05,
      "loss": 0.0048,
      "step": 5300
    },
    {
      "epoch": 0.2983825989960959,
      "grad_norm": 0.001352805644273758,
      "learning_rate": 1.8013385387618518e-05,
      "loss": 0.0001,
      "step": 5350
    },
    {
      "epoch": 0.30117122141662017,
      "grad_norm": 0.013343505561351776,
      "learning_rate": 1.7994794571481687e-05,
      "loss": 0.0807,
      "step": 5400
    },
    {
      "epoch": 0.30395984383714447,
      "grad_norm": 0.015243059024214745,
      "learning_rate": 1.797620375534486e-05,
      "loss": 0.0324,
      "step": 5450
    },
    {
      "epoch": 0.3067484662576687,
      "grad_norm": 0.003469986841082573,
      "learning_rate": 1.7957612939208033e-05,
      "loss": 0.0386,
      "step": 5500
    },
    {
      "epoch": 0.30953708867819296,
      "grad_norm": 0.006198008544743061,
      "learning_rate": 1.7939022123071203e-05,
      "loss": 0.0389,
      "step": 5550
    },
    {
      "epoch": 0.3123257110987172,
      "grad_norm": 0.002720557153224945,
      "learning_rate": 1.7920431306934376e-05,
      "loss": 0.0212,
      "step": 5600
    },
    {
      "epoch": 0.3151143335192415,
      "grad_norm": 0.0027546174824237823,
      "learning_rate": 1.790184049079755e-05,
      "loss": 0.0393,
      "step": 5650
    },
    {
      "epoch": 0.31790295593976575,
      "grad_norm": 0.2237127721309662,
      "learning_rate": 1.788324967466072e-05,
      "loss": 0.0379,
      "step": 5700
    },
    {
      "epoch": 0.32069157836029,
      "grad_norm": 0.012083852663636208,
      "learning_rate": 1.786465885852389e-05,
      "loss": 0.045,
      "step": 5750
    },
    {
      "epoch": 0.3234802007808143,
      "grad_norm": 11.782295227050781,
      "learning_rate": 1.784606804238706e-05,
      "loss": 0.0754,
      "step": 5800
    },
    {
      "epoch": 0.32626882320133854,
      "grad_norm": 0.2503175735473633,
      "learning_rate": 1.7827477226250234e-05,
      "loss": 0.004,
      "step": 5850
    },
    {
      "epoch": 0.3290574456218628,
      "grad_norm": 0.007074061781167984,
      "learning_rate": 1.7808886410113407e-05,
      "loss": 0.0524,
      "step": 5900
    },
    {
      "epoch": 0.3318460680423871,
      "grad_norm": 0.006457970943301916,
      "learning_rate": 1.7790295593976577e-05,
      "loss": 0.0253,
      "step": 5950
    },
    {
      "epoch": 0.33463469046291133,
      "grad_norm": 0.029226507991552353,
      "learning_rate": 1.777170477783975e-05,
      "loss": 0.0362,
      "step": 6000
    },
    {
      "epoch": 0.3374233128834356,
      "grad_norm": 0.003934411332011223,
      "learning_rate": 1.775311396170292e-05,
      "loss": 0.0481,
      "step": 6050
    },
    {
      "epoch": 0.3402119353039598,
      "grad_norm": 0.03650150075554848,
      "learning_rate": 1.7734523145566092e-05,
      "loss": 0.06,
      "step": 6100
    },
    {
      "epoch": 0.3430005577244841,
      "grad_norm": 0.005054328590631485,
      "learning_rate": 1.7715932329429265e-05,
      "loss": 0.0484,
      "step": 6150
    },
    {
      "epoch": 0.34578918014500837,
      "grad_norm": 0.0025279244873672724,
      "learning_rate": 1.7697341513292435e-05,
      "loss": 0.0025,
      "step": 6200
    },
    {
      "epoch": 0.3485778025655326,
      "grad_norm": 0.011811123229563236,
      "learning_rate": 1.7678750697155608e-05,
      "loss": 0.019,
      "step": 6250
    },
    {
      "epoch": 0.3513664249860569,
      "grad_norm": 3.1476407051086426,
      "learning_rate": 1.7660159881018777e-05,
      "loss": 0.0576,
      "step": 6300
    },
    {
      "epoch": 0.35415504740658116,
      "grad_norm": 0.01108650490641594,
      "learning_rate": 1.764156906488195e-05,
      "loss": 0.0005,
      "step": 6350
    },
    {
      "epoch": 0.3569436698271054,
      "grad_norm": 0.028866440057754517,
      "learning_rate": 1.7622978248745123e-05,
      "loss": 0.0322,
      "step": 6400
    },
    {
      "epoch": 0.35973229224762965,
      "grad_norm": 0.01949319988489151,
      "learning_rate": 1.7604387432608293e-05,
      "loss": 0.0169,
      "step": 6450
    },
    {
      "epoch": 0.36252091466815395,
      "grad_norm": 0.0032069056760519743,
      "learning_rate": 1.7585796616471466e-05,
      "loss": 0.0099,
      "step": 6500
    },
    {
      "epoch": 0.3653095370886782,
      "grad_norm": 0.49041369557380676,
      "learning_rate": 1.7567205800334636e-05,
      "loss": 0.0607,
      "step": 6550
    },
    {
      "epoch": 0.36809815950920244,
      "grad_norm": 0.002062180545181036,
      "learning_rate": 1.754861498419781e-05,
      "loss": 0.0179,
      "step": 6600
    },
    {
      "epoch": 0.37088678192972674,
      "grad_norm": 0.0023838572669774294,
      "learning_rate": 1.7530024168060978e-05,
      "loss": 0.0325,
      "step": 6650
    },
    {
      "epoch": 0.373675404350251,
      "grad_norm": 0.011586218141019344,
      "learning_rate": 1.751143335192415e-05,
      "loss": 0.0273,
      "step": 6700
    },
    {
      "epoch": 0.37646402677077523,
      "grad_norm": 0.005272038280963898,
      "learning_rate": 1.749284253578732e-05,
      "loss": 0.0003,
      "step": 6750
    },
    {
      "epoch": 0.3792526491912995,
      "grad_norm": 0.009859674610197544,
      "learning_rate": 1.7474251719650494e-05,
      "loss": 0.023,
      "step": 6800
    },
    {
      "epoch": 0.3820412716118238,
      "grad_norm": 0.00305093452334404,
      "learning_rate": 1.7455660903513663e-05,
      "loss": 0.0004,
      "step": 6850
    },
    {
      "epoch": 0.384829894032348,
      "grad_norm": 0.0010393542470410466,
      "learning_rate": 1.7437070087376836e-05,
      "loss": 0.0002,
      "step": 6900
    },
    {
      "epoch": 0.38761851645287226,
      "grad_norm": 0.0008831505547277629,
      "learning_rate": 1.741847927124001e-05,
      "loss": 0.0358,
      "step": 6950
    },
    {
      "epoch": 0.39040713887339656,
      "grad_norm": 0.003588725347071886,
      "learning_rate": 1.739988845510318e-05,
      "loss": 0.0468,
      "step": 7000
    },
    {
      "epoch": 0.3931957612939208,
      "grad_norm": 69.0753173828125,
      "learning_rate": 1.7381297638966352e-05,
      "loss": 0.036,
      "step": 7050
    },
    {
      "epoch": 0.39598438371444505,
      "grad_norm": 0.004871209152042866,
      "learning_rate": 1.736270682282952e-05,
      "loss": 0.0179,
      "step": 7100
    },
    {
      "epoch": 0.3987730061349693,
      "grad_norm": 0.3551177382469177,
      "learning_rate": 1.7344116006692695e-05,
      "loss": 0.0197,
      "step": 7150
    },
    {
      "epoch": 0.4015616285554936,
      "grad_norm": 0.040864426642656326,
      "learning_rate": 1.7325525190555868e-05,
      "loss": 0.0473,
      "step": 7200
    },
    {
      "epoch": 0.40435025097601784,
      "grad_norm": 0.003228146815672517,
      "learning_rate": 1.7306934374419037e-05,
      "loss": 0.0176,
      "step": 7250
    },
    {
      "epoch": 0.4071388733965421,
      "grad_norm": 0.1291859894990921,
      "learning_rate": 1.728834355828221e-05,
      "loss": 0.0529,
      "step": 7300
    },
    {
      "epoch": 0.4099274958170664,
      "grad_norm": 0.04487339407205582,
      "learning_rate": 1.7269752742145383e-05,
      "loss": 0.0343,
      "step": 7350
    },
    {
      "epoch": 0.41271611823759063,
      "grad_norm": 0.0036925459280610085,
      "learning_rate": 1.7251161926008553e-05,
      "loss": 0.0259,
      "step": 7400
    },
    {
      "epoch": 0.4155047406581149,
      "grad_norm": 0.0033646496012806892,
      "learning_rate": 1.7232571109871726e-05,
      "loss": 0.0004,
      "step": 7450
    },
    {
      "epoch": 0.4182933630786392,
      "grad_norm": 0.017607079818844795,
      "learning_rate": 1.7213980293734895e-05,
      "loss": 0.0462,
      "step": 7500
    },
    {
      "epoch": 0.4210819854991634,
      "grad_norm": 0.006404928397387266,
      "learning_rate": 1.719538947759807e-05,
      "loss": 0.013,
      "step": 7550
    },
    {
      "epoch": 0.42387060791968767,
      "grad_norm": 2.5706803798675537,
      "learning_rate": 1.717679866146124e-05,
      "loss": 0.0257,
      "step": 7600
    },
    {
      "epoch": 0.4266592303402119,
      "grad_norm": 0.008079598657786846,
      "learning_rate": 1.715820784532441e-05,
      "loss": 0.0179,
      "step": 7650
    },
    {
      "epoch": 0.4294478527607362,
      "grad_norm": 0.0017520079854875803,
      "learning_rate": 1.7139617029187584e-05,
      "loss": 0.0041,
      "step": 7700
    },
    {
      "epoch": 0.43223647518126046,
      "grad_norm": 0.10436669737100601,
      "learning_rate": 1.7121026213050757e-05,
      "loss": 0.0608,
      "step": 7750
    },
    {
      "epoch": 0.4350250976017847,
      "grad_norm": 0.0043154386803507805,
      "learning_rate": 1.7102435396913927e-05,
      "loss": 0.0328,
      "step": 7800
    },
    {
      "epoch": 0.437813720022309,
      "grad_norm": 0.006746784318238497,
      "learning_rate": 1.70838445807771e-05,
      "loss": 0.0285,
      "step": 7850
    },
    {
      "epoch": 0.44060234244283325,
      "grad_norm": 0.0027432837523519993,
      "learning_rate": 1.706525376464027e-05,
      "loss": 0.0004,
      "step": 7900
    },
    {
      "epoch": 0.4433909648633575,
      "grad_norm": 0.0017296097939833999,
      "learning_rate": 1.7046662948503442e-05,
      "loss": 0.0098,
      "step": 7950
    },
    {
      "epoch": 0.44617958728388174,
      "grad_norm": 15.639379501342773,
      "learning_rate": 1.7028443948689348e-05,
      "loss": 0.0444,
      "step": 8000
    },
    {
      "epoch": 0.44896820970440604,
      "grad_norm": 0.005932552274316549,
      "learning_rate": 1.700985313255252e-05,
      "loss": 0.0164,
      "step": 8050
    },
    {
      "epoch": 0.4517568321249303,
      "grad_norm": 0.0020653163082897663,
      "learning_rate": 1.6991262316415694e-05,
      "loss": 0.0288,
      "step": 8100
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.27899178862571716,
      "learning_rate": 1.6972671500278863e-05,
      "loss": 0.0456,
      "step": 8150
    },
    {
      "epoch": 0.45733407696597883,
      "grad_norm": 0.3213760256767273,
      "learning_rate": 1.6954080684142036e-05,
      "loss": 0.0119,
      "step": 8200
    },
    {
      "epoch": 0.4601226993865031,
      "grad_norm": 0.0016041817143559456,
      "learning_rate": 1.6935489868005206e-05,
      "loss": 0.0381,
      "step": 8250
    },
    {
      "epoch": 0.4629113218070273,
      "grad_norm": 0.003039321629330516,
      "learning_rate": 1.691689905186838e-05,
      "loss": 0.0274,
      "step": 8300
    },
    {
      "epoch": 0.46569994422755157,
      "grad_norm": 0.01141118723899126,
      "learning_rate": 1.6898308235731552e-05,
      "loss": 0.0423,
      "step": 8350
    },
    {
      "epoch": 0.46848856664807587,
      "grad_norm": 0.009630070067942142,
      "learning_rate": 1.687971741959472e-05,
      "loss": 0.0311,
      "step": 8400
    },
    {
      "epoch": 0.4712771890686001,
      "grad_norm": 24.965587615966797,
      "learning_rate": 1.6861126603457894e-05,
      "loss": 0.0435,
      "step": 8450
    },
    {
      "epoch": 0.47406581148912436,
      "grad_norm": 0.011237206868827343,
      "learning_rate": 1.6842535787321064e-05,
      "loss": 0.0534,
      "step": 8500
    },
    {
      "epoch": 0.47685443390964866,
      "grad_norm": 0.011872779577970505,
      "learning_rate": 1.6823944971184237e-05,
      "loss": 0.0235,
      "step": 8550
    },
    {
      "epoch": 0.4796430563301729,
      "grad_norm": 0.0022638675291091204,
      "learning_rate": 1.680535415504741e-05,
      "loss": 0.0167,
      "step": 8600
    },
    {
      "epoch": 0.48243167875069715,
      "grad_norm": 0.16044841706752777,
      "learning_rate": 1.678676333891058e-05,
      "loss": 0.0746,
      "step": 8650
    },
    {
      "epoch": 0.4852203011712214,
      "grad_norm": 0.040898118168115616,
      "learning_rate": 1.6768172522773753e-05,
      "loss": 0.0167,
      "step": 8700
    },
    {
      "epoch": 0.4880089235917457,
      "grad_norm": 0.002340699313208461,
      "learning_rate": 1.6749581706636922e-05,
      "loss": 0.0004,
      "step": 8750
    },
    {
      "epoch": 0.49079754601226994,
      "grad_norm": 0.007368119433522224,
      "learning_rate": 1.6730990890500095e-05,
      "loss": 0.0479,
      "step": 8800
    },
    {
      "epoch": 0.4935861684327942,
      "grad_norm": 0.005010502878576517,
      "learning_rate": 1.6712400074363265e-05,
      "loss": 0.0353,
      "step": 8850
    },
    {
      "epoch": 0.4963747908533185,
      "grad_norm": 0.0029033594764769077,
      "learning_rate": 1.6693809258226438e-05,
      "loss": 0.0004,
      "step": 8900
    },
    {
      "epoch": 0.4991634132738427,
      "grad_norm": 0.0024302457459270954,
      "learning_rate": 1.6675218442089607e-05,
      "loss": 0.0145,
      "step": 8950
    },
    {
      "epoch": 0.501952035694367,
      "grad_norm": 8.107166290283203,
      "learning_rate": 1.665662762595278e-05,
      "loss": 0.0171,
      "step": 9000
    },
    {
      "epoch": 0.5047406581148912,
      "grad_norm": 3.963550090789795,
      "learning_rate": 1.6638036809815953e-05,
      "loss": 0.0504,
      "step": 9050
    },
    {
      "epoch": 0.5075292805354155,
      "grad_norm": 0.0047508906573057175,
      "learning_rate": 1.6619445993679123e-05,
      "loss": 0.0187,
      "step": 9100
    },
    {
      "epoch": 0.5103179029559398,
      "grad_norm": 0.0036607279907912016,
      "learning_rate": 1.6600855177542296e-05,
      "loss": 0.0004,
      "step": 9150
    },
    {
      "epoch": 0.5131065253764641,
      "grad_norm": 0.003964010626077652,
      "learning_rate": 1.6582264361405466e-05,
      "loss": 0.0378,
      "step": 9200
    },
    {
      "epoch": 0.5158951477969883,
      "grad_norm": 0.0075516304932534695,
      "learning_rate": 1.656367354526864e-05,
      "loss": 0.0173,
      "step": 9250
    },
    {
      "epoch": 0.5186837702175126,
      "grad_norm": 0.001940940273925662,
      "learning_rate": 1.6545082729131808e-05,
      "loss": 0.0084,
      "step": 9300
    },
    {
      "epoch": 0.5214723926380368,
      "grad_norm": 0.2097250372171402,
      "learning_rate": 1.652649191299498e-05,
      "loss": 0.0308,
      "step": 9350
    },
    {
      "epoch": 0.524261015058561,
      "grad_norm": 0.0026183160953223705,
      "learning_rate": 1.6507901096858154e-05,
      "loss": 0.0323,
      "step": 9400
    },
    {
      "epoch": 0.5270496374790853,
      "grad_norm": 0.023913530632853508,
      "learning_rate": 1.6489310280721324e-05,
      "loss": 0.0059,
      "step": 9450
    },
    {
      "epoch": 0.5298382598996096,
      "grad_norm": 0.0021905216854065657,
      "learning_rate": 1.6470719464584497e-05,
      "loss": 0.0361,
      "step": 9500
    },
    {
      "epoch": 0.5326268823201339,
      "grad_norm": 0.0011429530568420887,
      "learning_rate": 1.6452128648447666e-05,
      "loss": 0.0291,
      "step": 9550
    },
    {
      "epoch": 0.5354155047406581,
      "grad_norm": 0.001280269818380475,
      "learning_rate": 1.643353783231084e-05,
      "loss": 0.0091,
      "step": 9600
    },
    {
      "epoch": 0.5382041271611824,
      "grad_norm": 0.03393604978919029,
      "learning_rate": 1.6414947016174012e-05,
      "loss": 0.0734,
      "step": 9650
    },
    {
      "epoch": 0.5409927495817066,
      "grad_norm": 0.029982658103108406,
      "learning_rate": 1.6396356200037182e-05,
      "loss": 0.0185,
      "step": 9700
    },
    {
      "epoch": 0.5437813720022309,
      "grad_norm": 0.0012814258225262165,
      "learning_rate": 1.6377765383900355e-05,
      "loss": 0.0002,
      "step": 9750
    },
    {
      "epoch": 0.5465699944227551,
      "grad_norm": 0.005921653471887112,
      "learning_rate": 1.6359174567763528e-05,
      "loss": 0.0002,
      "step": 9800
    },
    {
      "epoch": 0.5493586168432795,
      "grad_norm": 0.0027639660984277725,
      "learning_rate": 1.6340583751626698e-05,
      "loss": 0.0276,
      "step": 9850
    },
    {
      "epoch": 0.5521472392638037,
      "grad_norm": 0.007095434237271547,
      "learning_rate": 1.632199293548987e-05,
      "loss": 0.0292,
      "step": 9900
    },
    {
      "epoch": 0.554935861684328,
      "grad_norm": 0.000872335338499397,
      "learning_rate": 1.630340211935304e-05,
      "loss": 0.0003,
      "step": 9950
    },
    {
      "epoch": 0.5577244841048522,
      "grad_norm": 0.0008014303748495877,
      "learning_rate": 1.628518311953895e-05,
      "loss": 0.0115,
      "step": 10000
    },
    {
      "epoch": 0.5605131065253764,
      "grad_norm": 0.012694497592747211,
      "learning_rate": 1.626659230340212e-05,
      "loss": 0.0195,
      "step": 10050
    },
    {
      "epoch": 0.5633017289459007,
      "grad_norm": 0.009804165922105312,
      "learning_rate": 1.624800148726529e-05,
      "loss": 0.0649,
      "step": 10100
    },
    {
      "epoch": 0.5660903513664249,
      "grad_norm": 0.15994086861610413,
      "learning_rate": 1.6229410671128465e-05,
      "loss": 0.0029,
      "step": 10150
    },
    {
      "epoch": 0.5688789737869493,
      "grad_norm": 0.0014985355082899332,
      "learning_rate": 1.6210819854991634e-05,
      "loss": 0.0335,
      "step": 10200
    },
    {
      "epoch": 0.5716675962074735,
      "grad_norm": 0.001191274612210691,
      "learning_rate": 1.6192229038854807e-05,
      "loss": 0.0119,
      "step": 10250
    },
    {
      "epoch": 0.5744562186279978,
      "grad_norm": 0.0010605104034766555,
      "learning_rate": 1.6173638222717977e-05,
      "loss": 0.0002,
      "step": 10300
    },
    {
      "epoch": 0.577244841048522,
      "grad_norm": 0.002189124468713999,
      "learning_rate": 1.615504740658115e-05,
      "loss": 0.0211,
      "step": 10350
    },
    {
      "epoch": 0.5800334634690463,
      "grad_norm": 0.005381966475397348,
      "learning_rate": 1.6136456590444323e-05,
      "loss": 0.0532,
      "step": 10400
    },
    {
      "epoch": 0.5828220858895705,
      "grad_norm": 0.012439326383173466,
      "learning_rate": 1.6117865774307492e-05,
      "loss": 0.0424,
      "step": 10450
    },
    {
      "epoch": 0.5856107083100948,
      "grad_norm": 0.031426552683115005,
      "learning_rate": 1.6099274958170665e-05,
      "loss": 0.0126,
      "step": 10500
    },
    {
      "epoch": 0.5883993307306191,
      "grad_norm": 0.00569077068939805,
      "learning_rate": 1.6080684142033835e-05,
      "loss": 0.0477,
      "step": 10550
    },
    {
      "epoch": 0.5911879531511434,
      "grad_norm": 0.006995197851210833,
      "learning_rate": 1.6062465142219744e-05,
      "loss": 0.0712,
      "step": 10600
    },
    {
      "epoch": 0.5939765755716676,
      "grad_norm": 0.01134259533137083,
      "learning_rate": 1.6043874326082917e-05,
      "loss": 0.0231,
      "step": 10650
    },
    {
      "epoch": 0.5967651979921919,
      "grad_norm": 0.07603133469820023,
      "learning_rate": 1.6025283509946087e-05,
      "loss": 0.0694,
      "step": 10700
    },
    {
      "epoch": 0.5995538204127161,
      "grad_norm": 0.0016662424895912409,
      "learning_rate": 1.600669269380926e-05,
      "loss": 0.001,
      "step": 10750
    },
    {
      "epoch": 0.6023424428332403,
      "grad_norm": 0.01835903339087963,
      "learning_rate": 1.598810187767243e-05,
      "loss": 0.0743,
      "step": 10800
    },
    {
      "epoch": 0.6051310652537646,
      "grad_norm": 11.79714298248291,
      "learning_rate": 1.5969511061535602e-05,
      "loss": 0.0622,
      "step": 10850
    },
    {
      "epoch": 0.6079196876742889,
      "grad_norm": 0.008419790305197239,
      "learning_rate": 1.5950920245398772e-05,
      "loss": 0.031,
      "step": 10900
    },
    {
      "epoch": 0.6107083100948132,
      "grad_norm": 0.008430764079093933,
      "learning_rate": 1.5932329429261945e-05,
      "loss": 0.0337,
      "step": 10950
    },
    {
      "epoch": 0.6134969325153374,
      "grad_norm": 0.009234253317117691,
      "learning_rate": 1.5913738613125118e-05,
      "loss": 0.034,
      "step": 11000
    },
    {
      "epoch": 0.6162855549358617,
      "grad_norm": 0.011984827928245068,
      "learning_rate": 1.5895147796988287e-05,
      "loss": 0.0144,
      "step": 11050
    },
    {
      "epoch": 0.6190741773563859,
      "grad_norm": 0.007480529602617025,
      "learning_rate": 1.587655698085146e-05,
      "loss": 0.0375,
      "step": 11100
    },
    {
      "epoch": 0.6218627997769102,
      "grad_norm": 0.0030301609076559544,
      "learning_rate": 1.5857966164714633e-05,
      "loss": 0.0137,
      "step": 11150
    },
    {
      "epoch": 0.6246514221974344,
      "grad_norm": 0.004165783990174532,
      "learning_rate": 1.5839375348577803e-05,
      "loss": 0.0003,
      "step": 11200
    },
    {
      "epoch": 0.6274400446179588,
      "grad_norm": 0.0020572759676724672,
      "learning_rate": 1.5820784532440976e-05,
      "loss": 0.0037,
      "step": 11250
    },
    {
      "epoch": 0.630228667038483,
      "grad_norm": 0.0018564576748758554,
      "learning_rate": 1.5802193716304146e-05,
      "loss": 0.0415,
      "step": 11300
    },
    {
      "epoch": 0.6330172894590073,
      "grad_norm": 0.0017021779203787446,
      "learning_rate": 1.578360290016732e-05,
      "loss": 0.0102,
      "step": 11350
    },
    {
      "epoch": 0.6358059118795315,
      "grad_norm": 0.0012520205928012729,
      "learning_rate": 1.576501208403049e-05,
      "loss": 0.0005,
      "step": 11400
    },
    {
      "epoch": 0.6385945343000557,
      "grad_norm": 0.010036726482212543,
      "learning_rate": 1.574642126789366e-05,
      "loss": 0.0546,
      "step": 11450
    },
    {
      "epoch": 0.64138315672058,
      "grad_norm": 0.0058398060500621796,
      "learning_rate": 1.5727830451756834e-05,
      "loss": 0.0171,
      "step": 11500
    },
    {
      "epoch": 0.6441717791411042,
      "grad_norm": 0.0062280804850161076,
      "learning_rate": 1.5709239635620007e-05,
      "loss": 0.046,
      "step": 11550
    },
    {
      "epoch": 0.6469604015616286,
      "grad_norm": 1.3168755769729614,
      "learning_rate": 1.5690648819483177e-05,
      "loss": 0.0137,
      "step": 11600
    },
    {
      "epoch": 0.6497490239821528,
      "grad_norm": 0.018671445548534393,
      "learning_rate": 1.567205800334635e-05,
      "loss": 0.0296,
      "step": 11650
    },
    {
      "epoch": 0.6525376464026771,
      "grad_norm": 0.0021113259717822075,
      "learning_rate": 1.565346718720952e-05,
      "loss": 0.0125,
      "step": 11700
    },
    {
      "epoch": 0.6553262688232013,
      "grad_norm": 0.0015861974097788334,
      "learning_rate": 1.5634876371072692e-05,
      "loss": 0.0127,
      "step": 11750
    },
    {
      "epoch": 0.6581148912437256,
      "grad_norm": 0.007302787154912949,
      "learning_rate": 1.5616285554935865e-05,
      "loss": 0.0092,
      "step": 11800
    },
    {
      "epoch": 0.6609035136642498,
      "grad_norm": 0.0038959146477282047,
      "learning_rate": 1.5597694738799035e-05,
      "loss": 0.0291,
      "step": 11850
    },
    {
      "epoch": 0.6636921360847742,
      "grad_norm": 0.06075086072087288,
      "learning_rate": 1.5579103922662208e-05,
      "loss": 0.0512,
      "step": 11900
    },
    {
      "epoch": 0.6664807585052984,
      "grad_norm": 0.003947483841329813,
      "learning_rate": 1.5560513106525378e-05,
      "loss": 0.0418,
      "step": 11950
    },
    {
      "epoch": 0.6692693809258227,
      "grad_norm": 0.0035316559951752424,
      "learning_rate": 1.554192229038855e-05,
      "loss": 0.0302,
      "step": 12000
    },
    {
      "epoch": 0.6720580033463469,
      "grad_norm": 0.0021816561929881573,
      "learning_rate": 1.552333147425172e-05,
      "loss": 0.0118,
      "step": 12050
    },
    {
      "epoch": 0.6748466257668712,
      "grad_norm": 0.0017758033936843276,
      "learning_rate": 1.5504740658114893e-05,
      "loss": 0.0052,
      "step": 12100
    },
    {
      "epoch": 0.6776352481873954,
      "grad_norm": 0.0014134704833850265,
      "learning_rate": 1.5486149841978063e-05,
      "loss": 0.0001,
      "step": 12150
    },
    {
      "epoch": 0.6804238706079196,
      "grad_norm": 0.22926458716392517,
      "learning_rate": 1.5467559025841236e-05,
      "loss": 0.0419,
      "step": 12200
    },
    {
      "epoch": 0.683212493028444,
      "grad_norm": 0.008908005431294441,
      "learning_rate": 1.5448968209704405e-05,
      "loss": 0.0629,
      "step": 12250
    },
    {
      "epoch": 0.6860011154489682,
      "grad_norm": 0.004037051927298307,
      "learning_rate": 1.5430377393567578e-05,
      "loss": 0.0269,
      "step": 12300
    },
    {
      "epoch": 0.6887897378694925,
      "grad_norm": 0.016214022412896156,
      "learning_rate": 1.5411786577430748e-05,
      "loss": 0.0003,
      "step": 12350
    },
    {
      "epoch": 0.6915783602900167,
      "grad_norm": 0.017972484230995178,
      "learning_rate": 1.539319576129392e-05,
      "loss": 0.0237,
      "step": 12400
    },
    {
      "epoch": 0.694366982710541,
      "grad_norm": 7.6871562004089355,
      "learning_rate": 1.5374604945157094e-05,
      "loss": 0.0007,
      "step": 12450
    },
    {
      "epoch": 0.6971556051310652,
      "grad_norm": 0.002881893888115883,
      "learning_rate": 1.5356014129020263e-05,
      "loss": 0.0278,
      "step": 12500
    },
    {
      "epoch": 0.6999442275515895,
      "grad_norm": 0.015133112668991089,
      "learning_rate": 1.5337423312883436e-05,
      "loss": 0.0167,
      "step": 12550
    },
    {
      "epoch": 0.7027328499721138,
      "grad_norm": 0.002656233496963978,
      "learning_rate": 1.5318832496746606e-05,
      "loss": 0.0216,
      "step": 12600
    },
    {
      "epoch": 0.7055214723926381,
      "grad_norm": 0.00497526815161109,
      "learning_rate": 1.530024168060978e-05,
      "loss": 0.0266,
      "step": 12650
    },
    {
      "epoch": 0.7083100948131623,
      "grad_norm": 0.003432441968470812,
      "learning_rate": 1.5281650864472952e-05,
      "loss": 0.0281,
      "step": 12700
    },
    {
      "epoch": 0.7110987172336866,
      "grad_norm": 0.005152490455657244,
      "learning_rate": 1.526306004833612e-05,
      "loss": 0.0187,
      "step": 12750
    },
    {
      "epoch": 0.7138873396542108,
      "grad_norm": 61.01309585571289,
      "learning_rate": 1.5244469232199295e-05,
      "loss": 0.0377,
      "step": 12800
    },
    {
      "epoch": 0.716675962074735,
      "grad_norm": 0.12627261877059937,
      "learning_rate": 1.5225878416062468e-05,
      "loss": 0.0255,
      "step": 12850
    },
    {
      "epoch": 0.7194645844952593,
      "grad_norm": 0.005464171525090933,
      "learning_rate": 1.5207287599925637e-05,
      "loss": 0.0156,
      "step": 12900
    },
    {
      "epoch": 0.7222532069157837,
      "grad_norm": 0.002574356971308589,
      "learning_rate": 1.518869678378881e-05,
      "loss": 0.0004,
      "step": 12950
    },
    {
      "epoch": 0.7250418293363079,
      "grad_norm": 0.03661473095417023,
      "learning_rate": 1.517010596765198e-05,
      "loss": 0.0042,
      "step": 13000
    },
    {
      "epoch": 0.7278304517568321,
      "grad_norm": 0.0015652503352612257,
      "learning_rate": 1.5151515151515153e-05,
      "loss": 0.0138,
      "step": 13050
    },
    {
      "epoch": 0.7306190741773564,
      "grad_norm": 0.002477895235642791,
      "learning_rate": 1.5132924335378326e-05,
      "loss": 0.0127,
      "step": 13100
    },
    {
      "epoch": 0.7334076965978806,
      "grad_norm": 0.001954449340701103,
      "learning_rate": 1.5114333519241495e-05,
      "loss": 0.0358,
      "step": 13150
    },
    {
      "epoch": 0.7361963190184049,
      "grad_norm": 0.005035717971622944,
      "learning_rate": 1.5095742703104668e-05,
      "loss": 0.0116,
      "step": 13200
    },
    {
      "epoch": 0.7389849414389291,
      "grad_norm": 0.0055982437916100025,
      "learning_rate": 1.507715188696784e-05,
      "loss": 0.0028,
      "step": 13250
    },
    {
      "epoch": 0.7417735638594535,
      "grad_norm": 0.0016011431580409408,
      "learning_rate": 1.5058561070831011e-05,
      "loss": 0.0336,
      "step": 13300
    },
    {
      "epoch": 0.7445621862799777,
      "grad_norm": 0.0010619349777698517,
      "learning_rate": 1.5039970254694182e-05,
      "loss": 0.0002,
      "step": 13350
    },
    {
      "epoch": 0.747350808700502,
      "grad_norm": 20.031909942626953,
      "learning_rate": 1.5021379438557354e-05,
      "loss": 0.0104,
      "step": 13400
    },
    {
      "epoch": 0.7501394311210262,
      "grad_norm": 0.0010970531729981303,
      "learning_rate": 1.5002788622420525e-05,
      "loss": 0.0108,
      "step": 13450
    },
    {
      "epoch": 0.7529280535415505,
      "grad_norm": 0.0010578118963167071,
      "learning_rate": 1.4984197806283698e-05,
      "loss": 0.0488,
      "step": 13500
    },
    {
      "epoch": 0.7557166759620747,
      "grad_norm": 0.0031180856749415398,
      "learning_rate": 1.4965606990146868e-05,
      "loss": 0.0179,
      "step": 13550
    },
    {
      "epoch": 0.758505298382599,
      "grad_norm": 0.008674762211740017,
      "learning_rate": 1.494701617401004e-05,
      "loss": 0.0004,
      "step": 13600
    },
    {
      "epoch": 0.7612939208031233,
      "grad_norm": 0.09344114363193512,
      "learning_rate": 1.492842535787321e-05,
      "loss": 0.02,
      "step": 13650
    },
    {
      "epoch": 0.7640825432236475,
      "grad_norm": 0.011720393784344196,
      "learning_rate": 1.4909834541736383e-05,
      "loss": 0.0562,
      "step": 13700
    },
    {
      "epoch": 0.7668711656441718,
      "grad_norm": 0.0008664290653541684,
      "learning_rate": 1.4891243725599556e-05,
      "loss": 0.021,
      "step": 13750
    },
    {
      "epoch": 0.769659788064696,
      "grad_norm": 0.008860187605023384,
      "learning_rate": 1.4872652909462726e-05,
      "loss": 0.0001,
      "step": 13800
    },
    {
      "epoch": 0.7724484104852203,
      "grad_norm": 0.000659057404845953,
      "learning_rate": 1.4854062093325899e-05,
      "loss": 0.0237,
      "step": 13850
    },
    {
      "epoch": 0.7752370329057445,
      "grad_norm": 0.19069409370422363,
      "learning_rate": 1.483547127718907e-05,
      "loss": 0.0048,
      "step": 13900
    },
    {
      "epoch": 0.7780256553262688,
      "grad_norm": 0.004811616148799658,
      "learning_rate": 1.4816880461052241e-05,
      "loss": 0.0001,
      "step": 13950
    },
    {
      "epoch": 0.7808142777467931,
      "grad_norm": 0.0016028633108362556,
      "learning_rate": 1.4798289644915413e-05,
      "loss": 0.0329,
      "step": 14000
    },
    {
      "epoch": 0.7836029001673174,
      "grad_norm": 0.02427855134010315,
      "learning_rate": 1.4779698828778584e-05,
      "loss": 0.048,
      "step": 14050
    },
    {
      "epoch": 0.7863915225878416,
      "grad_norm": 0.00897262617945671,
      "learning_rate": 1.4761108012641757e-05,
      "loss": 0.0369,
      "step": 14100
    },
    {
      "epoch": 0.7891801450083659,
      "grad_norm": 0.0007289058994501829,
      "learning_rate": 1.4742517196504928e-05,
      "loss": 0.0214,
      "step": 14150
    },
    {
      "epoch": 0.7919687674288901,
      "grad_norm": 0.0008996500982902944,
      "learning_rate": 1.47239263803681e-05,
      "loss": 0.0472,
      "step": 14200
    },
    {
      "epoch": 0.7947573898494144,
      "grad_norm": 0.3020140528678894,
      "learning_rate": 1.470533556423127e-05,
      "loss": 0.0291,
      "step": 14250
    },
    {
      "epoch": 0.7975460122699386,
      "grad_norm": 0.005882679019123316,
      "learning_rate": 1.4686744748094444e-05,
      "loss": 0.0381,
      "step": 14300
    },
    {
      "epoch": 0.800334634690463,
      "grad_norm": 0.02494368702173233,
      "learning_rate": 1.4668153931957613e-05,
      "loss": 0.0182,
      "step": 14350
    },
    {
      "epoch": 0.8031232571109872,
      "grad_norm": 0.41333329677581787,
      "learning_rate": 1.4649563115820786e-05,
      "loss": 0.0595,
      "step": 14400
    },
    {
      "epoch": 0.8059118795315114,
      "grad_norm": 0.003266663523390889,
      "learning_rate": 1.4630972299683956e-05,
      "loss": 0.0348,
      "step": 14450
    },
    {
      "epoch": 0.8087005019520357,
      "grad_norm": 21.35424041748047,
      "learning_rate": 1.4612381483547129e-05,
      "loss": 0.0005,
      "step": 14500
    },
    {
      "epoch": 0.8114891243725599,
      "grad_norm": 0.0017597002442926168,
      "learning_rate": 1.4593790667410302e-05,
      "loss": 0.0084,
      "step": 14550
    },
    {
      "epoch": 0.8142777467930842,
      "grad_norm": 0.002350785071030259,
      "learning_rate": 1.4575199851273472e-05,
      "loss": 0.0546,
      "step": 14600
    },
    {
      "epoch": 0.8170663692136084,
      "grad_norm": 0.048261839896440506,
      "learning_rate": 1.4556609035136645e-05,
      "loss": 0.0241,
      "step": 14650
    },
    {
      "epoch": 0.8198549916341328,
      "grad_norm": 0.021516716107726097,
      "learning_rate": 1.4538018218999814e-05,
      "loss": 0.029,
      "step": 14700
    },
    {
      "epoch": 0.822643614054657,
      "grad_norm": 0.08381914347410202,
      "learning_rate": 1.4519427402862987e-05,
      "loss": 0.0225,
      "step": 14750
    },
    {
      "epoch": 0.8254322364751813,
      "grad_norm": 0.00995416846126318,
      "learning_rate": 1.4500836586726158e-05,
      "loss": 0.0326,
      "step": 14800
    },
    {
      "epoch": 0.8282208588957055,
      "grad_norm": 0.053751140832901,
      "learning_rate": 1.448224577058933e-05,
      "loss": 0.0003,
      "step": 14850
    },
    {
      "epoch": 0.8310094813162298,
      "grad_norm": 0.0031755459494888783,
      "learning_rate": 1.4463654954452501e-05,
      "loss": 0.0356,
      "step": 14900
    },
    {
      "epoch": 0.833798103736754,
      "grad_norm": 8.437758445739746,
      "learning_rate": 1.4445064138315674e-05,
      "loss": 0.0008,
      "step": 14950
    },
    {
      "epoch": 0.8365867261572784,
      "grad_norm": 0.1796608716249466,
      "learning_rate": 1.4426473322178844e-05,
      "loss": 0.0243,
      "step": 15000
    },
    {
      "epoch": 0.8393753485778026,
      "grad_norm": 0.023706644773483276,
      "learning_rate": 1.4407882506042017e-05,
      "loss": 0.0196,
      "step": 15050
    },
    {
      "epoch": 0.8421639709983268,
      "grad_norm": 0.0013088044943287969,
      "learning_rate": 1.4389291689905186e-05,
      "loss": 0.0003,
      "step": 15100
    },
    {
      "epoch": 0.8449525934188511,
      "grad_norm": 0.008142325095832348,
      "learning_rate": 1.437070087376836e-05,
      "loss": 0.0114,
      "step": 15150
    },
    {
      "epoch": 0.8477412158393753,
      "grad_norm": 0.0012318578083068132,
      "learning_rate": 1.4352110057631532e-05,
      "loss": 0.0061,
      "step": 15200
    },
    {
      "epoch": 0.8505298382598996,
      "grad_norm": 0.011678039096295834,
      "learning_rate": 1.4333519241494702e-05,
      "loss": 0.0298,
      "step": 15250
    },
    {
      "epoch": 0.8533184606804238,
      "grad_norm": 0.006303220055997372,
      "learning_rate": 1.4314928425357875e-05,
      "loss": 0.0138,
      "step": 15300
    },
    {
      "epoch": 0.8561070831009482,
      "grad_norm": 0.0015112069668248296,
      "learning_rate": 1.4296337609221048e-05,
      "loss": 0.0047,
      "step": 15350
    },
    {
      "epoch": 0.8588957055214724,
      "grad_norm": 0.0015695983311161399,
      "learning_rate": 1.4277746793084217e-05,
      "loss": 0.0001,
      "step": 15400
    },
    {
      "epoch": 0.8616843279419967,
      "grad_norm": 0.002168257487937808,
      "learning_rate": 1.4259527793270125e-05,
      "loss": 0.0507,
      "step": 15450
    },
    {
      "epoch": 0.8644729503625209,
      "grad_norm": 0.014511747285723686,
      "learning_rate": 1.4240936977133298e-05,
      "loss": 0.0323,
      "step": 15500
    },
    {
      "epoch": 0.8672615727830452,
      "grad_norm": 0.0016253483481705189,
      "learning_rate": 1.4222346160996469e-05,
      "loss": 0.024,
      "step": 15550
    },
    {
      "epoch": 0.8700501952035694,
      "grad_norm": 0.00453954515978694,
      "learning_rate": 1.420375534485964e-05,
      "loss": 0.0304,
      "step": 15600
    },
    {
      "epoch": 0.8728388176240937,
      "grad_norm": 0.0013068064581602812,
      "learning_rate": 1.4185164528722812e-05,
      "loss": 0.0036,
      "step": 15650
    },
    {
      "epoch": 0.875627440044618,
      "grad_norm": 0.0010143006220459938,
      "learning_rate": 1.4166573712585983e-05,
      "loss": 0.0162,
      "step": 15700
    },
    {
      "epoch": 0.8784160624651423,
      "grad_norm": 0.01591261848807335,
      "learning_rate": 1.4147982896449156e-05,
      "loss": 0.0223,
      "step": 15750
    },
    {
      "epoch": 0.8812046848856665,
      "grad_norm": 0.0017190687358379364,
      "learning_rate": 1.4129392080312327e-05,
      "loss": 0.014,
      "step": 15800
    },
    {
      "epoch": 0.8839933073061907,
      "grad_norm": 0.0007757607963867486,
      "learning_rate": 1.4110801264175498e-05,
      "loss": 0.0088,
      "step": 15850
    },
    {
      "epoch": 0.886781929726715,
      "grad_norm": 0.009790717624127865,
      "learning_rate": 1.409221044803867e-05,
      "loss": 0.0131,
      "step": 15900
    },
    {
      "epoch": 0.8895705521472392,
      "grad_norm": 0.000643080216832459,
      "learning_rate": 1.4073619631901843e-05,
      "loss": 0.0001,
      "step": 15950
    },
    {
      "epoch": 0.8923591745677635,
      "grad_norm": 0.0025876995641738176,
      "learning_rate": 1.4055028815765012e-05,
      "loss": 0.0001,
      "step": 16000
    },
    {
      "epoch": 0.8951477969882878,
      "grad_norm": 0.000590887269936502,
      "learning_rate": 1.4036437999628185e-05,
      "loss": 0.0155,
      "step": 16050
    },
    {
      "epoch": 0.8979364194088121,
      "grad_norm": 0.0004913347074761987,
      "learning_rate": 1.4017847183491355e-05,
      "loss": 0.0001,
      "step": 16100
    },
    {
      "epoch": 0.9007250418293363,
      "grad_norm": 0.0038319225423038006,
      "learning_rate": 1.3999256367354528e-05,
      "loss": 0.0344,
      "step": 16150
    },
    {
      "epoch": 0.9035136642498606,
      "grad_norm": 11.811174392700195,
      "learning_rate": 1.3980665551217701e-05,
      "loss": 0.0379,
      "step": 16200
    },
    {
      "epoch": 0.9063022866703848,
      "grad_norm": 0.004102977924048901,
      "learning_rate": 1.396207473508087e-05,
      "loss": 0.012,
      "step": 16250
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.0032551598269492388,
      "learning_rate": 1.3943483918944044e-05,
      "loss": 0.0321,
      "step": 16300
    },
    {
      "epoch": 0.9118795315114333,
      "grad_norm": 0.0011070641921833158,
      "learning_rate": 1.3924893102807215e-05,
      "loss": 0.014,
      "step": 16350
    },
    {
      "epoch": 0.9146681539319577,
      "grad_norm": 0.0012377805542200804,
      "learning_rate": 1.3906302286670386e-05,
      "loss": 0.0114,
      "step": 16400
    },
    {
      "epoch": 0.9174567763524819,
      "grad_norm": 0.0011275513097643852,
      "learning_rate": 1.3887711470533557e-05,
      "loss": 0.0162,
      "step": 16450
    },
    {
      "epoch": 0.9202453987730062,
      "grad_norm": 0.04336060956120491,
      "learning_rate": 1.3869120654396729e-05,
      "loss": 0.044,
      "step": 16500
    },
    {
      "epoch": 0.9230340211935304,
      "grad_norm": 1.6422207355499268,
      "learning_rate": 1.38505298382599e-05,
      "loss": 0.0071,
      "step": 16550
    },
    {
      "epoch": 0.9258226436140546,
      "grad_norm": 0.0010264117736369371,
      "learning_rate": 1.3831939022123073e-05,
      "loss": 0.0003,
      "step": 16600
    },
    {
      "epoch": 0.9286112660345789,
      "grad_norm": 0.0007966058328747749,
      "learning_rate": 1.3813348205986243e-05,
      "loss": 0.0002,
      "step": 16650
    },
    {
      "epoch": 0.9313998884551031,
      "grad_norm": 0.0008312836871482432,
      "learning_rate": 1.3794757389849416e-05,
      "loss": 0.0208,
      "step": 16700
    },
    {
      "epoch": 0.9341885108756275,
      "grad_norm": 61.21152114868164,
      "learning_rate": 1.3776166573712585e-05,
      "loss": 0.0317,
      "step": 16750
    },
    {
      "epoch": 0.9369771332961517,
      "grad_norm": 0.0012266868725419044,
      "learning_rate": 1.3757575757575758e-05,
      "loss": 0.0301,
      "step": 16800
    },
    {
      "epoch": 0.939765755716676,
      "grad_norm": 0.002869698451831937,
      "learning_rate": 1.3738984941438931e-05,
      "loss": 0.0516,
      "step": 16850
    },
    {
      "epoch": 0.9425543781372002,
      "grad_norm": 6.5133490562438965,
      "learning_rate": 1.37203941253021e-05,
      "loss": 0.0224,
      "step": 16900
    },
    {
      "epoch": 0.9453430005577245,
      "grad_norm": 0.0019172802567481995,
      "learning_rate": 1.3701803309165274e-05,
      "loss": 0.0003,
      "step": 16950
    },
    {
      "epoch": 0.9481316229782487,
      "grad_norm": 0.000919874757528305,
      "learning_rate": 1.3683212493028447e-05,
      "loss": 0.0001,
      "step": 17000
    },
    {
      "epoch": 0.950920245398773,
      "grad_norm": 0.0010742639424279332,
      "learning_rate": 1.3664621676891616e-05,
      "loss": 0.0248,
      "step": 17050
    },
    {
      "epoch": 0.9537088678192973,
      "grad_norm": 0.2429901659488678,
      "learning_rate": 1.364603086075479e-05,
      "loss": 0.0001,
      "step": 17100
    },
    {
      "epoch": 0.9564974902398216,
      "grad_norm": 0.0007116336491890252,
      "learning_rate": 1.3627440044617959e-05,
      "loss": 0.0357,
      "step": 17150
    },
    {
      "epoch": 0.9592861126603458,
      "grad_norm": 0.0006656034383922815,
      "learning_rate": 1.3608849228481132e-05,
      "loss": 0.0077,
      "step": 17200
    },
    {
      "epoch": 0.96207473508087,
      "grad_norm": 0.0006550404359586537,
      "learning_rate": 1.3590258412344303e-05,
      "loss": 0.0203,
      "step": 17250
    },
    {
      "epoch": 0.9648633575013943,
      "grad_norm": 0.0019391461974009871,
      "learning_rate": 1.3571667596207475e-05,
      "loss": 0.0009,
      "step": 17300
    },
    {
      "epoch": 0.9676519799219185,
      "grad_norm": 24.764877319335938,
      "learning_rate": 1.3553076780070646e-05,
      "loss": 0.0184,
      "step": 17350
    },
    {
      "epoch": 0.9704406023424428,
      "grad_norm": 0.003773116273805499,
      "learning_rate": 1.3534485963933819e-05,
      "loss": 0.0331,
      "step": 17400
    },
    {
      "epoch": 0.9732292247629671,
      "grad_norm": 0.0013248476898297668,
      "learning_rate": 1.3515895147796988e-05,
      "loss": 0.0179,
      "step": 17450
    },
    {
      "epoch": 0.9760178471834914,
      "grad_norm": 106.64051818847656,
      "learning_rate": 1.3497304331660161e-05,
      "loss": 0.0175,
      "step": 17500
    },
    {
      "epoch": 0.9788064696040156,
      "grad_norm": 0.0010783508187159896,
      "learning_rate": 1.3478713515523331e-05,
      "loss": 0.0193,
      "step": 17550
    },
    {
      "epoch": 0.9815950920245399,
      "grad_norm": 0.0323193296790123,
      "learning_rate": 1.3460122699386504e-05,
      "loss": 0.0396,
      "step": 17600
    },
    {
      "epoch": 0.9843837144450641,
      "grad_norm": 0.005161463748663664,
      "learning_rate": 1.3441531883249677e-05,
      "loss": 0.0257,
      "step": 17650
    },
    {
      "epoch": 0.9871723368655884,
      "grad_norm": 0.002287322888150811,
      "learning_rate": 1.3423312883435584e-05,
      "loss": 0.0479,
      "step": 17700
    },
    {
      "epoch": 0.9899609592861126,
      "grad_norm": 0.00237410981208086,
      "learning_rate": 1.3404722067298757e-05,
      "loss": 0.0331,
      "step": 17750
    },
    {
      "epoch": 0.992749581706637,
      "grad_norm": 0.00117951026186347,
      "learning_rate": 1.3386131251161927e-05,
      "loss": 0.0068,
      "step": 17800
    },
    {
      "epoch": 0.9955382041271612,
      "grad_norm": 0.0017054396448656917,
      "learning_rate": 1.33675404350251e-05,
      "loss": 0.022,
      "step": 17850
    },
    {
      "epoch": 0.9983268265476855,
      "grad_norm": 0.0010833563283085823,
      "learning_rate": 1.334894961888827e-05,
      "loss": 0.0001,
      "step": 17900
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.020819135010242462,
      "eval_runtime": 74.2458,
      "eval_samples_per_second": 482.977,
      "eval_steps_per_second": 60.381,
      "step": 17930
    },
    {
      "epoch": 1.0011154489682097,
      "grad_norm": 0.000857893202919513,
      "learning_rate": 1.3330358802751442e-05,
      "loss": 0.0027,
      "step": 17950
    },
    {
      "epoch": 1.003904071388734,
      "grad_norm": 0.0007628099410794675,
      "learning_rate": 1.3311767986614614e-05,
      "loss": 0.0001,
      "step": 18000
    },
    {
      "epoch": 1.0066926938092582,
      "grad_norm": 0.0008111891802400351,
      "learning_rate": 1.3293177170477785e-05,
      "loss": 0.0121,
      "step": 18050
    },
    {
      "epoch": 1.0094813162297824,
      "grad_norm": 0.0008526494493708014,
      "learning_rate": 1.3274586354340956e-05,
      "loss": 0.0436,
      "step": 18100
    },
    {
      "epoch": 1.0122699386503067,
      "grad_norm": 0.0010252398205921054,
      "learning_rate": 1.3255995538204128e-05,
      "loss": 0.0183,
      "step": 18150
    },
    {
      "epoch": 1.015058561070831,
      "grad_norm": 0.00106496037915349,
      "learning_rate": 1.3237404722067299e-05,
      "loss": 0.0021,
      "step": 18200
    },
    {
      "epoch": 1.0178471834913552,
      "grad_norm": 0.009105478413403034,
      "learning_rate": 1.3218813905930472e-05,
      "loss": 0.0204,
      "step": 18250
    },
    {
      "epoch": 1.0206358059118796,
      "grad_norm": 0.04743807017803192,
      "learning_rate": 1.3200223089793642e-05,
      "loss": 0.0127,
      "step": 18300
    },
    {
      "epoch": 1.0234244283324039,
      "grad_norm": 0.004243456292897463,
      "learning_rate": 1.3181632273656815e-05,
      "loss": 0.0003,
      "step": 18350
    },
    {
      "epoch": 1.0262130507529281,
      "grad_norm": 0.0006666774279437959,
      "learning_rate": 1.3163413273842722e-05,
      "loss": 0.0096,
      "step": 18400
    },
    {
      "epoch": 1.0290016731734524,
      "grad_norm": 0.0006158634787425399,
      "learning_rate": 1.3144822457705895e-05,
      "loss": 0.0273,
      "step": 18450
    },
    {
      "epoch": 1.0317902955939766,
      "grad_norm": 0.0007571927271783352,
      "learning_rate": 1.3126231641569064e-05,
      "loss": 0.0166,
      "step": 18500
    },
    {
      "epoch": 1.0345789180145009,
      "grad_norm": 0.0006640059291385114,
      "learning_rate": 1.3107640825432237e-05,
      "loss": 0.0187,
      "step": 18550
    },
    {
      "epoch": 1.037367540435025,
      "grad_norm": 0.012163540348410606,
      "learning_rate": 1.308905000929541e-05,
      "loss": 0.0077,
      "step": 18600
    },
    {
      "epoch": 1.0401561628555493,
      "grad_norm": 0.052748002111911774,
      "learning_rate": 1.307045919315858e-05,
      "loss": 0.0392,
      "step": 18650
    },
    {
      "epoch": 1.0429447852760736,
      "grad_norm": 0.0007074198802001774,
      "learning_rate": 1.3051868377021753e-05,
      "loss": 0.014,
      "step": 18700
    },
    {
      "epoch": 1.0457334076965978,
      "grad_norm": 0.0005634441040456295,
      "learning_rate": 1.3033277560884924e-05,
      "loss": 0.0205,
      "step": 18750
    },
    {
      "epoch": 1.048522030117122,
      "grad_norm": 0.0007161205285228789,
      "learning_rate": 1.3014686744748096e-05,
      "loss": 0.0313,
      "step": 18800
    },
    {
      "epoch": 1.0513106525376463,
      "grad_norm": 0.0016002453630790114,
      "learning_rate": 1.2996095928611267e-05,
      "loss": 0.0219,
      "step": 18850
    },
    {
      "epoch": 1.0540992749581706,
      "grad_norm": 0.006524883210659027,
      "learning_rate": 1.2977505112474438e-05,
      "loss": 0.0092,
      "step": 18900
    },
    {
      "epoch": 1.0568878973786948,
      "grad_norm": 0.0005076143424957991,
      "learning_rate": 1.295891429633761e-05,
      "loss": 0.0165,
      "step": 18950
    },
    {
      "epoch": 1.0596765197992193,
      "grad_norm": 0.0006641462678089738,
      "learning_rate": 1.2940323480200782e-05,
      "loss": 0.0275,
      "step": 19000
    },
    {
      "epoch": 1.0624651422197435,
      "grad_norm": 0.03359443321824074,
      "learning_rate": 1.2921732664063952e-05,
      "loss": 0.0263,
      "step": 19050
    },
    {
      "epoch": 1.0652537646402678,
      "grad_norm": 0.0006164702936075628,
      "learning_rate": 1.2903141847927125e-05,
      "loss": 0.0006,
      "step": 19100
    },
    {
      "epoch": 1.068042387060792,
      "grad_norm": 0.0005062881973572075,
      "learning_rate": 1.2884551031790296e-05,
      "loss": 0.0,
      "step": 19150
    },
    {
      "epoch": 1.0708310094813163,
      "grad_norm": 0.0005327780963853002,
      "learning_rate": 1.2865960215653468e-05,
      "loss": 0.0105,
      "step": 19200
    },
    {
      "epoch": 1.0736196319018405,
      "grad_norm": 0.000644420797470957,
      "learning_rate": 1.284736939951664e-05,
      "loss": 0.0354,
      "step": 19250
    },
    {
      "epoch": 1.0764082543223648,
      "grad_norm": 0.0005432414473034441,
      "learning_rate": 1.282877858337981e-05,
      "loss": 0.0066,
      "step": 19300
    },
    {
      "epoch": 1.079196876742889,
      "grad_norm": 0.0007618984673172235,
      "learning_rate": 1.2810559583565721e-05,
      "loss": 0.0067,
      "step": 19350
    },
    {
      "epoch": 1.0819854991634132,
      "grad_norm": 0.0006839838461019099,
      "learning_rate": 1.279196876742889e-05,
      "loss": 0.0275,
      "step": 19400
    },
    {
      "epoch": 1.0847741215839375,
      "grad_norm": 0.17890983819961548,
      "learning_rate": 1.2773377951292063e-05,
      "loss": 0.0003,
      "step": 19450
    },
    {
      "epoch": 1.0875627440044617,
      "grad_norm": 0.00124561064876616,
      "learning_rate": 1.2754787135155233e-05,
      "loss": 0.0081,
      "step": 19500
    },
    {
      "epoch": 1.090351366424986,
      "grad_norm": 0.0009719302179291844,
      "learning_rate": 1.2736196319018406e-05,
      "loss": 0.0001,
      "step": 19550
    },
    {
      "epoch": 1.0931399888455102,
      "grad_norm": 0.0017653268296271563,
      "learning_rate": 1.2717605502881577e-05,
      "loss": 0.0336,
      "step": 19600
    },
    {
      "epoch": 1.0959286112660345,
      "grad_norm": 0.0013748403871431947,
      "learning_rate": 1.2699014686744749e-05,
      "loss": 0.0118,
      "step": 19650
    },
    {
      "epoch": 1.098717233686559,
      "grad_norm": 0.0026513058692216873,
      "learning_rate": 1.2680423870607922e-05,
      "loss": 0.0111,
      "step": 19700
    },
    {
      "epoch": 1.1015058561070832,
      "grad_norm": 0.0007697875262238085,
      "learning_rate": 1.2661833054471093e-05,
      "loss": 0.0001,
      "step": 19750
    },
    {
      "epoch": 1.1042944785276074,
      "grad_norm": 0.001699670683592558,
      "learning_rate": 1.2643242238334264e-05,
      "loss": 0.0201,
      "step": 19800
    },
    {
      "epoch": 1.1070831009481317,
      "grad_norm": 0.0008180227014236152,
      "learning_rate": 1.2624651422197436e-05,
      "loss": 0.0001,
      "step": 19850
    },
    {
      "epoch": 1.109871723368656,
      "grad_norm": 0.0008465066202916205,
      "learning_rate": 1.2606060606060607e-05,
      "loss": 0.0003,
      "step": 19900
    },
    {
      "epoch": 1.1126603457891802,
      "grad_norm": 0.0005030362517572939,
      "learning_rate": 1.2587469789923778e-05,
      "loss": 0.0001,
      "step": 19950
    },
    {
      "epoch": 1.1154489682097044,
      "grad_norm": 0.000587740505579859,
      "learning_rate": 1.2568878973786951e-05,
      "loss": 0.0001,
      "step": 20000
    },
    {
      "epoch": 1.1182375906302287,
      "grad_norm": 0.000426760088885203,
      "learning_rate": 1.255028815765012e-05,
      "loss": 0.0001,
      "step": 20050
    },
    {
      "epoch": 1.121026213050753,
      "grad_norm": 0.015870744362473488,
      "learning_rate": 1.2531697341513294e-05,
      "loss": 0.0271,
      "step": 20100
    },
    {
      "epoch": 1.1238148354712771,
      "grad_norm": 0.03146710619330406,
      "learning_rate": 1.2513106525376467e-05,
      "loss": 0.0001,
      "step": 20150
    },
    {
      "epoch": 1.1266034578918014,
      "grad_norm": 0.0005379049107432365,
      "learning_rate": 1.2494515709239636e-05,
      "loss": 0.026,
      "step": 20200
    },
    {
      "epoch": 1.1293920803123256,
      "grad_norm": 0.0010083073284476995,
      "learning_rate": 1.247592489310281e-05,
      "loss": 0.0002,
      "step": 20250
    },
    {
      "epoch": 1.1321807027328499,
      "grad_norm": 0.0010641651460900903,
      "learning_rate": 1.2457334076965979e-05,
      "loss": 0.0154,
      "step": 20300
    },
    {
      "epoch": 1.1349693251533743,
      "grad_norm": 0.0005294168367981911,
      "learning_rate": 1.2438743260829152e-05,
      "loss": 0.0214,
      "step": 20350
    },
    {
      "epoch": 1.1377579475738986,
      "grad_norm": 0.016520949080586433,
      "learning_rate": 1.2420152444692323e-05,
      "loss": 0.0373,
      "step": 20400
    },
    {
      "epoch": 1.1405465699944228,
      "grad_norm": 0.0032741359900683165,
      "learning_rate": 1.2401561628555494e-05,
      "loss": 0.0002,
      "step": 20450
    },
    {
      "epoch": 1.143335192414947,
      "grad_norm": 0.002155428985133767,
      "learning_rate": 1.2382970812418666e-05,
      "loss": 0.0001,
      "step": 20500
    },
    {
      "epoch": 1.1461238148354713,
      "grad_norm": 0.0022112743463367224,
      "learning_rate": 1.2364379996281837e-05,
      "loss": 0.0154,
      "step": 20550
    },
    {
      "epoch": 1.1489124372559956,
      "grad_norm": 0.0008936981321312487,
      "learning_rate": 1.2345789180145008e-05,
      "loss": 0.0002,
      "step": 20600
    },
    {
      "epoch": 1.1517010596765198,
      "grad_norm": 0.005300184711813927,
      "learning_rate": 1.2327198364008181e-05,
      "loss": 0.0498,
      "step": 20650
    },
    {
      "epoch": 1.154489682097044,
      "grad_norm": 0.002055108780041337,
      "learning_rate": 1.2308607547871351e-05,
      "loss": 0.0002,
      "step": 20700
    },
    {
      "epoch": 1.1572783045175683,
      "grad_norm": 0.0064202542416751385,
      "learning_rate": 1.2290016731734524e-05,
      "loss": 0.0077,
      "step": 20750
    },
    {
      "epoch": 1.1600669269380925,
      "grad_norm": 0.001288528786972165,
      "learning_rate": 1.2271425915597697e-05,
      "loss": 0.0001,
      "step": 20800
    },
    {
      "epoch": 1.1628555493586168,
      "grad_norm": 0.005789427552372217,
      "learning_rate": 1.2252835099460867e-05,
      "loss": 0.0001,
      "step": 20850
    },
    {
      "epoch": 1.165644171779141,
      "grad_norm": 0.0008059769170358777,
      "learning_rate": 1.223424428332404e-05,
      "loss": 0.0139,
      "step": 20900
    },
    {
      "epoch": 1.1684327941996653,
      "grad_norm": 0.0023975966032594442,
      "learning_rate": 1.221565346718721e-05,
      "loss": 0.0152,
      "step": 20950
    },
    {
      "epoch": 1.1712214166201895,
      "grad_norm": 0.001422197325155139,
      "learning_rate": 1.2197062651050382e-05,
      "loss": 0.0001,
      "step": 21000
    },
    {
      "epoch": 1.1740100390407138,
      "grad_norm": 0.0006885947659611702,
      "learning_rate": 1.2178471834913555e-05,
      "loss": 0.0001,
      "step": 21050
    },
    {
      "epoch": 1.1767986614612382,
      "grad_norm": 0.009825854562222958,
      "learning_rate": 1.2159881018776725e-05,
      "loss": 0.0216,
      "step": 21100
    },
    {
      "epoch": 1.1795872838817625,
      "grad_norm": 0.0007324446341954172,
      "learning_rate": 1.2141290202639898e-05,
      "loss": 0.0192,
      "step": 21150
    },
    {
      "epoch": 1.1823759063022867,
      "grad_norm": 0.003473350778222084,
      "learning_rate": 1.2122699386503069e-05,
      "loss": 0.0185,
      "step": 21200
    },
    {
      "epoch": 1.185164528722811,
      "grad_norm": 0.0025455798022449017,
      "learning_rate": 1.210410857036624e-05,
      "loss": 0.0097,
      "step": 21250
    },
    {
      "epoch": 1.1879531511433352,
      "grad_norm": 0.0008879325469024479,
      "learning_rate": 1.2085517754229412e-05,
      "loss": 0.0107,
      "step": 21300
    },
    {
      "epoch": 1.1907417735638595,
      "grad_norm": 0.0006478080176748335,
      "learning_rate": 1.2066926938092583e-05,
      "loss": 0.008,
      "step": 21350
    },
    {
      "epoch": 1.1935303959843837,
      "grad_norm": 0.0018971662502735853,
      "learning_rate": 1.2048336121955754e-05,
      "loss": 0.0273,
      "step": 21400
    },
    {
      "epoch": 1.196319018404908,
      "grad_norm": 0.03774324059486389,
      "learning_rate": 1.2029745305818927e-05,
      "loss": 0.0212,
      "step": 21450
    },
    {
      "epoch": 1.1991076408254322,
      "grad_norm": 0.001889089005999267,
      "learning_rate": 1.2011154489682097e-05,
      "loss": 0.0002,
      "step": 21500
    },
    {
      "epoch": 1.2018962632459564,
      "grad_norm": 0.010933807119727135,
      "learning_rate": 1.199256367354527e-05,
      "loss": 0.0001,
      "step": 21550
    },
    {
      "epoch": 1.2046848856664807,
      "grad_norm": 0.0010175020433962345,
      "learning_rate": 1.197397285740844e-05,
      "loss": 0.0001,
      "step": 21600
    },
    {
      "epoch": 1.207473508087005,
      "grad_norm": 0.001330545754171908,
      "learning_rate": 1.1955382041271612e-05,
      "loss": 0.0122,
      "step": 21650
    },
    {
      "epoch": 1.2102621305075294,
      "grad_norm": 0.0011234579142183065,
      "learning_rate": 1.1936791225134785e-05,
      "loss": 0.0342,
      "step": 21700
    },
    {
      "epoch": 1.2130507529280536,
      "grad_norm": 0.0007562836981378496,
      "learning_rate": 1.1918200408997955e-05,
      "loss": 0.0001,
      "step": 21750
    },
    {
      "epoch": 1.2158393753485779,
      "grad_norm": 0.0010774319525808096,
      "learning_rate": 1.1899609592861128e-05,
      "loss": 0.0001,
      "step": 21800
    },
    {
      "epoch": 1.2186279977691021,
      "grad_norm": 0.0007392433471977711,
      "learning_rate": 1.18810187767243e-05,
      "loss": 0.0001,
      "step": 21850
    },
    {
      "epoch": 1.2214166201896264,
      "grad_norm": 0.0038916640914976597,
      "learning_rate": 1.186242796058747e-05,
      "loss": 0.0001,
      "step": 21900
    },
    {
      "epoch": 1.2242052426101506,
      "grad_norm": 0.0006994995637796819,
      "learning_rate": 1.1843837144450644e-05,
      "loss": 0.0245,
      "step": 21950
    },
    {
      "epoch": 1.2269938650306749,
      "grad_norm": 0.0015384904108941555,
      "learning_rate": 1.1825246328313813e-05,
      "loss": 0.0001,
      "step": 22000
    },
    {
      "epoch": 1.2297824874511991,
      "grad_norm": 0.005290846340358257,
      "learning_rate": 1.1806655512176986e-05,
      "loss": 0.0154,
      "step": 22050
    },
    {
      "epoch": 1.2325711098717234,
      "grad_norm": 0.0007103354437276721,
      "learning_rate": 1.1788064696040158e-05,
      "loss": 0.012,
      "step": 22100
    },
    {
      "epoch": 1.2353597322922476,
      "grad_norm": 0.0006544627249240875,
      "learning_rate": 1.1769473879903329e-05,
      "loss": 0.0001,
      "step": 22150
    },
    {
      "epoch": 1.2381483547127718,
      "grad_norm": 0.0015791988698765635,
      "learning_rate": 1.17508830637665e-05,
      "loss": 0.0001,
      "step": 22200
    },
    {
      "epoch": 1.240936977133296,
      "grad_norm": 0.0008686676737852395,
      "learning_rate": 1.1732292247629673e-05,
      "loss": 0.0001,
      "step": 22250
    },
    {
      "epoch": 1.2437255995538203,
      "grad_norm": 0.000474466010928154,
      "learning_rate": 1.1713701431492843e-05,
      "loss": 0.0114,
      "step": 22300
    },
    {
      "epoch": 1.2465142219743446,
      "grad_norm": 0.0006213576416485012,
      "learning_rate": 1.1695110615356016e-05,
      "loss": 0.0382,
      "step": 22350
    },
    {
      "epoch": 1.2493028443948688,
      "grad_norm": 0.0005974179948680103,
      "learning_rate": 1.1676519799219185e-05,
      "loss": 0.0106,
      "step": 22400
    },
    {
      "epoch": 1.252091466815393,
      "grad_norm": 0.0006771957851015031,
      "learning_rate": 1.1657928983082358e-05,
      "loss": 0.0253,
      "step": 22450
    },
    {
      "epoch": 1.2548800892359175,
      "grad_norm": 0.08347374945878983,
      "learning_rate": 1.1639338166945531e-05,
      "loss": 0.0367,
      "step": 22500
    },
    {
      "epoch": 1.2576687116564418,
      "grad_norm": 0.0013746559852734208,
      "learning_rate": 1.1620747350808701e-05,
      "loss": 0.0007,
      "step": 22550
    },
    {
      "epoch": 1.260457334076966,
      "grad_norm": 0.001423030742444098,
      "learning_rate": 1.1602156534671874e-05,
      "loss": 0.0002,
      "step": 22600
    },
    {
      "epoch": 1.2632459564974903,
      "grad_norm": 0.0011777430772781372,
      "learning_rate": 1.1583565718535043e-05,
      "loss": 0.0184,
      "step": 22650
    },
    {
      "epoch": 1.2660345789180145,
      "grad_norm": 0.0012337733060121536,
      "learning_rate": 1.1564974902398216e-05,
      "loss": 0.0001,
      "step": 22700
    },
    {
      "epoch": 1.2688232013385388,
      "grad_norm": 0.004172150976955891,
      "learning_rate": 1.1546384086261388e-05,
      "loss": 0.0012,
      "step": 22750
    },
    {
      "epoch": 1.271611823759063,
      "grad_norm": 0.0017107108142226934,
      "learning_rate": 1.1527793270124559e-05,
      "loss": 0.0001,
      "step": 22800
    },
    {
      "epoch": 1.2744004461795873,
      "grad_norm": 0.014018104411661625,
      "learning_rate": 1.150920245398773e-05,
      "loss": 0.0303,
      "step": 22850
    },
    {
      "epoch": 1.2771890686001115,
      "grad_norm": 0.004774703644216061,
      "learning_rate": 1.1490611637850903e-05,
      "loss": 0.0132,
      "step": 22900
    },
    {
      "epoch": 1.2799776910206357,
      "grad_norm": 0.0008407481363974512,
      "learning_rate": 1.1472020821714075e-05,
      "loss": 0.0,
      "step": 22950
    },
    {
      "epoch": 1.28276631344116,
      "grad_norm": 0.0007619512616656721,
      "learning_rate": 1.1453430005577246e-05,
      "loss": 0.0078,
      "step": 23000
    },
    {
      "epoch": 1.2855549358616845,
      "grad_norm": 0.0007365962374024093,
      "learning_rate": 1.1434839189440417e-05,
      "loss": 0.0,
      "step": 23050
    },
    {
      "epoch": 1.2883435582822087,
      "grad_norm": 0.0007107651908881962,
      "learning_rate": 1.1416248373303589e-05,
      "loss": 0.0142,
      "step": 23100
    },
    {
      "epoch": 1.291132180702733,
      "grad_norm": 0.0006674064206890762,
      "learning_rate": 1.1397657557166762e-05,
      "loss": 0.0,
      "step": 23150
    },
    {
      "epoch": 1.2939208031232572,
      "grad_norm": 0.0006202970980666578,
      "learning_rate": 1.1379066741029931e-05,
      "loss": 0.0115,
      "step": 23200
    },
    {
      "epoch": 1.2967094255437814,
      "grad_norm": 0.3355358839035034,
      "learning_rate": 1.1360475924893104e-05,
      "loss": 0.0135,
      "step": 23250
    },
    {
      "epoch": 1.2994980479643057,
      "grad_norm": 0.0005909586325287819,
      "learning_rate": 1.1341885108756274e-05,
      "loss": 0.0109,
      "step": 23300
    },
    {
      "epoch": 1.30228667038483,
      "grad_norm": 2.07433819770813,
      "learning_rate": 1.1323294292619447e-05,
      "loss": 0.0121,
      "step": 23350
    },
    {
      "epoch": 1.3050752928053542,
      "grad_norm": 0.0006110271788202226,
      "learning_rate": 1.130470347648262e-05,
      "loss": 0.0308,
      "step": 23400
    },
    {
      "epoch": 1.3078639152258784,
      "grad_norm": 0.00047547038411721587,
      "learning_rate": 1.128611266034579e-05,
      "loss": 0.0002,
      "step": 23450
    },
    {
      "epoch": 1.3106525376464027,
      "grad_norm": 0.0005028893938288093,
      "learning_rate": 1.1267521844208962e-05,
      "loss": 0.0,
      "step": 23500
    },
    {
      "epoch": 1.313441160066927,
      "grad_norm": 70.03629302978516,
      "learning_rate": 1.1248931028072134e-05,
      "loss": 0.0282,
      "step": 23550
    },
    {
      "epoch": 1.3162297824874511,
      "grad_norm": 0.0004859445907641202,
      "learning_rate": 1.1230340211935305e-05,
      "loss": 0.0001,
      "step": 23600
    },
    {
      "epoch": 1.3190184049079754,
      "grad_norm": 0.0003501803148537874,
      "learning_rate": 1.1211749395798476e-05,
      "loss": 0.0001,
      "step": 23650
    },
    {
      "epoch": 1.3218070273284996,
      "grad_norm": 0.0004490070859901607,
      "learning_rate": 1.1193158579661648e-05,
      "loss": 0.0001,
      "step": 23700
    },
    {
      "epoch": 1.3245956497490239,
      "grad_norm": 0.0006767222075723112,
      "learning_rate": 1.1174567763524819e-05,
      "loss": 0.0393,
      "step": 23750
    },
    {
      "epoch": 1.3273842721695481,
      "grad_norm": 0.0005464655114337802,
      "learning_rate": 1.1155976947387992e-05,
      "loss": 0.0004,
      "step": 23800
    },
    {
      "epoch": 1.3301728945900724,
      "grad_norm": 0.03158129006624222,
      "learning_rate": 1.1137386131251161e-05,
      "loss": 0.004,
      "step": 23850
    },
    {
      "epoch": 1.3329615170105968,
      "grad_norm": 0.00034904482890851796,
      "learning_rate": 1.1118795315114334e-05,
      "loss": 0.0001,
      "step": 23900
    },
    {
      "epoch": 1.335750139431121,
      "grad_norm": 0.0015211283462122083,
      "learning_rate": 1.1100204498977507e-05,
      "loss": 0.0784,
      "step": 23950
    },
    {
      "epoch": 1.3385387618516453,
      "grad_norm": 0.0033595894929021597,
      "learning_rate": 1.1081613682840677e-05,
      "loss": 0.0272,
      "step": 24000
    },
    {
      "epoch": 1.3413273842721696,
      "grad_norm": 0.002851734170690179,
      "learning_rate": 1.1063394683026584e-05,
      "loss": 0.0202,
      "step": 24050
    },
    {
      "epoch": 1.3441160066926938,
      "grad_norm": 0.0012745921267196536,
      "learning_rate": 1.1044803866889757e-05,
      "loss": 0.0095,
      "step": 24100
    },
    {
      "epoch": 1.346904629113218,
      "grad_norm": 0.0013145878911018372,
      "learning_rate": 1.102621305075293e-05,
      "loss": 0.0001,
      "step": 24150
    },
    {
      "epoch": 1.3496932515337423,
      "grad_norm": 0.0009669038117863238,
      "learning_rate": 1.10076222346161e-05,
      "loss": 0.0011,
      "step": 24200
    },
    {
      "epoch": 1.3524818739542666,
      "grad_norm": 0.000835227023344487,
      "learning_rate": 1.0989031418479273e-05,
      "loss": 0.0001,
      "step": 24250
    },
    {
      "epoch": 1.3552704963747908,
      "grad_norm": 0.0008671322138980031,
      "learning_rate": 1.0970440602342444e-05,
      "loss": 0.0089,
      "step": 24300
    },
    {
      "epoch": 1.358059118795315,
      "grad_norm": 0.0007456706953234971,
      "learning_rate": 1.0951849786205615e-05,
      "loss": 0.0043,
      "step": 24350
    },
    {
      "epoch": 1.3608477412158395,
      "grad_norm": 0.009958529844880104,
      "learning_rate": 1.0933258970068787e-05,
      "loss": 0.0221,
      "step": 24400
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.0009048052015714347,
      "learning_rate": 1.0914668153931958e-05,
      "loss": 0.0067,
      "step": 24450
    },
    {
      "epoch": 1.366424986056888,
      "grad_norm": 0.0007971462910063565,
      "learning_rate": 1.089607733779513e-05,
      "loss": 0.0109,
      "step": 24500
    },
    {
      "epoch": 1.3692136084774122,
      "grad_norm": 0.0006524392520077527,
      "learning_rate": 1.0877486521658302e-05,
      "loss": 0.0003,
      "step": 24550
    },
    {
      "epoch": 1.3720022308979365,
      "grad_norm": 0.0007384494529105723,
      "learning_rate": 1.0858895705521472e-05,
      "loss": 0.0002,
      "step": 24600
    },
    {
      "epoch": 1.3747908533184607,
      "grad_norm": 0.0016543699894100428,
      "learning_rate": 1.0840304889384645e-05,
      "loss": 0.0,
      "step": 24650
    },
    {
      "epoch": 1.377579475738985,
      "grad_norm": 0.0012545343488454819,
      "learning_rate": 1.0821714073247816e-05,
      "loss": 0.0,
      "step": 24700
    },
    {
      "epoch": 1.3803680981595092,
      "grad_norm": 0.006971501279622316,
      "learning_rate": 1.0803123257110988e-05,
      "loss": 0.0228,
      "step": 24750
    },
    {
      "epoch": 1.3831567205800335,
      "grad_norm": 0.001511103822849691,
      "learning_rate": 1.078453244097416e-05,
      "loss": 0.0153,
      "step": 24800
    },
    {
      "epoch": 1.3859453430005577,
      "grad_norm": 0.006297796964645386,
      "learning_rate": 1.076594162483733e-05,
      "loss": 0.0243,
      "step": 24850
    },
    {
      "epoch": 1.388733965421082,
      "grad_norm": 12.968903541564941,
      "learning_rate": 1.0747350808700503e-05,
      "loss": 0.0177,
      "step": 24900
    },
    {
      "epoch": 1.3915225878416062,
      "grad_norm": 0.018527304753661156,
      "learning_rate": 1.0728759992563676e-05,
      "loss": 0.0005,
      "step": 24950
    },
    {
      "epoch": 1.3943112102621305,
      "grad_norm": 0.0018359789391979575,
      "learning_rate": 1.0710169176426846e-05,
      "loss": 0.0082,
      "step": 25000
    },
    {
      "epoch": 1.3970998326826547,
      "grad_norm": 0.0013721688883379102,
      "learning_rate": 1.0691578360290019e-05,
      "loss": 0.0054,
      "step": 25050
    },
    {
      "epoch": 1.399888455103179,
      "grad_norm": 0.0012571249390020967,
      "learning_rate": 1.0672987544153188e-05,
      "loss": 0.0001,
      "step": 25100
    },
    {
      "epoch": 1.4026770775237032,
      "grad_norm": 0.000665874220430851,
      "learning_rate": 1.0654396728016361e-05,
      "loss": 0.0142,
      "step": 25150
    },
    {
      "epoch": 1.4054656999442274,
      "grad_norm": 0.001745537854731083,
      "learning_rate": 1.0635805911879533e-05,
      "loss": 0.0319,
      "step": 25200
    },
    {
      "epoch": 1.4082543223647517,
      "grad_norm": 0.0010124628897756338,
      "learning_rate": 1.0617215095742704e-05,
      "loss": 0.0005,
      "step": 25250
    },
    {
      "epoch": 1.4110429447852761,
      "grad_norm": 0.0006555096479132771,
      "learning_rate": 1.0598624279605875e-05,
      "loss": 0.0001,
      "step": 25300
    },
    {
      "epoch": 1.4138315672058004,
      "grad_norm": 0.0006254228064790368,
      "learning_rate": 1.0580033463469048e-05,
      "loss": 0.0,
      "step": 25350
    },
    {
      "epoch": 1.4166201896263246,
      "grad_norm": 0.0008284854702651501,
      "learning_rate": 1.0561442647332218e-05,
      "loss": 0.0119,
      "step": 25400
    },
    {
      "epoch": 1.4194088120468489,
      "grad_norm": 0.0013472350547090173,
      "learning_rate": 1.054285183119539e-05,
      "loss": 0.0419,
      "step": 25450
    },
    {
      "epoch": 1.4221974344673731,
      "grad_norm": 0.0008623765897937119,
      "learning_rate": 1.052426101505856e-05,
      "loss": 0.0032,
      "step": 25500
    },
    {
      "epoch": 1.4249860568878974,
      "grad_norm": 0.0007304093451239169,
      "learning_rate": 1.0505670198921733e-05,
      "loss": 0.0002,
      "step": 25550
    },
    {
      "epoch": 1.4277746793084216,
      "grad_norm": 0.0019974918104708195,
      "learning_rate": 1.0487079382784906e-05,
      "loss": 0.0001,
      "step": 25600
    },
    {
      "epoch": 1.4305633017289459,
      "grad_norm": 0.0005989602650515735,
      "learning_rate": 1.0468488566648076e-05,
      "loss": 0.0,
      "step": 25650
    },
    {
      "epoch": 1.43335192414947,
      "grad_norm": 0.0005363895324990153,
      "learning_rate": 1.0449897750511249e-05,
      "loss": 0.0185,
      "step": 25700
    },
    {
      "epoch": 1.4361405465699943,
      "grad_norm": 0.0024858058895915747,
      "learning_rate": 1.0431306934374419e-05,
      "loss": 0.0388,
      "step": 25750
    },
    {
      "epoch": 1.4389291689905188,
      "grad_norm": 0.0015888214111328125,
      "learning_rate": 1.0412716118237592e-05,
      "loss": 0.0062,
      "step": 25800
    },
    {
      "epoch": 1.441717791411043,
      "grad_norm": 0.0018843087600544095,
      "learning_rate": 1.0394125302100765e-05,
      "loss": 0.023,
      "step": 25850
    },
    {
      "epoch": 1.4445064138315673,
      "grad_norm": 0.0014239194570109248,
      "learning_rate": 1.0375534485963934e-05,
      "loss": 0.0394,
      "step": 25900
    },
    {
      "epoch": 1.4472950362520915,
      "grad_norm": 0.007469070143997669,
      "learning_rate": 1.0356943669827107e-05,
      "loss": 0.0296,
      "step": 25950
    },
    {
      "epoch": 1.4500836586726158,
      "grad_norm": 0.00437009846791625,
      "learning_rate": 1.0338352853690278e-05,
      "loss": 0.0002,
      "step": 26000
    },
    {
      "epoch": 1.45287228109314,
      "grad_norm": 0.003772202879190445,
      "learning_rate": 1.031976203755345e-05,
      "loss": 0.0272,
      "step": 26050
    },
    {
      "epoch": 1.4556609035136643,
      "grad_norm": 0.002128124237060547,
      "learning_rate": 1.0301171221416621e-05,
      "loss": 0.0002,
      "step": 26100
    },
    {
      "epoch": 1.4584495259341885,
      "grad_norm": 0.0018006851896643639,
      "learning_rate": 1.0282580405279792e-05,
      "loss": 0.0002,
      "step": 26150
    },
    {
      "epoch": 1.4612381483547128,
      "grad_norm": 0.002040616236627102,
      "learning_rate": 1.0263989589142964e-05,
      "loss": 0.0001,
      "step": 26200
    },
    {
      "epoch": 1.464026770775237,
      "grad_norm": 0.0015086580533534288,
      "learning_rate": 1.0245398773006137e-05,
      "loss": 0.0001,
      "step": 26250
    },
    {
      "epoch": 1.4668153931957613,
      "grad_norm": 0.0012834850931540132,
      "learning_rate": 1.0226807956869306e-05,
      "loss": 0.0001,
      "step": 26300
    },
    {
      "epoch": 1.4696040156162855,
      "grad_norm": 0.0014541097916662693,
      "learning_rate": 1.020821714073248e-05,
      "loss": 0.0003,
      "step": 26350
    },
    {
      "epoch": 1.4723926380368098,
      "grad_norm": 0.0012846775352954865,
      "learning_rate": 1.0189626324595649e-05,
      "loss": 0.0001,
      "step": 26400
    },
    {
      "epoch": 1.475181260457334,
      "grad_norm": 0.0010132959578186274,
      "learning_rate": 1.0171035508458822e-05,
      "loss": 0.0,
      "step": 26450
    },
    {
      "epoch": 1.4779698828778582,
      "grad_norm": 0.0017242684261873364,
      "learning_rate": 1.0152444692321995e-05,
      "loss": 0.0263,
      "step": 26500
    },
    {
      "epoch": 1.4807585052983825,
      "grad_norm": 0.002972470596432686,
      "learning_rate": 1.0133853876185164e-05,
      "loss": 0.0268,
      "step": 26550
    },
    {
      "epoch": 1.4835471277189067,
      "grad_norm": 0.015463229268789291,
      "learning_rate": 1.0115263060048337e-05,
      "loss": 0.0183,
      "step": 26600
    },
    {
      "epoch": 1.4863357501394312,
      "grad_norm": 0.0020505497232079506,
      "learning_rate": 1.0096672243911509e-05,
      "loss": 0.0106,
      "step": 26650
    },
    {
      "epoch": 1.4891243725599554,
      "grad_norm": 0.005689941346645355,
      "learning_rate": 1.007808142777468e-05,
      "loss": 0.0238,
      "step": 26700
    },
    {
      "epoch": 1.4919129949804797,
      "grad_norm": 0.00396758271381259,
      "learning_rate": 1.0059490611637851e-05,
      "loss": 0.0354,
      "step": 26750
    },
    {
      "epoch": 1.494701617401004,
      "grad_norm": 0.002153088105842471,
      "learning_rate": 1.0040899795501023e-05,
      "loss": 0.0008,
      "step": 26800
    },
    {
      "epoch": 1.4974902398215282,
      "grad_norm": 0.0022162101231515408,
      "learning_rate": 1.0022308979364196e-05,
      "loss": 0.0004,
      "step": 26850
    },
    {
      "epoch": 1.5002788622420524,
      "grad_norm": 0.0013151256134733558,
      "learning_rate": 1.0003718163227367e-05,
      "loss": 0.0001,
      "step": 26900
    },
    {
      "epoch": 1.5030674846625767,
      "grad_norm": 0.001671697129495442,
      "learning_rate": 9.985127347090538e-06,
      "loss": 0.0001,
      "step": 26950
    },
    {
      "epoch": 1.505856107083101,
      "grad_norm": 0.0013849545503035188,
      "learning_rate": 9.96653653095371e-06,
      "loss": 0.055,
      "step": 27000
    },
    {
      "epoch": 1.5086447295036252,
      "grad_norm": 0.0024942110758274794,
      "learning_rate": 9.94794571481688e-06,
      "loss": 0.0003,
      "step": 27050
    },
    {
      "epoch": 1.5114333519241496,
      "grad_norm": 0.0010219522519037127,
      "learning_rate": 9.929354898680052e-06,
      "loss": 0.0284,
      "step": 27100
    },
    {
      "epoch": 1.5142219743446739,
      "grad_norm": 0.0011898367665708065,
      "learning_rate": 9.910764082543225e-06,
      "loss": 0.0213,
      "step": 27150
    },
    {
      "epoch": 1.5170105967651981,
      "grad_norm": 0.000984802027232945,
      "learning_rate": 9.892173266406396e-06,
      "loss": 0.0124,
      "step": 27200
    },
    {
      "epoch": 1.5197992191857224,
      "grad_norm": 0.0012464842293411493,
      "learning_rate": 9.873582450269568e-06,
      "loss": 0.0048,
      "step": 27250
    },
    {
      "epoch": 1.5225878416062466,
      "grad_norm": 0.001249205437488854,
      "learning_rate": 9.854991634132739e-06,
      "loss": 0.0173,
      "step": 27300
    },
    {
      "epoch": 1.5253764640267709,
      "grad_norm": 0.0008047797600738704,
      "learning_rate": 9.83640081799591e-06,
      "loss": 0.0001,
      "step": 27350
    },
    {
      "epoch": 1.528165086447295,
      "grad_norm": 0.011761358939111233,
      "learning_rate": 9.817810001859083e-06,
      "loss": 0.0226,
      "step": 27400
    },
    {
      "epoch": 1.5309537088678193,
      "grad_norm": 0.006499097216874361,
      "learning_rate": 9.799219185722255e-06,
      "loss": 0.0001,
      "step": 27450
    },
    {
      "epoch": 1.5337423312883436,
      "grad_norm": 0.003208903595805168,
      "learning_rate": 9.780628369585426e-06,
      "loss": 0.0144,
      "step": 27500
    },
    {
      "epoch": 1.5365309537088678,
      "grad_norm": 0.2365325689315796,
      "learning_rate": 9.762037553448597e-06,
      "loss": 0.014,
      "step": 27550
    },
    {
      "epoch": 1.539319576129392,
      "grad_norm": 0.0006938445148989558,
      "learning_rate": 9.743446737311768e-06,
      "loss": 0.0007,
      "step": 27600
    },
    {
      "epoch": 1.5421081985499163,
      "grad_norm": 0.0006195628666318953,
      "learning_rate": 9.72485592117494e-06,
      "loss": 0.0,
      "step": 27650
    },
    {
      "epoch": 1.5448968209704406,
      "grad_norm": 0.0008175857365131378,
      "learning_rate": 9.706265105038111e-06,
      "loss": 0.013,
      "step": 27700
    },
    {
      "epoch": 1.5476854433909648,
      "grad_norm": 0.005141252186149359,
      "learning_rate": 9.687674288901282e-06,
      "loss": 0.0161,
      "step": 27750
    },
    {
      "epoch": 1.550474065811489,
      "grad_norm": 0.009927636943757534,
      "learning_rate": 9.669083472764455e-06,
      "loss": 0.0002,
      "step": 27800
    },
    {
      "epoch": 1.5532626882320133,
      "grad_norm": 0.0005696896114386618,
      "learning_rate": 9.650492656627627e-06,
      "loss": 0.02,
      "step": 27850
    },
    {
      "epoch": 1.5560513106525375,
      "grad_norm": 0.001437351806089282,
      "learning_rate": 9.631901840490798e-06,
      "loss": 0.0001,
      "step": 27900
    },
    {
      "epoch": 1.5588399330730618,
      "grad_norm": 0.0006102855550125241,
      "learning_rate": 9.61331102435397e-06,
      "loss": 0.0152,
      "step": 27950
    },
    {
      "epoch": 1.561628555493586,
      "grad_norm": 0.0005324583034962416,
      "learning_rate": 9.594720208217142e-06,
      "loss": 0.0195,
      "step": 28000
    },
    {
      "epoch": 1.5644171779141103,
      "grad_norm": 0.0007064021192491055,
      "learning_rate": 9.576129392080314e-06,
      "loss": 0.0001,
      "step": 28050
    },
    {
      "epoch": 1.5672058003346345,
      "grad_norm": 0.0005282154306769371,
      "learning_rate": 9.557538575943485e-06,
      "loss": 0.0001,
      "step": 28100
    },
    {
      "epoch": 1.569994422755159,
      "grad_norm": 0.0005827907007187605,
      "learning_rate": 9.538947759806656e-06,
      "loss": 0.0162,
      "step": 28150
    },
    {
      "epoch": 1.5727830451756832,
      "grad_norm": 0.0005659449961967766,
      "learning_rate": 9.520356943669829e-06,
      "loss": 0.0,
      "step": 28200
    },
    {
      "epoch": 1.5755716675962075,
      "grad_norm": 0.0004945661639794707,
      "learning_rate": 9.502137943855736e-06,
      "loss": 0.0057,
      "step": 28250
    },
    {
      "epoch": 1.5783602900167317,
      "grad_norm": 0.0006153939175419509,
      "learning_rate": 9.483547127718908e-06,
      "loss": 0.0,
      "step": 28300
    },
    {
      "epoch": 1.581148912437256,
      "grad_norm": 0.0005129656638018787,
      "learning_rate": 9.464956311582079e-06,
      "loss": 0.0001,
      "step": 28350
    },
    {
      "epoch": 1.5839375348577802,
      "grad_norm": 0.0004482818767428398,
      "learning_rate": 9.44636549544525e-06,
      "loss": 0.0003,
      "step": 28400
    },
    {
      "epoch": 1.5867261572783047,
      "grad_norm": 0.0004398529708851129,
      "learning_rate": 9.427774679308422e-06,
      "loss": 0.0,
      "step": 28450
    },
    {
      "epoch": 1.589514779698829,
      "grad_norm": 0.0004403707280289382,
      "learning_rate": 9.409183863171595e-06,
      "loss": 0.0,
      "step": 28500
    },
    {
      "epoch": 1.5923034021193532,
      "grad_norm": 0.0004453449510037899,
      "learning_rate": 9.390593047034766e-06,
      "loss": 0.0,
      "step": 28550
    },
    {
      "epoch": 1.5950920245398774,
      "grad_norm": 0.0006405048188753426,
      "learning_rate": 9.372002230897937e-06,
      "loss": 0.0184,
      "step": 28600
    },
    {
      "epoch": 1.5978806469604017,
      "grad_norm": 0.00044101226376369596,
      "learning_rate": 9.353783231083844e-06,
      "loss": 0.0045,
      "step": 28650
    },
    {
      "epoch": 1.600669269380926,
      "grad_norm": 0.0005474544013850391,
      "learning_rate": 9.335192414947017e-06,
      "loss": 0.0379,
      "step": 28700
    },
    {
      "epoch": 1.6034578918014502,
      "grad_norm": 2.691413164138794,
      "learning_rate": 9.316601598810189e-06,
      "loss": 0.0046,
      "step": 28750
    },
    {
      "epoch": 1.6062465142219744,
      "grad_norm": 0.0004444835940375924,
      "learning_rate": 9.29801078267336e-06,
      "loss": 0.0001,
      "step": 28800
    },
    {
      "epoch": 1.6090351366424986,
      "grad_norm": 0.0004714303067885339,
      "learning_rate": 9.279419966536531e-06,
      "loss": 0.0001,
      "step": 28850
    },
    {
      "epoch": 1.6118237590630229,
      "grad_norm": 0.0004458954790607095,
      "learning_rate": 9.260829150399703e-06,
      "loss": 0.0079,
      "step": 28900
    },
    {
      "epoch": 1.6146123814835471,
      "grad_norm": 0.0007383867632597685,
      "learning_rate": 9.242238334262876e-06,
      "loss": 0.0234,
      "step": 28950
    },
    {
      "epoch": 1.6174010039040714,
      "grad_norm": 0.01593937911093235,
      "learning_rate": 9.223647518126047e-06,
      "loss": 0.0342,
      "step": 29000
    },
    {
      "epoch": 1.6201896263245956,
      "grad_norm": 0.0024723794776946306,
      "learning_rate": 9.205056701989218e-06,
      "loss": 0.0119,
      "step": 29050
    },
    {
      "epoch": 1.6229782487451199,
      "grad_norm": 0.001125209266319871,
      "learning_rate": 9.18646588585239e-06,
      "loss": 0.0393,
      "step": 29100
    },
    {
      "epoch": 1.6257668711656441,
      "grad_norm": 0.001151147997006774,
      "learning_rate": 9.167875069715562e-06,
      "loss": 0.0007,
      "step": 29150
    },
    {
      "epoch": 1.6285554935861684,
      "grad_norm": 0.0005297994357533753,
      "learning_rate": 9.149284253578734e-06,
      "loss": 0.0003,
      "step": 29200
    },
    {
      "epoch": 1.6313441160066926,
      "grad_norm": 0.0005907501908950508,
      "learning_rate": 9.130693437441905e-06,
      "loss": 0.0351,
      "step": 29250
    },
    {
      "epoch": 1.6341327384272168,
      "grad_norm": 0.0014636170817539096,
      "learning_rate": 9.112102621305076e-06,
      "loss": 0.0002,
      "step": 29300
    },
    {
      "epoch": 1.636921360847741,
      "grad_norm": 0.009814715012907982,
      "learning_rate": 9.093511805168248e-06,
      "loss": 0.0001,
      "step": 29350
    },
    {
      "epoch": 1.6397099832682653,
      "grad_norm": 0.0005339666968211532,
      "learning_rate": 9.074920989031419e-06,
      "loss": 0.0001,
      "step": 29400
    },
    {
      "epoch": 1.6424986056887896,
      "grad_norm": 0.050821807235479355,
      "learning_rate": 9.05633017289459e-06,
      "loss": 0.0002,
      "step": 29450
    },
    {
      "epoch": 1.645287228109314,
      "grad_norm": 0.014501042664051056,
      "learning_rate": 9.037739356757762e-06,
      "loss": 0.0094,
      "step": 29500
    },
    {
      "epoch": 1.6480758505298383,
      "grad_norm": 0.0008468165178783238,
      "learning_rate": 9.019148540620935e-06,
      "loss": 0.0001,
      "step": 29550
    },
    {
      "epoch": 1.6508644729503625,
      "grad_norm": 0.001667591743171215,
      "learning_rate": 9.000557724484106e-06,
      "loss": 0.0205,
      "step": 29600
    },
    {
      "epoch": 1.6536530953708868,
      "grad_norm": 0.02176329307258129,
      "learning_rate": 8.981966908347277e-06,
      "loss": 0.0638,
      "step": 29650
    },
    {
      "epoch": 1.656441717791411,
      "grad_norm": 0.008023686707019806,
      "learning_rate": 8.963376092210448e-06,
      "loss": 0.0008,
      "step": 29700
    },
    {
      "epoch": 1.6592303402119353,
      "grad_norm": 0.0013733975356444716,
      "learning_rate": 8.944785276073621e-06,
      "loss": 0.0001,
      "step": 29750
    },
    {
      "epoch": 1.6620189626324595,
      "grad_norm": 0.027413373813033104,
      "learning_rate": 8.926194459936793e-06,
      "loss": 0.0152,
      "step": 29800
    },
    {
      "epoch": 1.664807585052984,
      "grad_norm": 0.0010284445015713573,
      "learning_rate": 8.907603643799964e-06,
      "loss": 0.0002,
      "step": 29850
    },
    {
      "epoch": 1.6675962074735082,
      "grad_norm": 0.0008293065475299954,
      "learning_rate": 8.889012827663135e-06,
      "loss": 0.0286,
      "step": 29900
    },
    {
      "epoch": 1.6703848298940325,
      "grad_norm": 0.0006622159853577614,
      "learning_rate": 8.870422011526307e-06,
      "loss": 0.013,
      "step": 29950
    },
    {
      "epoch": 1.6731734523145567,
      "grad_norm": 0.0031371591612696648,
      "learning_rate": 8.851831195389478e-06,
      "loss": 0.0228,
      "step": 30000
    },
    {
      "epoch": 1.675962074735081,
      "grad_norm": 0.0008021935354918242,
      "learning_rate": 8.83324037925265e-06,
      "loss": 0.0157,
      "step": 30050
    },
    {
      "epoch": 1.6787506971556052,
      "grad_norm": 0.0006593894795514643,
      "learning_rate": 8.81464956311582e-06,
      "loss": 0.0001,
      "step": 30100
    },
    {
      "epoch": 1.6815393195761295,
      "grad_norm": 0.0018364638090133667,
      "learning_rate": 8.796058746978993e-06,
      "loss": 0.0464,
      "step": 30150
    },
    {
      "epoch": 1.6843279419966537,
      "grad_norm": 0.001722122891806066,
      "learning_rate": 8.777467930842165e-06,
      "loss": 0.0004,
      "step": 30200
    },
    {
      "epoch": 1.687116564417178,
      "grad_norm": 0.0015275669284164906,
      "learning_rate": 8.758877114705336e-06,
      "loss": 0.0015,
      "step": 30250
    },
    {
      "epoch": 1.6899051868377022,
      "grad_norm": 0.0011708632810041308,
      "learning_rate": 8.740286298568507e-06,
      "loss": 0.0001,
      "step": 30300
    },
    {
      "epoch": 1.6926938092582264,
      "grad_norm": 0.001040558679960668,
      "learning_rate": 8.721695482431679e-06,
      "loss": 0.0451,
      "step": 30350
    },
    {
      "epoch": 1.6954824316787507,
      "grad_norm": 0.001887282240204513,
      "learning_rate": 8.703104666294852e-06,
      "loss": 0.0088,
      "step": 30400
    },
    {
      "epoch": 1.698271054099275,
      "grad_norm": 0.0011470429599285126,
      "learning_rate": 8.684513850158023e-06,
      "loss": 0.0001,
      "step": 30450
    },
    {
      "epoch": 1.7010596765197992,
      "grad_norm": 0.0008681699982844293,
      "learning_rate": 8.665923034021194e-06,
      "loss": 0.0003,
      "step": 30500
    },
    {
      "epoch": 1.7038482989403234,
      "grad_norm": 1.231070876121521,
      "learning_rate": 8.647332217884366e-06,
      "loss": 0.0001,
      "step": 30550
    },
    {
      "epoch": 1.7066369213608477,
      "grad_norm": 0.0007475933525711298,
      "learning_rate": 8.628741401747539e-06,
      "loss": 0.0001,
      "step": 30600
    },
    {
      "epoch": 1.709425543781372,
      "grad_norm": 0.001520209014415741,
      "learning_rate": 8.61015058561071e-06,
      "loss": 0.0001,
      "step": 30650
    },
    {
      "epoch": 1.7122141662018961,
      "grad_norm": 0.0007176943472586572,
      "learning_rate": 8.591559769473881e-06,
      "loss": 0.0001,
      "step": 30700
    },
    {
      "epoch": 1.7150027886224204,
      "grad_norm": 0.0006211430882103741,
      "learning_rate": 8.572968953337052e-06,
      "loss": 0.0225,
      "step": 30750
    },
    {
      "epoch": 1.7177914110429446,
      "grad_norm": 0.00056423683417961,
      "learning_rate": 8.554378137200224e-06,
      "loss": 0.0002,
      "step": 30800
    },
    {
      "epoch": 1.7205800334634689,
      "grad_norm": 0.000639965757727623,
      "learning_rate": 8.535787321063395e-06,
      "loss": 0.0,
      "step": 30850
    },
    {
      "epoch": 1.7233686558839934,
      "grad_norm": 0.004787619225680828,
      "learning_rate": 8.517196504926566e-06,
      "loss": 0.0,
      "step": 30900
    },
    {
      "epoch": 1.7261572783045176,
      "grad_norm": 0.0005025033606216311,
      "learning_rate": 8.498605688789738e-06,
      "loss": 0.0001,
      "step": 30950
    },
    {
      "epoch": 1.7289459007250418,
      "grad_norm": 0.0005276009324006736,
      "learning_rate": 8.480014872652909e-06,
      "loss": 0.0,
      "step": 31000
    },
    {
      "epoch": 1.731734523145566,
      "grad_norm": 1.3640223741531372,
      "learning_rate": 8.461424056516082e-06,
      "loss": 0.0195,
      "step": 31050
    },
    {
      "epoch": 1.7345231455660903,
      "grad_norm": 0.0005411356105469167,
      "learning_rate": 8.442833240379253e-06,
      "loss": 0.0001,
      "step": 31100
    },
    {
      "epoch": 1.7373117679866146,
      "grad_norm": 0.0004899565246887505,
      "learning_rate": 8.424242424242425e-06,
      "loss": 0.0,
      "step": 31150
    },
    {
      "epoch": 1.7401003904071388,
      "grad_norm": 0.000506879179738462,
      "learning_rate": 8.406023424428333e-06,
      "loss": 0.0068,
      "step": 31200
    },
    {
      "epoch": 1.7428890128276633,
      "grad_norm": 0.0006922039901837707,
      "learning_rate": 8.387432608291505e-06,
      "loss": 0.0001,
      "step": 31250
    },
    {
      "epoch": 1.7456776352481875,
      "grad_norm": 0.0004969442961737514,
      "learning_rate": 8.368841792154676e-06,
      "loss": 0.0043,
      "step": 31300
    },
    {
      "epoch": 1.7484662576687118,
      "grad_norm": 0.00045194808626547456,
      "learning_rate": 8.350250976017847e-06,
      "loss": 0.0199,
      "step": 31350
    },
    {
      "epoch": 1.751254880089236,
      "grad_norm": 0.0005028328159824014,
      "learning_rate": 8.33166015988102e-06,
      "loss": 0.0185,
      "step": 31400
    },
    {
      "epoch": 1.7540435025097603,
      "grad_norm": 51.34001159667969,
      "learning_rate": 8.313069343744192e-06,
      "loss": 0.0228,
      "step": 31450
    },
    {
      "epoch": 1.7568321249302845,
      "grad_norm": 0.00040559351327829063,
      "learning_rate": 8.294478527607363e-06,
      "loss": 0.0002,
      "step": 31500
    },
    {
      "epoch": 1.7596207473508088,
      "grad_norm": 0.0061482940800487995,
      "learning_rate": 8.275887711470534e-06,
      "loss": 0.0001,
      "step": 31550
    },
    {
      "epoch": 1.762409369771333,
      "grad_norm": 0.0004514515749178827,
      "learning_rate": 8.257296895333706e-06,
      "loss": 0.0001,
      "step": 31600
    },
    {
      "epoch": 1.7651979921918572,
      "grad_norm": 0.0004351057286839932,
      "learning_rate": 8.238706079196877e-06,
      "loss": 0.0,
      "step": 31650
    },
    {
      "epoch": 1.7679866146123815,
      "grad_norm": 0.0004817044537048787,
      "learning_rate": 8.220115263060048e-06,
      "loss": 0.0107,
      "step": 31700
    },
    {
      "epoch": 1.7707752370329057,
      "grad_norm": 0.006663717329502106,
      "learning_rate": 8.20152444692322e-06,
      "loss": 0.0151,
      "step": 31750
    },
    {
      "epoch": 1.77356385945343,
      "grad_norm": 0.00044326085480861366,
      "learning_rate": 8.182933630786392e-06,
      "loss": 0.0001,
      "step": 31800
    },
    {
      "epoch": 1.7763524818739542,
      "grad_norm": 0.025718124583363533,
      "learning_rate": 8.164342814649564e-06,
      "loss": 0.0001,
      "step": 31850
    },
    {
      "epoch": 1.7791411042944785,
      "grad_norm": 0.001009250758215785,
      "learning_rate": 8.145751998512735e-06,
      "loss": 0.0,
      "step": 31900
    },
    {
      "epoch": 1.7819297267150027,
      "grad_norm": 0.00038898817729204893,
      "learning_rate": 8.127161182375906e-06,
      "loss": 0.0127,
      "step": 31950
    },
    {
      "epoch": 1.784718349135527,
      "grad_norm": 0.0006318935775198042,
      "learning_rate": 8.108570366239078e-06,
      "loss": 0.0012,
      "step": 32000
    },
    {
      "epoch": 1.7875069715560512,
      "grad_norm": 0.013224964961409569,
      "learning_rate": 8.08997955010225e-06,
      "loss": 0.0268,
      "step": 32050
    },
    {
      "epoch": 1.7902955939765755,
      "grad_norm": 0.0021344698034226894,
      "learning_rate": 8.071388733965422e-06,
      "loss": 0.0001,
      "step": 32100
    },
    {
      "epoch": 1.7930842163970997,
      "grad_norm": 17.061017990112305,
      "learning_rate": 8.052797917828593e-06,
      "loss": 0.0302,
      "step": 32150
    },
    {
      "epoch": 1.795872838817624,
      "grad_norm": 0.0005291542038321495,
      "learning_rate": 8.034207101691765e-06,
      "loss": 0.0119,
      "step": 32200
    },
    {
      "epoch": 1.7986614612381484,
      "grad_norm": 0.04627210646867752,
      "learning_rate": 8.015616285554938e-06,
      "loss": 0.0001,
      "step": 32250
    },
    {
      "epoch": 1.8014500836586727,
      "grad_norm": 0.005424774717539549,
      "learning_rate": 7.997025469418109e-06,
      "loss": 0.0001,
      "step": 32300
    },
    {
      "epoch": 1.804238706079197,
      "grad_norm": 133.63577270507812,
      "learning_rate": 7.97843465328128e-06,
      "loss": 0.0281,
      "step": 32350
    },
    {
      "epoch": 1.8070273284997211,
      "grad_norm": 0.00044349775998853147,
      "learning_rate": 7.959843837144451e-06,
      "loss": 0.0001,
      "step": 32400
    },
    {
      "epoch": 1.8098159509202454,
      "grad_norm": 0.01087948214262724,
      "learning_rate": 7.941253021007623e-06,
      "loss": 0.0142,
      "step": 32450
    },
    {
      "epoch": 1.8126045733407696,
      "grad_norm": 0.0004920600331388414,
      "learning_rate": 7.922662204870794e-06,
      "loss": 0.0001,
      "step": 32500
    },
    {
      "epoch": 1.8153931957612939,
      "grad_norm": 0.001426328788511455,
      "learning_rate": 7.904071388733965e-06,
      "loss": 0.0,
      "step": 32550
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.0004649490292649716,
      "learning_rate": 7.885480572597137e-06,
      "loss": 0.0001,
      "step": 32600
    },
    {
      "epoch": 1.8209704406023426,
      "grad_norm": 0.00029000837821513414,
      "learning_rate": 7.86688975646031e-06,
      "loss": 0.0,
      "step": 32650
    },
    {
      "epoch": 1.8237590630228668,
      "grad_norm": 0.0003437093982938677,
      "learning_rate": 7.848298940323481e-06,
      "loss": 0.0149,
      "step": 32700
    },
    {
      "epoch": 1.826547685443391,
      "grad_norm": 0.0003538672171998769,
      "learning_rate": 7.829708124186652e-06,
      "loss": 0.0,
      "step": 32750
    },
    {
      "epoch": 1.8293363078639153,
      "grad_norm": 0.00036764272954314947,
      "learning_rate": 7.811117308049823e-06,
      "loss": 0.0,
      "step": 32800
    },
    {
      "epoch": 1.8321249302844396,
      "grad_norm": 0.0014038827503100038,
      "learning_rate": 7.792526491912996e-06,
      "loss": 0.0001,
      "step": 32850
    },
    {
      "epoch": 1.8349135527049638,
      "grad_norm": 0.0003847587504424155,
      "learning_rate": 7.773935675776168e-06,
      "loss": 0.0,
      "step": 32900
    },
    {
      "epoch": 1.837702175125488,
      "grad_norm": 0.00041084858821704984,
      "learning_rate": 7.755344859639339e-06,
      "loss": 0.045,
      "step": 32950
    },
    {
      "epoch": 1.8404907975460123,
      "grad_norm": 0.0003984647337347269,
      "learning_rate": 7.73675404350251e-06,
      "loss": 0.0001,
      "step": 33000
    },
    {
      "epoch": 1.8432794199665365,
      "grad_norm": 0.08532432466745377,
      "learning_rate": 7.718163227365682e-06,
      "loss": 0.0008,
      "step": 33050
    },
    {
      "epoch": 1.8460680423870608,
      "grad_norm": 0.00035918920184485614,
      "learning_rate": 7.699572411228855e-06,
      "loss": 0.0001,
      "step": 33100
    },
    {
      "epoch": 1.848856664807585,
      "grad_norm": 0.0003535425057634711,
      "learning_rate": 7.680981595092026e-06,
      "loss": 0.0001,
      "step": 33150
    },
    {
      "epoch": 1.8516452872281093,
      "grad_norm": 0.00030990500818006694,
      "learning_rate": 7.662390778955197e-06,
      "loss": 0.0,
      "step": 33200
    },
    {
      "epoch": 1.8544339096486335,
      "grad_norm": 0.00030503032030537724,
      "learning_rate": 7.643799962818369e-06,
      "loss": 0.0089,
      "step": 33250
    },
    {
      "epoch": 1.8572225320691578,
      "grad_norm": 0.0002905402798205614,
      "learning_rate": 7.625209146681541e-06,
      "loss": 0.0242,
      "step": 33300
    },
    {
      "epoch": 1.860011154489682,
      "grad_norm": 0.0003505055501591414,
      "learning_rate": 7.606618330544712e-06,
      "loss": 0.0051,
      "step": 33350
    },
    {
      "epoch": 1.8627997769102063,
      "grad_norm": 28.535751342773438,
      "learning_rate": 7.588027514407883e-06,
      "loss": 0.0112,
      "step": 33400
    },
    {
      "epoch": 1.8655883993307305,
      "grad_norm": 0.0003060176968574524,
      "learning_rate": 7.569436698271055e-06,
      "loss": 0.0001,
      "step": 33450
    },
    {
      "epoch": 1.8683770217512548,
      "grad_norm": 0.001824172679334879,
      "learning_rate": 7.550845882134227e-06,
      "loss": 0.0001,
      "step": 33500
    },
    {
      "epoch": 1.871165644171779,
      "grad_norm": 0.0005530064227059484,
      "learning_rate": 7.532255065997398e-06,
      "loss": 0.0302,
      "step": 33550
    },
    {
      "epoch": 1.8739542665923032,
      "grad_norm": 0.000640717102214694,
      "learning_rate": 7.513664249860569e-06,
      "loss": 0.0001,
      "step": 33600
    },
    {
      "epoch": 1.8767428890128277,
      "grad_norm": 0.0005801200168207288,
      "learning_rate": 7.495073433723741e-06,
      "loss": 0.0001,
      "step": 33650
    },
    {
      "epoch": 1.879531511433352,
      "grad_norm": 0.0003837696276605129,
      "learning_rate": 7.476482617586913e-06,
      "loss": 0.0,
      "step": 33700
    },
    {
      "epoch": 1.8823201338538762,
      "grad_norm": 0.0004005859373137355,
      "learning_rate": 7.457891801450085e-06,
      "loss": 0.0,
      "step": 33750
    },
    {
      "epoch": 1.8851087562744004,
      "grad_norm": 0.0035015239845961332,
      "learning_rate": 7.439300985313256e-06,
      "loss": 0.0278,
      "step": 33800
    },
    {
      "epoch": 1.8878973786949247,
      "grad_norm": 0.0009447128395549953,
      "learning_rate": 7.4207101691764275e-06,
      "loss": 0.0001,
      "step": 33850
    },
    {
      "epoch": 1.890686001115449,
      "grad_norm": 0.0012355610961094499,
      "learning_rate": 7.402119353039599e-06,
      "loss": 0.0001,
      "step": 33900
    },
    {
      "epoch": 1.8934746235359732,
      "grad_norm": 0.0010478694457560778,
      "learning_rate": 7.383528536902771e-06,
      "loss": 0.0,
      "step": 33950
    },
    {
      "epoch": 1.8962632459564976,
      "grad_norm": 0.0011257980950176716,
      "learning_rate": 7.364937720765942e-06,
      "loss": 0.0318,
      "step": 34000
    },
    {
      "epoch": 1.899051868377022,
      "grad_norm": 0.0014244487974792719,
      "learning_rate": 7.3463469046291136e-06,
      "loss": 0.0332,
      "step": 34050
    },
    {
      "epoch": 1.9018404907975461,
      "grad_norm": 0.0051447427831590176,
      "learning_rate": 7.327756088492285e-06,
      "loss": 0.0448,
      "step": 34100
    },
    {
      "epoch": 1.9046291132180704,
      "grad_norm": 0.0024395280051976442,
      "learning_rate": 7.309165272355457e-06,
      "loss": 0.0119,
      "step": 34150
    },
    {
      "epoch": 1.9074177356385946,
      "grad_norm": 0.0020069978199899197,
      "learning_rate": 7.290574456218628e-06,
      "loss": 0.0002,
      "step": 34200
    },
    {
      "epoch": 1.9102063580591189,
      "grad_norm": 0.0017684914637356997,
      "learning_rate": 7.2719836400818e-06,
      "loss": 0.0002,
      "step": 34250
    },
    {
      "epoch": 1.9129949804796431,
      "grad_norm": 0.0009169558179564774,
      "learning_rate": 7.253392823944972e-06,
      "loss": 0.0001,
      "step": 34300
    },
    {
      "epoch": 1.9157836029001674,
      "grad_norm": 0.06247234717011452,
      "learning_rate": 7.234802007808144e-06,
      "loss": 0.0159,
      "step": 34350
    },
    {
      "epoch": 1.9185722253206916,
      "grad_norm": 0.0007861684425733984,
      "learning_rate": 7.216211191671315e-06,
      "loss": 0.0001,
      "step": 34400
    },
    {
      "epoch": 1.9213608477412158,
      "grad_norm": 0.0012216256000101566,
      "learning_rate": 7.1976203755344865e-06,
      "loss": 0.0086,
      "step": 34450
    },
    {
      "epoch": 1.92414947016174,
      "grad_norm": 0.0007768923533149064,
      "learning_rate": 7.179029559397658e-06,
      "loss": 0.0,
      "step": 34500
    },
    {
      "epoch": 1.9269380925822643,
      "grad_norm": 0.0010122238891199231,
      "learning_rate": 7.16043874326083e-06,
      "loss": 0.009,
      "step": 34550
    },
    {
      "epoch": 1.9297267150027886,
      "grad_norm": 0.0005545357125811279,
      "learning_rate": 7.141847927124001e-06,
      "loss": 0.0001,
      "step": 34600
    },
    {
      "epoch": 1.9325153374233128,
      "grad_norm": 0.002516515087336302,
      "learning_rate": 7.1232571109871725e-06,
      "loss": 0.0223,
      "step": 34650
    },
    {
      "epoch": 1.935303959843837,
      "grad_norm": 0.0038863536901772022,
      "learning_rate": 7.104666294850344e-06,
      "loss": 0.0002,
      "step": 34700
    },
    {
      "epoch": 1.9380925822643613,
      "grad_norm": 0.0007294285460375249,
      "learning_rate": 7.086075478713517e-06,
      "loss": 0.0007,
      "step": 34750
    },
    {
      "epoch": 1.9408812046848856,
      "grad_norm": 0.0005309917032718658,
      "learning_rate": 7.067484662576688e-06,
      "loss": 0.0,
      "step": 34800
    },
    {
      "epoch": 1.9436698271054098,
      "grad_norm": 0.0005295233568176627,
      "learning_rate": 7.0488938464398594e-06,
      "loss": 0.0001,
      "step": 34850
    },
    {
      "epoch": 1.946458449525934,
      "grad_norm": 0.0005366337136365473,
      "learning_rate": 7.030303030303031e-06,
      "loss": 0.0007,
      "step": 34900
    },
    {
      "epoch": 1.9492470719464583,
      "grad_norm": 0.0005869122687727213,
      "learning_rate": 7.011712214166202e-06,
      "loss": 0.0,
      "step": 34950
    },
    {
      "epoch": 1.9520356943669828,
      "grad_norm": 0.0006910996744409204,
      "learning_rate": 6.993121398029374e-06,
      "loss": 0.0366,
      "step": 35000
    },
    {
      "epoch": 1.954824316787507,
      "grad_norm": 0.0019808488432317972,
      "learning_rate": 6.9745305818925455e-06,
      "loss": 0.0001,
      "step": 35050
    },
    {
      "epoch": 1.9576129392080313,
      "grad_norm": 0.0017135859234258533,
      "learning_rate": 6.956311582078454e-06,
      "loss": 0.0308,
      "step": 35100
    },
    {
      "epoch": 1.9604015616285555,
      "grad_norm": 0.0014157238183543086,
      "learning_rate": 6.937720765941626e-06,
      "loss": 0.001,
      "step": 35150
    },
    {
      "epoch": 1.9631901840490797,
      "grad_norm": 0.0035992381162941456,
      "learning_rate": 6.919129949804797e-06,
      "loss": 0.0128,
      "step": 35200
    },
    {
      "epoch": 1.965978806469604,
      "grad_norm": 0.0008700184989720583,
      "learning_rate": 6.900539133667968e-06,
      "loss": 0.0002,
      "step": 35250
    },
    {
      "epoch": 1.9687674288901282,
      "grad_norm": 0.003525212872773409,
      "learning_rate": 6.88194831753114e-06,
      "loss": 0.0001,
      "step": 35300
    },
    {
      "epoch": 1.9715560513106527,
      "grad_norm": 0.11047317832708359,
      "learning_rate": 6.863357501394312e-06,
      "loss": 0.0001,
      "step": 35350
    },
    {
      "epoch": 1.974344673731177,
      "grad_norm": 0.0046053421683609486,
      "learning_rate": 6.844766685257483e-06,
      "loss": 0.0603,
      "step": 35400
    },
    {
      "epoch": 1.9771332961517012,
      "grad_norm": 0.0010736455442383885,
      "learning_rate": 6.826175869120655e-06,
      "loss": 0.0003,
      "step": 35450
    },
    {
      "epoch": 1.9799219185722254,
      "grad_norm": 0.005446034949272871,
      "learning_rate": 6.8075850529838265e-06,
      "loss": 0.0001,
      "step": 35500
    },
    {
      "epoch": 1.9827105409927497,
      "grad_norm": 0.08277761191129684,
      "learning_rate": 6.788994236846999e-06,
      "loss": 0.0001,
      "step": 35550
    },
    {
      "epoch": 1.985499163413274,
      "grad_norm": 0.0005997218540869653,
      "learning_rate": 6.77040342071017e-06,
      "loss": 0.0001,
      "step": 35600
    },
    {
      "epoch": 1.9882877858337982,
      "grad_norm": 0.0005743640358559787,
      "learning_rate": 6.751812604573341e-06,
      "loss": 0.0001,
      "step": 35650
    },
    {
      "epoch": 1.9910764082543224,
      "grad_norm": 0.0040617045015096664,
      "learning_rate": 6.7332217884365125e-06,
      "loss": 0.0001,
      "step": 35700
    },
    {
      "epoch": 1.9938650306748467,
      "grad_norm": 0.003763634478673339,
      "learning_rate": 6.714630972299685e-06,
      "loss": 0.0215,
      "step": 35750
    },
    {
      "epoch": 1.996653653095371,
      "grad_norm": 0.002712718676775694,
      "learning_rate": 6.696040156162856e-06,
      "loss": 0.0001,
      "step": 35800
    },
    {
      "epoch": 1.9994422755158952,
      "grad_norm": 0.010075314901769161,
      "learning_rate": 6.677449340026027e-06,
      "loss": 0.0163,
      "step": 35850
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.018412888050079346,
      "eval_runtime": 74.3629,
      "eval_samples_per_second": 482.216,
      "eval_steps_per_second": 60.285,
      "step": 35860
    },
    {
      "epoch": 2.0022308979364194,
      "grad_norm": 0.00994566734880209,
      "learning_rate": 6.6588585238891986e-06,
      "loss": 0.0044,
      "step": 35900
    },
    {
      "epoch": 2.0050195203569436,
      "grad_norm": 0.0007721675792708993,
      "learning_rate": 6.6402677077523716e-06,
      "loss": 0.0001,
      "step": 35950
    },
    {
      "epoch": 2.007808142777468,
      "grad_norm": 0.0038363649509847164,
      "learning_rate": 6.621676891615543e-06,
      "loss": 0.0001,
      "step": 36000
    },
    {
      "epoch": 2.010596765197992,
      "grad_norm": 0.00044743757462128997,
      "learning_rate": 6.603086075478714e-06,
      "loss": 0.0001,
      "step": 36050
    },
    {
      "epoch": 2.0133853876185164,
      "grad_norm": 0.0004271354991942644,
      "learning_rate": 6.5844952593418854e-06,
      "loss": 0.028,
      "step": 36100
    },
    {
      "epoch": 2.0161740100390406,
      "grad_norm": 0.0005005932762287557,
      "learning_rate": 6.565904443205057e-06,
      "loss": 0.0,
      "step": 36150
    },
    {
      "epoch": 2.018962632459565,
      "grad_norm": 0.0005183280445635319,
      "learning_rate": 6.547313627068229e-06,
      "loss": 0.0001,
      "step": 36200
    },
    {
      "epoch": 2.021751254880089,
      "grad_norm": 0.0005295909941196442,
      "learning_rate": 6.5287228109314e-06,
      "loss": 0.0103,
      "step": 36250
    },
    {
      "epoch": 2.0245398773006134,
      "grad_norm": 0.0004910599091090262,
      "learning_rate": 6.5101319947945715e-06,
      "loss": 0.0001,
      "step": 36300
    },
    {
      "epoch": 2.0273284997211376,
      "grad_norm": 0.0004821914480999112,
      "learning_rate": 6.491541178657743e-06,
      "loss": 0.0,
      "step": 36350
    },
    {
      "epoch": 2.030117122141662,
      "grad_norm": 0.0005221562460064888,
      "learning_rate": 6.472950362520916e-06,
      "loss": 0.0001,
      "step": 36400
    },
    {
      "epoch": 2.032905744562186,
      "grad_norm": 0.028053196147084236,
      "learning_rate": 6.454359546384087e-06,
      "loss": 0.018,
      "step": 36450
    },
    {
      "epoch": 2.0356943669827103,
      "grad_norm": 0.0004918835475109518,
      "learning_rate": 6.435768730247258e-06,
      "loss": 0.0002,
      "step": 36500
    },
    {
      "epoch": 2.038482989403235,
      "grad_norm": 0.0004125485720578581,
      "learning_rate": 6.41717791411043e-06,
      "loss": 0.0001,
      "step": 36550
    },
    {
      "epoch": 2.0412716118237593,
      "grad_norm": 0.013388287276029587,
      "learning_rate": 6.398587097973602e-06,
      "loss": 0.0,
      "step": 36600
    },
    {
      "epoch": 2.0440602342442835,
      "grad_norm": 0.06826151907444,
      "learning_rate": 6.379996281836773e-06,
      "loss": 0.0,
      "step": 36650
    },
    {
      "epoch": 2.0468488566648078,
      "grad_norm": 0.9133211970329285,
      "learning_rate": 6.361405465699944e-06,
      "loss": 0.0001,
      "step": 36700
    },
    {
      "epoch": 2.049637479085332,
      "grad_norm": 0.00037774688098579645,
      "learning_rate": 6.343186465885853e-06,
      "loss": 0.0069,
      "step": 36750
    },
    {
      "epoch": 2.0524261015058562,
      "grad_norm": 0.0004274350358173251,
      "learning_rate": 6.324595649749025e-06,
      "loss": 0.0,
      "step": 36800
    },
    {
      "epoch": 2.0552147239263805,
      "grad_norm": 0.0003869280044455081,
      "learning_rate": 6.306004833612196e-06,
      "loss": 0.0,
      "step": 36850
    },
    {
      "epoch": 2.0580033463469047,
      "grad_norm": 0.0004247968608979136,
      "learning_rate": 6.287414017475367e-06,
      "loss": 0.0,
      "step": 36900
    },
    {
      "epoch": 2.060791968767429,
      "grad_norm": 0.00030561580206267536,
      "learning_rate": 6.268823201338539e-06,
      "loss": 0.0,
      "step": 36950
    },
    {
      "epoch": 2.0635805911879532,
      "grad_norm": 0.00035129449679516256,
      "learning_rate": 6.250232385201711e-06,
      "loss": 0.0,
      "step": 37000
    },
    {
      "epoch": 2.0663692136084775,
      "grad_norm": 0.006160816643387079,
      "learning_rate": 6.231641569064882e-06,
      "loss": 0.0,
      "step": 37050
    },
    {
      "epoch": 2.0691578360290017,
      "grad_norm": 0.00033598169102333486,
      "learning_rate": 6.213050752928054e-06,
      "loss": 0.0,
      "step": 37100
    },
    {
      "epoch": 2.071946458449526,
      "grad_norm": 0.00035902915988117456,
      "learning_rate": 6.194459936791226e-06,
      "loss": 0.0,
      "step": 37150
    },
    {
      "epoch": 2.07473508087005,
      "grad_norm": 0.00033489687484689057,
      "learning_rate": 6.1758691206543976e-06,
      "loss": 0.0266,
      "step": 37200
    },
    {
      "epoch": 2.0775237032905745,
      "grad_norm": 0.00032319981255568564,
      "learning_rate": 6.157278304517569e-06,
      "loss": 0.0,
      "step": 37250
    },
    {
      "epoch": 2.0803123257110987,
      "grad_norm": 0.00028588337590917945,
      "learning_rate": 6.13868748838074e-06,
      "loss": 0.0001,
      "step": 37300
    },
    {
      "epoch": 2.083100948131623,
      "grad_norm": 0.0006292702746577561,
      "learning_rate": 6.1200966722439115e-06,
      "loss": 0.0,
      "step": 37350
    },
    {
      "epoch": 2.085889570552147,
      "grad_norm": 0.0002705159713514149,
      "learning_rate": 6.101505856107084e-06,
      "loss": 0.0,
      "step": 37400
    },
    {
      "epoch": 2.0886781929726714,
      "grad_norm": 0.00030111646628938615,
      "learning_rate": 6.082915039970255e-06,
      "loss": 0.0,
      "step": 37450
    },
    {
      "epoch": 2.0914668153931957,
      "grad_norm": 0.00027279264759272337,
      "learning_rate": 6.064324223833426e-06,
      "loss": 0.0107,
      "step": 37500
    },
    {
      "epoch": 2.09425543781372,
      "grad_norm": 0.00026849593268707395,
      "learning_rate": 6.0457334076965975e-06,
      "loss": 0.0127,
      "step": 37550
    },
    {
      "epoch": 2.097044060234244,
      "grad_norm": 0.00028314400697126985,
      "learning_rate": 6.0271425915597705e-06,
      "loss": 0.0,
      "step": 37600
    },
    {
      "epoch": 2.0998326826547684,
      "grad_norm": 0.00026811473071575165,
      "learning_rate": 6.008551775422942e-06,
      "loss": 0.0,
      "step": 37650
    },
    {
      "epoch": 2.1026213050752927,
      "grad_norm": 0.0003397184773348272,
      "learning_rate": 5.989960959286113e-06,
      "loss": 0.0,
      "step": 37700
    },
    {
      "epoch": 2.105409927495817,
      "grad_norm": 0.0002588159404695034,
      "learning_rate": 5.971370143149284e-06,
      "loss": 0.0001,
      "step": 37750
    },
    {
      "epoch": 2.108198549916341,
      "grad_norm": 0.00106041191611439,
      "learning_rate": 5.9527793270124565e-06,
      "loss": 0.0288,
      "step": 37800
    },
    {
      "epoch": 2.1109871723368654,
      "grad_norm": 0.0007397010340355337,
      "learning_rate": 5.934188510875628e-06,
      "loss": 0.0,
      "step": 37850
    },
    {
      "epoch": 2.1137757947573896,
      "grad_norm": 0.0006357586826197803,
      "learning_rate": 5.915597694738799e-06,
      "loss": 0.0,
      "step": 37900
    },
    {
      "epoch": 2.116564417177914,
      "grad_norm": 0.0007128092111088336,
      "learning_rate": 5.8970068786019704e-06,
      "loss": 0.0,
      "step": 37950
    },
    {
      "epoch": 2.1193530395984386,
      "grad_norm": 0.0004839951579924673,
      "learning_rate": 5.8784160624651434e-06,
      "loss": 0.0,
      "step": 38000
    },
    {
      "epoch": 2.122141662018963,
      "grad_norm": 0.00038493346073664725,
      "learning_rate": 5.859825246328315e-06,
      "loss": 0.0,
      "step": 38050
    },
    {
      "epoch": 2.124930284439487,
      "grad_norm": 0.0004981494857929647,
      "learning_rate": 5.841234430191486e-06,
      "loss": 0.0001,
      "step": 38100
    },
    {
      "epoch": 2.1277189068600113,
      "grad_norm": 0.0006529067177325487,
      "learning_rate": 5.822643614054657e-06,
      "loss": 0.0,
      "step": 38150
    },
    {
      "epoch": 2.1305075292805356,
      "grad_norm": 0.0005514296353794634,
      "learning_rate": 5.8040527979178295e-06,
      "loss": 0.0,
      "step": 38200
    },
    {
      "epoch": 2.13329615170106,
      "grad_norm": 0.003304973943158984,
      "learning_rate": 5.785461981781001e-06,
      "loss": 0.0214,
      "step": 38250
    },
    {
      "epoch": 2.136084774121584,
      "grad_norm": 0.0003508279623929411,
      "learning_rate": 5.766871165644172e-06,
      "loss": 0.0,
      "step": 38300
    },
    {
      "epoch": 2.1388733965421083,
      "grad_norm": 0.00039295971510000527,
      "learning_rate": 5.748280349507343e-06,
      "loss": 0.0104,
      "step": 38350
    },
    {
      "epoch": 2.1416620189626325,
      "grad_norm": 0.00044043941306881607,
      "learning_rate": 5.729689533370515e-06,
      "loss": 0.0265,
      "step": 38400
    },
    {
      "epoch": 2.1444506413831568,
      "grad_norm": 0.00042875815415754914,
      "learning_rate": 5.711098717233688e-06,
      "loss": 0.0,
      "step": 38450
    },
    {
      "epoch": 2.147239263803681,
      "grad_norm": 0.00048544167657382786,
      "learning_rate": 5.692507901096859e-06,
      "loss": 0.0,
      "step": 38500
    },
    {
      "epoch": 2.1500278862242053,
      "grad_norm": 0.0004076443437952548,
      "learning_rate": 5.67391708496003e-06,
      "loss": 0.0001,
      "step": 38550
    },
    {
      "epoch": 2.1528165086447295,
      "grad_norm": 0.00047454569721594453,
      "learning_rate": 5.6553262688232015e-06,
      "loss": 0.0,
      "step": 38600
    },
    {
      "epoch": 2.1556051310652538,
      "grad_norm": 0.0003806870081461966,
      "learning_rate": 5.636735452686374e-06,
      "loss": 0.0,
      "step": 38650
    },
    {
      "epoch": 2.158393753485778,
      "grad_norm": 0.00036069683847017586,
      "learning_rate": 5.618144636549545e-06,
      "loss": 0.0,
      "step": 38700
    },
    {
      "epoch": 2.1611823759063022,
      "grad_norm": 0.0003120421606581658,
      "learning_rate": 5.599553820412716e-06,
      "loss": 0.0,
      "step": 38750
    },
    {
      "epoch": 2.1639709983268265,
      "grad_norm": 0.0003016791306436062,
      "learning_rate": 5.580963004275888e-06,
      "loss": 0.0,
      "step": 38800
    },
    {
      "epoch": 2.1667596207473507,
      "grad_norm": 0.0002852561592590064,
      "learning_rate": 5.562372188139061e-06,
      "loss": 0.0,
      "step": 38850
    },
    {
      "epoch": 2.169548243167875,
      "grad_norm": 0.00037108297692611814,
      "learning_rate": 5.543781372002232e-06,
      "loss": 0.0,
      "step": 38900
    },
    {
      "epoch": 2.1723368655883992,
      "grad_norm": 0.27130836248397827,
      "learning_rate": 5.525190555865403e-06,
      "loss": 0.0,
      "step": 38950
    },
    {
      "epoch": 2.1751254880089235,
      "grad_norm": 0.0002444216806907207,
      "learning_rate": 5.5065997397285745e-06,
      "loss": 0.0,
      "step": 39000
    },
    {
      "epoch": 2.1779141104294477,
      "grad_norm": 0.0002732356369961053,
      "learning_rate": 5.488008923591747e-06,
      "loss": 0.0,
      "step": 39050
    },
    {
      "epoch": 2.180702732849972,
      "grad_norm": 0.0017951397458091378,
      "learning_rate": 5.469418107454918e-06,
      "loss": 0.0002,
      "step": 39100
    },
    {
      "epoch": 2.183491355270496,
      "grad_norm": 0.00025941955391317606,
      "learning_rate": 5.450827291318089e-06,
      "loss": 0.0,
      "step": 39150
    },
    {
      "epoch": 2.1862799776910204,
      "grad_norm": 0.000268202624283731,
      "learning_rate": 5.4322364751812605e-06,
      "loss": 0.0,
      "step": 39200
    },
    {
      "epoch": 2.1890686001115447,
      "grad_norm": 0.0002654186391737312,
      "learning_rate": 5.413645659044432e-06,
      "loss": 0.0,
      "step": 39250
    },
    {
      "epoch": 2.191857222532069,
      "grad_norm": 0.00033743903622962534,
      "learning_rate": 5.395054842907605e-06,
      "loss": 0.0,
      "step": 39300
    },
    {
      "epoch": 2.1946458449525936,
      "grad_norm": 0.00029622967122122645,
      "learning_rate": 5.376464026770776e-06,
      "loss": 0.0,
      "step": 39350
    },
    {
      "epoch": 2.197434467373118,
      "grad_norm": 0.00022525475651491433,
      "learning_rate": 5.357873210633947e-06,
      "loss": 0.0,
      "step": 39400
    },
    {
      "epoch": 2.200223089793642,
      "grad_norm": 0.0002634548000060022,
      "learning_rate": 5.339282394497119e-06,
      "loss": 0.0,
      "step": 39450
    },
    {
      "epoch": 2.2030117122141664,
      "grad_norm": 0.00023789201804902405,
      "learning_rate": 5.320691578360291e-06,
      "loss": 0.0,
      "step": 39500
    },
    {
      "epoch": 2.2058003346346906,
      "grad_norm": 0.00026184870512224734,
      "learning_rate": 5.302100762223462e-06,
      "loss": 0.0356,
      "step": 39550
    },
    {
      "epoch": 2.208588957055215,
      "grad_norm": 0.0003321611147839576,
      "learning_rate": 5.2835099460866334e-06,
      "loss": 0.0104,
      "step": 39600
    },
    {
      "epoch": 2.211377579475739,
      "grad_norm": 0.0002551249344833195,
      "learning_rate": 5.264919129949805e-06,
      "loss": 0.0114,
      "step": 39650
    },
    {
      "epoch": 2.2141662018962633,
      "grad_norm": 0.00025439541786909103,
      "learning_rate": 5.246328313812977e-06,
      "loss": 0.0191,
      "step": 39700
    },
    {
      "epoch": 2.2169548243167876,
      "grad_norm": 0.0002477226371411234,
      "learning_rate": 5.227737497676148e-06,
      "loss": 0.0346,
      "step": 39750
    },
    {
      "epoch": 2.219743446737312,
      "grad_norm": 0.00405418174341321,
      "learning_rate": 5.2091466815393195e-06,
      "loss": 0.0002,
      "step": 39800
    },
    {
      "epoch": 2.222532069157836,
      "grad_norm": 0.0020250771194696426,
      "learning_rate": 5.190555865402492e-06,
      "loss": 0.0,
      "step": 39850
    },
    {
      "epoch": 2.2253206915783603,
      "grad_norm": 0.000283691450022161,
      "learning_rate": 5.171965049265664e-06,
      "loss": 0.0001,
      "step": 39900
    },
    {
      "epoch": 2.2281093139988846,
      "grad_norm": 0.0002669013920240104,
      "learning_rate": 5.153374233128835e-06,
      "loss": 0.0,
      "step": 39950
    },
    {
      "epoch": 2.230897936419409,
      "grad_norm": 0.00023508114099968225,
      "learning_rate": 5.134783416992006e-06,
      "loss": 0.0,
      "step": 40000
    },
    {
      "epoch": 2.233686558839933,
      "grad_norm": 0.00027981222956441343,
      "learning_rate": 5.116192600855178e-06,
      "loss": 0.0,
      "step": 40050
    },
    {
      "epoch": 2.2364751812604573,
      "grad_norm": 0.0005852479371242225,
      "learning_rate": 5.09760178471835e-06,
      "loss": 0.0294,
      "step": 40100
    },
    {
      "epoch": 2.2392638036809815,
      "grad_norm": 0.0003895075642503798,
      "learning_rate": 5.079010968581521e-06,
      "loss": 0.0,
      "step": 40150
    },
    {
      "epoch": 2.242052426101506,
      "grad_norm": 0.0006534050917252898,
      "learning_rate": 5.060420152444692e-06,
      "loss": 0.0002,
      "step": 40200
    },
    {
      "epoch": 2.24484104852203,
      "grad_norm": 0.0006335400394164026,
      "learning_rate": 5.041829336307864e-06,
      "loss": 0.0,
      "step": 40250
    },
    {
      "epoch": 2.2476296709425543,
      "grad_norm": 0.0008534914231859148,
      "learning_rate": 5.023238520171035e-06,
      "loss": 0.0,
      "step": 40300
    },
    {
      "epoch": 2.2504182933630785,
      "grad_norm": 0.00029442974482662976,
      "learning_rate": 5.004647704034208e-06,
      "loss": 0.0,
      "step": 40350
    },
    {
      "epoch": 2.2532069157836028,
      "grad_norm": 0.0005295879673212767,
      "learning_rate": 4.986056887897379e-06,
      "loss": 0.0,
      "step": 40400
    },
    {
      "epoch": 2.255995538204127,
      "grad_norm": 0.0004521103692241013,
      "learning_rate": 4.967466071760551e-06,
      "loss": 0.0,
      "step": 40450
    },
    {
      "epoch": 2.2587841606246513,
      "grad_norm": 0.0002934053773060441,
      "learning_rate": 4.948875255623723e-06,
      "loss": 0.0,
      "step": 40500
    },
    {
      "epoch": 2.2615727830451755,
      "grad_norm": 0.00038943428080528975,
      "learning_rate": 4.930284439486894e-06,
      "loss": 0.0,
      "step": 40550
    },
    {
      "epoch": 2.2643614054656998,
      "grad_norm": 0.0003429302596487105,
      "learning_rate": 4.911693623350065e-06,
      "loss": 0.0,
      "step": 40600
    },
    {
      "epoch": 2.267150027886224,
      "grad_norm": 0.00039853720227256417,
      "learning_rate": 4.893102807213237e-06,
      "loss": 0.0,
      "step": 40650
    },
    {
      "epoch": 2.2699386503067487,
      "grad_norm": 0.0003564826911315322,
      "learning_rate": 4.874511991076409e-06,
      "loss": 0.0,
      "step": 40700
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.00028050708351656795,
      "learning_rate": 4.85592117493958e-06,
      "loss": 0.0099,
      "step": 40750
    },
    {
      "epoch": 2.275515895147797,
      "grad_norm": 0.45423901081085205,
      "learning_rate": 4.837330358802752e-06,
      "loss": 0.0,
      "step": 40800
    },
    {
      "epoch": 2.2783045175683214,
      "grad_norm": 0.0003239759535063058,
      "learning_rate": 4.8187395426659235e-06,
      "loss": 0.0,
      "step": 40850
    },
    {
      "epoch": 2.2810931399888457,
      "grad_norm": 0.000301037187455222,
      "learning_rate": 4.800148726529095e-06,
      "loss": 0.0,
      "step": 40900
    },
    {
      "epoch": 2.28388176240937,
      "grad_norm": 0.0002793658059090376,
      "learning_rate": 4.781557910392267e-06,
      "loss": 0.0,
      "step": 40950
    },
    {
      "epoch": 2.286670384829894,
      "grad_norm": 0.0003117658197879791,
      "learning_rate": 4.762967094255438e-06,
      "loss": 0.0,
      "step": 41000
    },
    {
      "epoch": 2.2894590072504184,
      "grad_norm": 0.00032207684125751257,
      "learning_rate": 4.7443762781186096e-06,
      "loss": 0.0,
      "step": 41050
    },
    {
      "epoch": 2.2922476296709426,
      "grad_norm": 0.00034330139169469476,
      "learning_rate": 4.725785461981781e-06,
      "loss": 0.0,
      "step": 41100
    },
    {
      "epoch": 2.295036252091467,
      "grad_norm": 0.0002947130415122956,
      "learning_rate": 4.707194645844953e-06,
      "loss": 0.0,
      "step": 41150
    },
    {
      "epoch": 2.297824874511991,
      "grad_norm": 0.0003001182049047202,
      "learning_rate": 4.688603829708124e-06,
      "loss": 0.0001,
      "step": 41200
    },
    {
      "epoch": 2.3006134969325154,
      "grad_norm": 0.00022164716210681945,
      "learning_rate": 4.6700130135712965e-06,
      "loss": 0.0,
      "step": 41250
    },
    {
      "epoch": 2.3034021193530396,
      "grad_norm": 0.00026788184186443686,
      "learning_rate": 4.651422197434468e-06,
      "loss": 0.0,
      "step": 41300
    },
    {
      "epoch": 2.306190741773564,
      "grad_norm": 0.0002651422983035445,
      "learning_rate": 4.632831381297639e-06,
      "loss": 0.0,
      "step": 41350
    },
    {
      "epoch": 2.308979364194088,
      "grad_norm": 0.00025450121029280126,
      "learning_rate": 4.61424056516081e-06,
      "loss": 0.0,
      "step": 41400
    },
    {
      "epoch": 2.3117679866146124,
      "grad_norm": 0.00027140264865010977,
      "learning_rate": 4.5956497490239825e-06,
      "loss": 0.0133,
      "step": 41450
    },
    {
      "epoch": 2.3145566090351366,
      "grad_norm": 0.00020591923384927213,
      "learning_rate": 4.577058932887154e-06,
      "loss": 0.0,
      "step": 41500
    },
    {
      "epoch": 2.317345231455661,
      "grad_norm": 0.00021523622854147106,
      "learning_rate": 4.558468116750326e-06,
      "loss": 0.0002,
      "step": 41550
    },
    {
      "epoch": 2.320133853876185,
      "grad_norm": 0.00023867878189776093,
      "learning_rate": 4.539877300613497e-06,
      "loss": 0.0,
      "step": 41600
    },
    {
      "epoch": 2.3229224762967093,
      "grad_norm": 0.00021770635794382542,
      "learning_rate": 4.521286484476669e-06,
      "loss": 0.0,
      "step": 41650
    },
    {
      "epoch": 2.3257110987172336,
      "grad_norm": 0.00020406498515512794,
      "learning_rate": 4.502695668339841e-06,
      "loss": 0.0,
      "step": 41700
    },
    {
      "epoch": 2.328499721137758,
      "grad_norm": 0.00028346010367386043,
      "learning_rate": 4.484104852203012e-06,
      "loss": 0.0369,
      "step": 41750
    },
    {
      "epoch": 2.331288343558282,
      "grad_norm": 0.00025988227571360767,
      "learning_rate": 4.465514036066183e-06,
      "loss": 0.0,
      "step": 41800
    },
    {
      "epoch": 2.3340769659788063,
      "grad_norm": 0.00020404861425049603,
      "learning_rate": 4.4469232199293554e-06,
      "loss": 0.0,
      "step": 41850
    },
    {
      "epoch": 2.3368655883993306,
      "grad_norm": 0.0002720824850257486,
      "learning_rate": 4.428332403792527e-06,
      "loss": 0.0,
      "step": 41900
    },
    {
      "epoch": 2.339654210819855,
      "grad_norm": 0.0002577778068371117,
      "learning_rate": 4.409741587655699e-06,
      "loss": 0.0168,
      "step": 41950
    },
    {
      "epoch": 2.342442833240379,
      "grad_norm": 0.00025852344697341323,
      "learning_rate": 4.39115077151887e-06,
      "loss": 0.0,
      "step": 42000
    },
    {
      "epoch": 2.3452314556609037,
      "grad_norm": 0.003968149423599243,
      "learning_rate": 4.3725599553820415e-06,
      "loss": 0.0,
      "step": 42050
    },
    {
      "epoch": 2.3480200780814275,
      "grad_norm": 0.0008185980259440839,
      "learning_rate": 4.353969139245214e-06,
      "loss": 0.0291,
      "step": 42100
    },
    {
      "epoch": 2.3508087005019522,
      "grad_norm": 0.011079373769462109,
      "learning_rate": 4.335378323108385e-06,
      "loss": 0.0001,
      "step": 42150
    },
    {
      "epoch": 2.3535973229224765,
      "grad_norm": 0.0012165047228336334,
      "learning_rate": 4.316787506971556e-06,
      "loss": 0.0,
      "step": 42200
    },
    {
      "epoch": 2.3563859453430007,
      "grad_norm": 0.0006088250083848834,
      "learning_rate": 4.2981966908347275e-06,
      "loss": 0.0,
      "step": 42250
    },
    {
      "epoch": 2.359174567763525,
      "grad_norm": 0.0006270991289056838,
      "learning_rate": 4.2796058746979e-06,
      "loss": 0.0,
      "step": 42300
    },
    {
      "epoch": 2.361963190184049,
      "grad_norm": 0.0003980966575909406,
      "learning_rate": 4.261015058561071e-06,
      "loss": 0.0,
      "step": 42350
    },
    {
      "epoch": 2.3647518126045735,
      "grad_norm": 0.00042029659380204976,
      "learning_rate": 4.242424242424243e-06,
      "loss": 0.0,
      "step": 42400
    },
    {
      "epoch": 2.3675404350250977,
      "grad_norm": 0.000990348868072033,
      "learning_rate": 4.223833426287414e-06,
      "loss": 0.0314,
      "step": 42450
    },
    {
      "epoch": 2.370329057445622,
      "grad_norm": 0.0014130000490695238,
      "learning_rate": 4.205242610150586e-06,
      "loss": 0.007,
      "step": 42500
    },
    {
      "epoch": 2.373117679866146,
      "grad_norm": 0.0006970161339268088,
      "learning_rate": 4.186651794013758e-06,
      "loss": 0.0,
      "step": 42550
    },
    {
      "epoch": 2.3759063022866704,
      "grad_norm": 0.0007733001839369535,
      "learning_rate": 4.168060977876929e-06,
      "loss": 0.0,
      "step": 42600
    },
    {
      "epoch": 2.3786949247071947,
      "grad_norm": 0.0009376519010402262,
      "learning_rate": 4.1494701617401004e-06,
      "loss": 0.0001,
      "step": 42650
    },
    {
      "epoch": 2.381483547127719,
      "grad_norm": 0.00042322243098169565,
      "learning_rate": 4.130879345603273e-06,
      "loss": 0.0,
      "step": 42700
    },
    {
      "epoch": 2.384272169548243,
      "grad_norm": 0.0004615953366737813,
      "learning_rate": 4.112288529466444e-06,
      "loss": 0.0,
      "step": 42750
    },
    {
      "epoch": 2.3870607919687674,
      "grad_norm": 0.0005981751601211727,
      "learning_rate": 4.093697713329616e-06,
      "loss": 0.0,
      "step": 42800
    },
    {
      "epoch": 2.3898494143892917,
      "grad_norm": 0.0005642370088025928,
      "learning_rate": 4.075106897192787e-06,
      "loss": 0.0,
      "step": 42850
    },
    {
      "epoch": 2.392638036809816,
      "grad_norm": 0.0003855097747873515,
      "learning_rate": 4.056516081055959e-06,
      "loss": 0.0001,
      "step": 42900
    },
    {
      "epoch": 2.39542665923034,
      "grad_norm": 0.0021315847989171743,
      "learning_rate": 4.03792526491913e-06,
      "loss": 0.0,
      "step": 42950
    },
    {
      "epoch": 2.3982152816508644,
      "grad_norm": 0.00028718545217998326,
      "learning_rate": 4.019334448782301e-06,
      "loss": 0.0,
      "step": 43000
    },
    {
      "epoch": 2.4010039040713886,
      "grad_norm": 0.002655062125995755,
      "learning_rate": 4.000743632645473e-06,
      "loss": 0.0,
      "step": 43050
    },
    {
      "epoch": 2.403792526491913,
      "grad_norm": 0.00029622475267387927,
      "learning_rate": 3.982152816508645e-06,
      "loss": 0.0,
      "step": 43100
    },
    {
      "epoch": 2.406581148912437,
      "grad_norm": 3.2673590183258057,
      "learning_rate": 3.963562000371817e-06,
      "loss": 0.0001,
      "step": 43150
    },
    {
      "epoch": 2.4093697713329614,
      "grad_norm": 0.0006791107007302344,
      "learning_rate": 3.944971184234988e-06,
      "loss": 0.0408,
      "step": 43200
    },
    {
      "epoch": 2.4121583937534856,
      "grad_norm": 0.0011629038490355015,
      "learning_rate": 3.926752184420897e-06,
      "loss": 0.0022,
      "step": 43250
    },
    {
      "epoch": 2.41494701617401,
      "grad_norm": 0.0005769619019702077,
      "learning_rate": 3.908161368284068e-06,
      "loss": 0.0001,
      "step": 43300
    },
    {
      "epoch": 2.417735638594534,
      "grad_norm": 0.0006342938868328929,
      "learning_rate": 3.88957055214724e-06,
      "loss": 0.0,
      "step": 43350
    },
    {
      "epoch": 2.420524261015059,
      "grad_norm": 0.0009010309586301446,
      "learning_rate": 3.870979736010411e-06,
      "loss": 0.0,
      "step": 43400
    },
    {
      "epoch": 2.4233128834355826,
      "grad_norm": 0.0006025405600667,
      "learning_rate": 3.852388919873582e-06,
      "loss": 0.0,
      "step": 43450
    },
    {
      "epoch": 2.4261015058561073,
      "grad_norm": 0.0004970583249814808,
      "learning_rate": 3.833798103736754e-06,
      "loss": 0.0075,
      "step": 43500
    },
    {
      "epoch": 2.4288901282766315,
      "grad_norm": 0.0005343703087419271,
      "learning_rate": 3.815207287599926e-06,
      "loss": 0.0001,
      "step": 43550
    },
    {
      "epoch": 2.4316787506971558,
      "grad_norm": 0.00042667557136155665,
      "learning_rate": 3.796616471463098e-06,
      "loss": 0.0,
      "step": 43600
    },
    {
      "epoch": 2.43446737311768,
      "grad_norm": 0.0004869787662755698,
      "learning_rate": 3.778025655326269e-06,
      "loss": 0.0,
      "step": 43650
    },
    {
      "epoch": 2.4372559955382043,
      "grad_norm": 0.000470304221380502,
      "learning_rate": 3.759434839189441e-06,
      "loss": 0.0243,
      "step": 43700
    },
    {
      "epoch": 2.4400446179587285,
      "grad_norm": 0.000756032473873347,
      "learning_rate": 3.740844023052612e-06,
      "loss": 0.026,
      "step": 43750
    },
    {
      "epoch": 2.4428332403792528,
      "grad_norm": 0.00120556412730366,
      "learning_rate": 3.722253206915784e-06,
      "loss": 0.0156,
      "step": 43800
    },
    {
      "epoch": 2.445621862799777,
      "grad_norm": 0.0003228125860914588,
      "learning_rate": 3.7036623907789556e-06,
      "loss": 0.0069,
      "step": 43850
    },
    {
      "epoch": 2.4484104852203012,
      "grad_norm": 0.0008172646630555391,
      "learning_rate": 3.6850715746421273e-06,
      "loss": 0.0,
      "step": 43900
    },
    {
      "epoch": 2.4511991076408255,
      "grad_norm": 0.0009188107214868069,
      "learning_rate": 3.6664807585052986e-06,
      "loss": 0.0022,
      "step": 43950
    },
    {
      "epoch": 2.4539877300613497,
      "grad_norm": 0.000637005316093564,
      "learning_rate": 3.6478899423684703e-06,
      "loss": 0.0,
      "step": 44000
    },
    {
      "epoch": 2.456776352481874,
      "grad_norm": 0.0005266895168460906,
      "learning_rate": 3.6292991262316416e-06,
      "loss": 0.0,
      "step": 44050
    },
    {
      "epoch": 2.4595649749023982,
      "grad_norm": 0.00041851744754239917,
      "learning_rate": 3.6107083100948138e-06,
      "loss": 0.0101,
      "step": 44100
    },
    {
      "epoch": 2.4623535973229225,
      "grad_norm": 0.001961827278137207,
      "learning_rate": 3.592117493957985e-06,
      "loss": 0.0107,
      "step": 44150
    },
    {
      "epoch": 2.4651422197434467,
      "grad_norm": 0.0006721950485371053,
      "learning_rate": 3.5735266778211564e-06,
      "loss": 0.0,
      "step": 44200
    },
    {
      "epoch": 2.467930842163971,
      "grad_norm": 0.00039743620436638594,
      "learning_rate": 3.554935861684328e-06,
      "loss": 0.0,
      "step": 44250
    },
    {
      "epoch": 2.470719464584495,
      "grad_norm": 0.0007119481451809406,
      "learning_rate": 3.5363450455474994e-06,
      "loss": 0.0,
      "step": 44300
    },
    {
      "epoch": 2.4735080870050195,
      "grad_norm": 0.000428711820859462,
      "learning_rate": 3.5177542294106715e-06,
      "loss": 0.0,
      "step": 44350
    },
    {
      "epoch": 2.4762967094255437,
      "grad_norm": 0.00044580388930626214,
      "learning_rate": 3.499163413273843e-06,
      "loss": 0.0,
      "step": 44400
    },
    {
      "epoch": 2.479085331846068,
      "grad_norm": 0.0004214109794702381,
      "learning_rate": 3.4805725971370146e-06,
      "loss": 0.0,
      "step": 44450
    },
    {
      "epoch": 2.481873954266592,
      "grad_norm": 0.00038930910523049533,
      "learning_rate": 3.461981781000186e-06,
      "loss": 0.0,
      "step": 44500
    },
    {
      "epoch": 2.4846625766871164,
      "grad_norm": 0.00036860862746834755,
      "learning_rate": 3.443390964863358e-06,
      "loss": 0.0,
      "step": 44550
    },
    {
      "epoch": 2.4874511991076407,
      "grad_norm": 0.0005372908199205995,
      "learning_rate": 3.4248001487265293e-06,
      "loss": 0.0111,
      "step": 44600
    },
    {
      "epoch": 2.490239821528165,
      "grad_norm": 0.00039455608930438757,
      "learning_rate": 3.406209332589701e-06,
      "loss": 0.0122,
      "step": 44650
    },
    {
      "epoch": 2.493028443948689,
      "grad_norm": 0.0004053267475683242,
      "learning_rate": 3.3876185164528723e-06,
      "loss": 0.0,
      "step": 44700
    },
    {
      "epoch": 2.495817066369214,
      "grad_norm": 0.0004697333788499236,
      "learning_rate": 3.3690277003160445e-06,
      "loss": 0.0002,
      "step": 44750
    },
    {
      "epoch": 2.4986056887897377,
      "grad_norm": 0.008752615191042423,
      "learning_rate": 3.3504368841792158e-06,
      "loss": 0.0,
      "step": 44800
    },
    {
      "epoch": 2.5013943112102623,
      "grad_norm": 0.0003698421933222562,
      "learning_rate": 3.3318460680423875e-06,
      "loss": 0.0,
      "step": 44850
    },
    {
      "epoch": 2.504182933630786,
      "grad_norm": 0.00037130899727344513,
      "learning_rate": 3.3132552519055588e-06,
      "loss": 0.0,
      "step": 44900
    },
    {
      "epoch": 2.506971556051311,
      "grad_norm": 0.000363706931238994,
      "learning_rate": 3.294664435768731e-06,
      "loss": 0.0001,
      "step": 44950
    },
    {
      "epoch": 2.509760178471835,
      "grad_norm": 0.0002885788562707603,
      "learning_rate": 3.2760736196319022e-06,
      "loss": 0.0,
      "step": 45000
    },
    {
      "epoch": 2.5125488008923593,
      "grad_norm": 0.0002983149024657905,
      "learning_rate": 3.257482803495074e-06,
      "loss": 0.0,
      "step": 45050
    },
    {
      "epoch": 2.5153374233128836,
      "grad_norm": 0.07853417843580246,
      "learning_rate": 3.2388919873582452e-06,
      "loss": 0.0197,
      "step": 45100
    },
    {
      "epoch": 2.518126045733408,
      "grad_norm": 0.0003502886393107474,
      "learning_rate": 3.2203011712214165e-06,
      "loss": 0.0,
      "step": 45150
    },
    {
      "epoch": 2.520914668153932,
      "grad_norm": 0.00039945283788256347,
      "learning_rate": 3.2017103550845887e-06,
      "loss": 0.0001,
      "step": 45200
    },
    {
      "epoch": 2.5237032905744563,
      "grad_norm": 0.0003624778182711452,
      "learning_rate": 3.18311953894776e-06,
      "loss": 0.0,
      "step": 45250
    },
    {
      "epoch": 2.5264919129949805,
      "grad_norm": 0.0002487476740498096,
      "learning_rate": 3.1649005391336685e-06,
      "loss": 0.0034,
      "step": 45300
    },
    {
      "epoch": 2.529280535415505,
      "grad_norm": 0.00037932617124170065,
      "learning_rate": 3.14630972299684e-06,
      "loss": 0.0,
      "step": 45350
    },
    {
      "epoch": 2.532069157836029,
      "grad_norm": 0.011220930144190788,
      "learning_rate": 3.1277189068600115e-06,
      "loss": 0.0,
      "step": 45400
    },
    {
      "epoch": 2.5348577802565533,
      "grad_norm": 0.0002876135113183409,
      "learning_rate": 3.109128090723183e-06,
      "loss": 0.0,
      "step": 45450
    },
    {
      "epoch": 2.5376464026770775,
      "grad_norm": 0.00032484219991602004,
      "learning_rate": 3.0905372745863545e-06,
      "loss": 0.0184,
      "step": 45500
    },
    {
      "epoch": 2.5404350250976018,
      "grad_norm": 0.004599974025040865,
      "learning_rate": 3.0719464584495263e-06,
      "loss": 0.0269,
      "step": 45550
    },
    {
      "epoch": 2.543223647518126,
      "grad_norm": 0.0011419453658163548,
      "learning_rate": 3.0533556423126976e-06,
      "loss": 0.0001,
      "step": 45600
    },
    {
      "epoch": 2.5460122699386503,
      "grad_norm": 0.000533712503965944,
      "learning_rate": 3.0347648261758693e-06,
      "loss": 0.0099,
      "step": 45650
    },
    {
      "epoch": 2.5488008923591745,
      "grad_norm": 0.0028350420761853456,
      "learning_rate": 3.0161740100390406e-06,
      "loss": 0.0,
      "step": 45700
    },
    {
      "epoch": 2.5515895147796988,
      "grad_norm": 0.0005525745800696313,
      "learning_rate": 2.9975831939022127e-06,
      "loss": 0.0,
      "step": 45750
    },
    {
      "epoch": 2.554378137200223,
      "grad_norm": 0.0005548193003050983,
      "learning_rate": 2.978992377765384e-06,
      "loss": 0.0,
      "step": 45800
    },
    {
      "epoch": 2.5571667596207472,
      "grad_norm": 0.0006628518458455801,
      "learning_rate": 2.9604015616285557e-06,
      "loss": 0.0003,
      "step": 45850
    },
    {
      "epoch": 2.5599553820412715,
      "grad_norm": 0.0007864867802709341,
      "learning_rate": 2.941810745491727e-06,
      "loss": 0.0,
      "step": 45900
    },
    {
      "epoch": 2.5627440044617957,
      "grad_norm": 0.0006817421526648104,
      "learning_rate": 2.923219929354899e-06,
      "loss": 0.0214,
      "step": 45950
    },
    {
      "epoch": 2.56553262688232,
      "grad_norm": 0.0009054165566340089,
      "learning_rate": 2.9046291132180705e-06,
      "loss": 0.0001,
      "step": 46000
    },
    {
      "epoch": 2.5683212493028442,
      "grad_norm": 0.007617373019456863,
      "learning_rate": 2.886038297081242e-06,
      "loss": 0.0552,
      "step": 46050
    },
    {
      "epoch": 2.571109871723369,
      "grad_norm": 0.0011546214809641242,
      "learning_rate": 2.8674474809444135e-06,
      "loss": 0.0001,
      "step": 46100
    },
    {
      "epoch": 2.5738984941438927,
      "grad_norm": 0.000550075841601938,
      "learning_rate": 2.8488566648075856e-06,
      "loss": 0.0001,
      "step": 46150
    },
    {
      "epoch": 2.5766871165644174,
      "grad_norm": 0.00099795067217201,
      "learning_rate": 2.830265848670757e-06,
      "loss": 0.0001,
      "step": 46200
    },
    {
      "epoch": 2.579475738984941,
      "grad_norm": 0.0006701771053485572,
      "learning_rate": 2.8116750325339287e-06,
      "loss": 0.0001,
      "step": 46250
    },
    {
      "epoch": 2.582264361405466,
      "grad_norm": 0.09354952722787857,
      "learning_rate": 2.7930842163971e-06,
      "loss": 0.0,
      "step": 46300
    },
    {
      "epoch": 2.5850529838259897,
      "grad_norm": 0.0015871737850829959,
      "learning_rate": 2.774493400260272e-06,
      "loss": 0.0001,
      "step": 46350
    },
    {
      "epoch": 2.5878416062465144,
      "grad_norm": 0.00042197125731036067,
      "learning_rate": 2.7559025841234434e-06,
      "loss": 0.0,
      "step": 46400
    },
    {
      "epoch": 2.5906302286670386,
      "grad_norm": 0.0008912503253668547,
      "learning_rate": 2.7373117679866147e-06,
      "loss": 0.0,
      "step": 46450
    },
    {
      "epoch": 2.593418851087563,
      "grad_norm": 0.000541216169949621,
      "learning_rate": 2.7187209518497864e-06,
      "loss": 0.0,
      "step": 46500
    },
    {
      "epoch": 2.596207473508087,
      "grad_norm": 0.00037833265378139913,
      "learning_rate": 2.7001301357129577e-06,
      "loss": 0.0,
      "step": 46550
    },
    {
      "epoch": 2.5989960959286114,
      "grad_norm": 0.00035231775837019086,
      "learning_rate": 2.68153931957613e-06,
      "loss": 0.0,
      "step": 46600
    },
    {
      "epoch": 2.6017847183491356,
      "grad_norm": 0.0007332246750593185,
      "learning_rate": 2.662948503439301e-06,
      "loss": 0.0,
      "step": 46650
    },
    {
      "epoch": 2.60457334076966,
      "grad_norm": 0.0004133432521484792,
      "learning_rate": 2.644357687302473e-06,
      "loss": 0.0,
      "step": 46700
    },
    {
      "epoch": 2.607361963190184,
      "grad_norm": 0.000438648829003796,
      "learning_rate": 2.625766871165644e-06,
      "loss": 0.0002,
      "step": 46750
    },
    {
      "epoch": 2.6101505856107083,
      "grad_norm": 0.0003591816348489374,
      "learning_rate": 2.607176055028816e-06,
      "loss": 0.0,
      "step": 46800
    },
    {
      "epoch": 2.6129392080312326,
      "grad_norm": 0.0004791552200913429,
      "learning_rate": 2.5885852388919876e-06,
      "loss": 0.0,
      "step": 46850
    },
    {
      "epoch": 2.615727830451757,
      "grad_norm": 0.014926143921911716,
      "learning_rate": 2.5699944227551594e-06,
      "loss": 0.0,
      "step": 46900
    },
    {
      "epoch": 2.618516452872281,
      "grad_norm": 0.00038982354453764856,
      "learning_rate": 2.5514036066183307e-06,
      "loss": 0.0,
      "step": 46950
    },
    {
      "epoch": 2.6213050752928053,
      "grad_norm": 0.001334020053036511,
      "learning_rate": 2.5328127904815024e-06,
      "loss": 0.0,
      "step": 47000
    },
    {
      "epoch": 2.6240936977133296,
      "grad_norm": 0.00033704270026646554,
      "learning_rate": 2.5142219743446737e-06,
      "loss": 0.0,
      "step": 47050
    },
    {
      "epoch": 2.626882320133854,
      "grad_norm": 0.0006047567585483193,
      "learning_rate": 2.4956311582078454e-06,
      "loss": 0.0,
      "step": 47100
    },
    {
      "epoch": 2.629670942554378,
      "grad_norm": 0.00045312524889595807,
      "learning_rate": 2.477040342071017e-06,
      "loss": 0.0,
      "step": 47150
    },
    {
      "epoch": 2.6324595649749023,
      "grad_norm": 0.00031207967549562454,
      "learning_rate": 2.458449525934189e-06,
      "loss": 0.0,
      "step": 47200
    },
    {
      "epoch": 2.6352481873954265,
      "grad_norm": 0.0003640835639089346,
      "learning_rate": 2.43985870979736e-06,
      "loss": 0.0002,
      "step": 47250
    },
    {
      "epoch": 2.638036809815951,
      "grad_norm": 0.000504070078022778,
      "learning_rate": 2.421267893660532e-06,
      "loss": 0.0104,
      "step": 47300
    },
    {
      "epoch": 2.640825432236475,
      "grad_norm": 0.000376936950488016,
      "learning_rate": 2.4026770775237036e-06,
      "loss": 0.0,
      "step": 47350
    },
    {
      "epoch": 2.6436140546569993,
      "grad_norm": 0.0011868909932672977,
      "learning_rate": 2.3840862613868753e-06,
      "loss": 0.0,
      "step": 47400
    },
    {
      "epoch": 2.646402677077524,
      "grad_norm": 0.00042753099114634097,
      "learning_rate": 2.3654954452500466e-06,
      "loss": 0.0,
      "step": 47450
    },
    {
      "epoch": 2.6491912994980478,
      "grad_norm": 0.00023648884962312877,
      "learning_rate": 2.3469046291132183e-06,
      "loss": 0.0,
      "step": 47500
    },
    {
      "epoch": 2.6519799219185725,
      "grad_norm": 0.0003368450270500034,
      "learning_rate": 2.32831381297639e-06,
      "loss": 0.0,
      "step": 47550
    },
    {
      "epoch": 2.6547685443390963,
      "grad_norm": 0.0003286967403255403,
      "learning_rate": 2.3097229968395614e-06,
      "loss": 0.0001,
      "step": 47600
    },
    {
      "epoch": 2.657557166759621,
      "grad_norm": 0.00030549257644452155,
      "learning_rate": 2.291132180702733e-06,
      "loss": 0.0,
      "step": 47650
    },
    {
      "epoch": 2.6603457891801447,
      "grad_norm": 0.0043540215119719505,
      "learning_rate": 2.272541364565905e-06,
      "loss": 0.0,
      "step": 47700
    },
    {
      "epoch": 2.6631344116006694,
      "grad_norm": 0.00023736506409477443,
      "learning_rate": 2.2539505484290765e-06,
      "loss": 0.0,
      "step": 47750
    },
    {
      "epoch": 2.6659230340211937,
      "grad_norm": 0.0002674041606951505,
      "learning_rate": 2.235359732292248e-06,
      "loss": 0.0,
      "step": 47800
    },
    {
      "epoch": 2.668711656441718,
      "grad_norm": 0.00029448140412569046,
      "learning_rate": 2.216768916155419e-06,
      "loss": 0.0,
      "step": 47850
    },
    {
      "epoch": 2.671500278862242,
      "grad_norm": 0.00028001147438772023,
      "learning_rate": 2.198178100018591e-06,
      "loss": 0.0,
      "step": 47900
    },
    {
      "epoch": 2.6742889012827664,
      "grad_norm": 0.00025610881857573986,
      "learning_rate": 2.1795872838817626e-06,
      "loss": 0.0,
      "step": 47950
    },
    {
      "epoch": 2.6770775237032907,
      "grad_norm": 0.0004333452961873263,
      "learning_rate": 2.1609964677449343e-06,
      "loss": 0.0,
      "step": 48000
    },
    {
      "epoch": 2.679866146123815,
      "grad_norm": 0.00026066991267725825,
      "learning_rate": 2.1424056516081056e-06,
      "loss": 0.0239,
      "step": 48050
    },
    {
      "epoch": 2.682654768544339,
      "grad_norm": 0.005626828875392675,
      "learning_rate": 2.1238148354712773e-06,
      "loss": 0.0001,
      "step": 48100
    },
    {
      "epoch": 2.6854433909648634,
      "grad_norm": 0.0010080686770379543,
      "learning_rate": 2.1055958356571854e-06,
      "loss": 0.0041,
      "step": 48150
    },
    {
      "epoch": 2.6882320133853876,
      "grad_norm": 0.001896017580293119,
      "learning_rate": 2.087005019520357e-06,
      "loss": 0.0265,
      "step": 48200
    },
    {
      "epoch": 2.691020635805912,
      "grad_norm": 0.0011365351965650916,
      "learning_rate": 2.0684142033835284e-06,
      "loss": 0.0001,
      "step": 48250
    },
    {
      "epoch": 2.693809258226436,
      "grad_norm": 0.0013603141997009516,
      "learning_rate": 2.0498233872467e-06,
      "loss": 0.0,
      "step": 48300
    },
    {
      "epoch": 2.6965978806469604,
      "grad_norm": 0.0019412359688431025,
      "learning_rate": 2.031232571109872e-06,
      "loss": 0.0,
      "step": 48350
    },
    {
      "epoch": 2.6993865030674846,
      "grad_norm": 0.001736799837090075,
      "learning_rate": 2.0126417549730436e-06,
      "loss": 0.0,
      "step": 48400
    },
    {
      "epoch": 2.702175125488009,
      "grad_norm": 0.001236780546605587,
      "learning_rate": 1.994050938836215e-06,
      "loss": 0.0,
      "step": 48450
    },
    {
      "epoch": 2.704963747908533,
      "grad_norm": 0.001151332980953157,
      "learning_rate": 1.9754601226993866e-06,
      "loss": 0.0275,
      "step": 48500
    },
    {
      "epoch": 2.7077523703290574,
      "grad_norm": 0.0014144573360681534,
      "learning_rate": 1.9568693065625583e-06,
      "loss": 0.0001,
      "step": 48550
    },
    {
      "epoch": 2.7105409927495816,
      "grad_norm": 0.0007227298337966204,
      "learning_rate": 1.93827849042573e-06,
      "loss": 0.0,
      "step": 48600
    },
    {
      "epoch": 2.713329615170106,
      "grad_norm": 0.0005990213248878717,
      "learning_rate": 1.9196876742889013e-06,
      "loss": 0.0001,
      "step": 48650
    },
    {
      "epoch": 2.71611823759063,
      "grad_norm": 0.0013686243910342455,
      "learning_rate": 1.901096858152073e-06,
      "loss": 0.0,
      "step": 48700
    },
    {
      "epoch": 2.7189068600111543,
      "grad_norm": 0.0005934364162385464,
      "learning_rate": 1.8825060420152448e-06,
      "loss": 0.0,
      "step": 48750
    },
    {
      "epoch": 2.721695482431679,
      "grad_norm": 0.0011591253569349647,
      "learning_rate": 1.8639152258784163e-06,
      "loss": 0.0,
      "step": 48800
    },
    {
      "epoch": 2.724484104852203,
      "grad_norm": 0.0008006321149878204,
      "learning_rate": 1.8453244097415878e-06,
      "loss": 0.0,
      "step": 48850
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.0011807347182184458,
      "learning_rate": 1.8267335936047595e-06,
      "loss": 0.0,
      "step": 48900
    },
    {
      "epoch": 2.7300613496932513,
      "grad_norm": 0.0008722057100385427,
      "learning_rate": 1.808142777467931e-06,
      "loss": 0.0422,
      "step": 48950
    },
    {
      "epoch": 2.732849972113776,
      "grad_norm": 0.0005253085400909185,
      "learning_rate": 1.7895519613311027e-06,
      "loss": 0.0,
      "step": 49000
    },
    {
      "epoch": 2.7356385945343,
      "grad_norm": 0.0018450383795425296,
      "learning_rate": 1.7709611451942743e-06,
      "loss": 0.0,
      "step": 49050
    },
    {
      "epoch": 2.7384272169548245,
      "grad_norm": 0.0005344788078218699,
      "learning_rate": 1.7523703290574456e-06,
      "loss": 0.0,
      "step": 49100
    },
    {
      "epoch": 2.7412158393753487,
      "grad_norm": 0.0008804789977148175,
      "learning_rate": 1.7337795129206173e-06,
      "loss": 0.0,
      "step": 49150
    },
    {
      "epoch": 2.744004461795873,
      "grad_norm": 0.0004057061451021582,
      "learning_rate": 1.7151886967837888e-06,
      "loss": 0.013,
      "step": 49200
    },
    {
      "epoch": 2.7467930842163972,
      "grad_norm": 0.0005515433731488883,
      "learning_rate": 1.6965978806469605e-06,
      "loss": 0.0,
      "step": 49250
    },
    {
      "epoch": 2.7495817066369215,
      "grad_norm": 0.000505100644659251,
      "learning_rate": 1.678007064510132e-06,
      "loss": 0.0,
      "step": 49300
    },
    {
      "epoch": 2.7523703290574457,
      "grad_norm": 0.0006764386780560017,
      "learning_rate": 1.6594162483733037e-06,
      "loss": 0.0,
      "step": 49350
    },
    {
      "epoch": 2.75515895147797,
      "grad_norm": 0.0003839717246592045,
      "learning_rate": 1.6408254322364752e-06,
      "loss": 0.0001,
      "step": 49400
    },
    {
      "epoch": 2.757947573898494,
      "grad_norm": 0.0007635738584212959,
      "learning_rate": 1.622234616099647e-06,
      "loss": 0.0,
      "step": 49450
    },
    {
      "epoch": 2.7607361963190185,
      "grad_norm": 0.0004355211276561022,
      "learning_rate": 1.6036437999628185e-06,
      "loss": 0.0,
      "step": 49500
    },
    {
      "epoch": 2.7635248187395427,
      "grad_norm": 0.007667893543839455,
      "learning_rate": 1.5850529838259902e-06,
      "loss": 0.0,
      "step": 49550
    },
    {
      "epoch": 2.766313441160067,
      "grad_norm": 0.00046679406659677625,
      "learning_rate": 1.5664621676891617e-06,
      "loss": 0.0385,
      "step": 49600
    },
    {
      "epoch": 2.769102063580591,
      "grad_norm": 0.000509723846334964,
      "learning_rate": 1.5478713515523332e-06,
      "loss": 0.0083,
      "step": 49650
    },
    {
      "epoch": 2.7718906860011154,
      "grad_norm": 0.000417196424677968,
      "learning_rate": 1.529280535415505e-06,
      "loss": 0.0,
      "step": 49700
    },
    {
      "epoch": 2.7746793084216397,
      "grad_norm": 0.00038864233647473156,
      "learning_rate": 1.5106897192786765e-06,
      "loss": 0.0,
      "step": 49750
    },
    {
      "epoch": 2.777467930842164,
      "grad_norm": 0.0008180723525583744,
      "learning_rate": 1.4920989031418482e-06,
      "loss": 0.0001,
      "step": 49800
    },
    {
      "epoch": 2.780256553262688,
      "grad_norm": 0.00039172277320176363,
      "learning_rate": 1.4735080870050197e-06,
      "loss": 0.0,
      "step": 49850
    },
    {
      "epoch": 2.7830451756832124,
      "grad_norm": 0.00036527065094560385,
      "learning_rate": 1.4549172708681914e-06,
      "loss": 0.0,
      "step": 49900
    },
    {
      "epoch": 2.7858337981037367,
      "grad_norm": 0.0004939890350215137,
      "learning_rate": 1.436326454731363e-06,
      "loss": 0.0,
      "step": 49950
    },
    {
      "epoch": 2.788622420524261,
      "grad_norm": 0.0004871144483331591,
      "learning_rate": 1.4177356385945342e-06,
      "loss": 0.0,
      "step": 50000
    },
    {
      "epoch": 2.791411042944785,
      "grad_norm": 0.0013594807824119925,
      "learning_rate": 1.399144822457706e-06,
      "loss": 0.0,
      "step": 50050
    },
    {
      "epoch": 2.7941996653653094,
      "grad_norm": 0.00150666618719697,
      "learning_rate": 1.3805540063208775e-06,
      "loss": 0.022,
      "step": 50100
    },
    {
      "epoch": 2.7969882877858336,
      "grad_norm": 0.0006684009567834437,
      "learning_rate": 1.3619631901840492e-06,
      "loss": 0.0,
      "step": 50150
    },
    {
      "epoch": 2.799776910206358,
      "grad_norm": 0.00041678454726934433,
      "learning_rate": 1.3433723740472207e-06,
      "loss": 0.0,
      "step": 50200
    },
    {
      "epoch": 2.8025655326268826,
      "grad_norm": 0.0006365656736306846,
      "learning_rate": 1.3247815579103924e-06,
      "loss": 0.0153,
      "step": 50250
    },
    {
      "epoch": 2.8053541550474064,
      "grad_norm": 0.0004854837025050074,
      "learning_rate": 1.306190741773564e-06,
      "loss": 0.0,
      "step": 50300
    },
    {
      "epoch": 2.808142777467931,
      "grad_norm": 0.0010348785435780883,
      "learning_rate": 1.2875999256367354e-06,
      "loss": 0.0,
      "step": 50350
    },
    {
      "epoch": 2.810931399888455,
      "grad_norm": 0.0042950743809342384,
      "learning_rate": 1.2690091094999071e-06,
      "loss": 0.0,
      "step": 50400
    },
    {
      "epoch": 2.8137200223089796,
      "grad_norm": 0.0003460944280959666,
      "learning_rate": 1.2504182933630787e-06,
      "loss": 0.0001,
      "step": 50450
    },
    {
      "epoch": 2.8165086447295034,
      "grad_norm": 0.00039318972267210484,
      "learning_rate": 1.232199293548987e-06,
      "loss": 0.007,
      "step": 50500
    },
    {
      "epoch": 2.819297267150028,
      "grad_norm": 0.00033368897857144475,
      "learning_rate": 1.2136084774121585e-06,
      "loss": 0.0,
      "step": 50550
    },
    {
      "epoch": 2.8220858895705523,
      "grad_norm": 0.0004130225570406765,
      "learning_rate": 1.19501766127533e-06,
      "loss": 0.0,
      "step": 50600
    },
    {
      "epoch": 2.8248745119910765,
      "grad_norm": 0.00043877869029529393,
      "learning_rate": 1.1764268451385017e-06,
      "loss": 0.0,
      "step": 50650
    },
    {
      "epoch": 2.8276631344116008,
      "grad_norm": 0.0005260067991912365,
      "learning_rate": 1.1578360290016732e-06,
      "loss": 0.0,
      "step": 50700
    },
    {
      "epoch": 2.830451756832125,
      "grad_norm": 0.0003162011271342635,
      "learning_rate": 1.139245212864845e-06,
      "loss": 0.0,
      "step": 50750
    },
    {
      "epoch": 2.8332403792526493,
      "grad_norm": 0.0002961973659694195,
      "learning_rate": 1.1206543967280164e-06,
      "loss": 0.0,
      "step": 50800
    },
    {
      "epoch": 2.8360290016731735,
      "grad_norm": 0.00044994003837928176,
      "learning_rate": 1.1020635805911882e-06,
      "loss": 0.0,
      "step": 50850
    },
    {
      "epoch": 2.8388176240936978,
      "grad_norm": 0.0003358826506882906,
      "learning_rate": 1.0834727644543597e-06,
      "loss": 0.0001,
      "step": 50900
    },
    {
      "epoch": 2.841606246514222,
      "grad_norm": 0.0009393201908096671,
      "learning_rate": 1.0648819483175312e-06,
      "loss": 0.0344,
      "step": 50950
    },
    {
      "epoch": 2.8443948689347462,
      "grad_norm": 0.005174925550818443,
      "learning_rate": 1.046291132180703e-06,
      "loss": 0.0,
      "step": 51000
    },
    {
      "epoch": 2.8471834913552705,
      "grad_norm": 0.00030471975333057344,
      "learning_rate": 1.0277003160438744e-06,
      "loss": 0.0,
      "step": 51050
    },
    {
      "epoch": 2.8499721137757947,
      "grad_norm": 0.0004157504008617252,
      "learning_rate": 1.009109499907046e-06,
      "loss": 0.0,
      "step": 51100
    },
    {
      "epoch": 2.852760736196319,
      "grad_norm": 0.0002804827527143061,
      "learning_rate": 9.905186837702176e-07,
      "loss": 0.0001,
      "step": 51150
    },
    {
      "epoch": 2.8555493586168432,
      "grad_norm": 0.0007367515354417264,
      "learning_rate": 9.719278676333891e-07,
      "loss": 0.0,
      "step": 51200
    },
    {
      "epoch": 2.8583379810373675,
      "grad_norm": 0.0011252043768763542,
      "learning_rate": 9.533370514965608e-07,
      "loss": 0.0,
      "step": 51250
    },
    {
      "epoch": 2.8611266034578917,
      "grad_norm": 0.00042533999658189714,
      "learning_rate": 9.347462353597324e-07,
      "loss": 0.0,
      "step": 51300
    },
    {
      "epoch": 2.863915225878416,
      "grad_norm": 0.001715676044113934,
      "learning_rate": 9.16155419222904e-07,
      "loss": 0.0,
      "step": 51350
    },
    {
      "epoch": 2.86670384829894,
      "grad_norm": 0.00026806636014953256,
      "learning_rate": 8.975646030860756e-07,
      "loss": 0.0,
      "step": 51400
    },
    {
      "epoch": 2.8694924707194644,
      "grad_norm": 0.00046872420352883637,
      "learning_rate": 8.789737869492472e-07,
      "loss": 0.0001,
      "step": 51450
    },
    {
      "epoch": 2.8722810931399887,
      "grad_norm": 0.0004759926232509315,
      "learning_rate": 8.603829708124186e-07,
      "loss": 0.0,
      "step": 51500
    },
    {
      "epoch": 2.875069715560513,
      "grad_norm": 0.0011365568498149514,
      "learning_rate": 8.417921546755903e-07,
      "loss": 0.0,
      "step": 51550
    },
    {
      "epoch": 2.8778583379810376,
      "grad_norm": 0.004054795950651169,
      "learning_rate": 8.232013385387619e-07,
      "loss": 0.0,
      "step": 51600
    },
    {
      "epoch": 2.8806469604015614,
      "grad_norm": 0.0008615134283900261,
      "learning_rate": 8.046105224019335e-07,
      "loss": 0.0,
      "step": 51650
    },
    {
      "epoch": 2.883435582822086,
      "grad_norm": 0.0006609488627873361,
      "learning_rate": 7.863915225878417e-07,
      "loss": 0.0041,
      "step": 51700
    },
    {
      "epoch": 2.88622420524261,
      "grad_norm": 0.006737689021974802,
      "learning_rate": 7.678007064510133e-07,
      "loss": 0.0087,
      "step": 51750
    },
    {
      "epoch": 2.8890128276631346,
      "grad_norm": 0.0003230681468266994,
      "learning_rate": 7.492098903141849e-07,
      "loss": 0.0,
      "step": 51800
    },
    {
      "epoch": 2.8918014500836584,
      "grad_norm": 0.00031416380079463124,
      "learning_rate": 7.306190741773564e-07,
      "loss": 0.0129,
      "step": 51850
    },
    {
      "epoch": 2.894590072504183,
      "grad_norm": 0.0003585625672712922,
      "learning_rate": 7.12028258040528e-07,
      "loss": 0.0,
      "step": 51900
    },
    {
      "epoch": 2.8973786949247073,
      "grad_norm": 0.0002777449553832412,
      "learning_rate": 6.934374419036996e-07,
      "loss": 0.0004,
      "step": 51950
    },
    {
      "epoch": 2.9001673173452316,
      "grad_norm": 0.00039291707798838615,
      "learning_rate": 6.748466257668713e-07,
      "loss": 0.0144,
      "step": 52000
    },
    {
      "epoch": 2.902955939765756,
      "grad_norm": 0.00039532064693048596,
      "learning_rate": 6.562558096300428e-07,
      "loss": 0.0,
      "step": 52050
    },
    {
      "epoch": 2.90574456218628,
      "grad_norm": 0.00039505789754912257,
      "learning_rate": 6.376649934932144e-07,
      "loss": 0.0,
      "step": 52100
    },
    {
      "epoch": 2.9085331846068043,
      "grad_norm": 0.000761673494707793,
      "learning_rate": 6.19074177356386e-07,
      "loss": 0.0,
      "step": 52150
    },
    {
      "epoch": 2.9113218070273286,
      "grad_norm": 0.000413941394072026,
      "learning_rate": 6.004833612195576e-07,
      "loss": 0.0,
      "step": 52200
    },
    {
      "epoch": 2.914110429447853,
      "grad_norm": 0.000430436892202124,
      "learning_rate": 5.818925450827291e-07,
      "loss": 0.0117,
      "step": 52250
    },
    {
      "epoch": 2.916899051868377,
      "grad_norm": 0.00034929130924865603,
      "learning_rate": 5.633017289459007e-07,
      "loss": 0.0,
      "step": 52300
    },
    {
      "epoch": 2.9196876742889013,
      "grad_norm": 0.06228529289364815,
      "learning_rate": 5.447109128090724e-07,
      "loss": 0.0049,
      "step": 52350
    },
    {
      "epoch": 2.9224762967094255,
      "grad_norm": 0.00029517628718167543,
      "learning_rate": 5.26120096672244e-07,
      "loss": 0.0,
      "step": 52400
    },
    {
      "epoch": 2.92526491912995,
      "grad_norm": 0.000695160124450922,
      "learning_rate": 5.075292805354155e-07,
      "loss": 0.0,
      "step": 52450
    },
    {
      "epoch": 2.928053541550474,
      "grad_norm": 0.0006225325632840395,
      "learning_rate": 4.889384643985871e-07,
      "loss": 0.0144,
      "step": 52500
    },
    {
      "epoch": 2.9308421639709983,
      "grad_norm": 0.00035690076765604317,
      "learning_rate": 4.7034764826175877e-07,
      "loss": 0.0,
      "step": 52550
    },
    {
      "epoch": 2.9336307863915225,
      "grad_norm": 0.00034420142765156925,
      "learning_rate": 4.5175683212493033e-07,
      "loss": 0.0,
      "step": 52600
    },
    {
      "epoch": 2.9364194088120468,
      "grad_norm": 0.0006521689356304705,
      "learning_rate": 4.331660159881019e-07,
      "loss": 0.0,
      "step": 52650
    },
    {
      "epoch": 2.939208031232571,
      "grad_norm": 0.00033376182545907795,
      "learning_rate": 4.145751998512735e-07,
      "loss": 0.0171,
      "step": 52700
    },
    {
      "epoch": 2.9419966536530953,
      "grad_norm": 0.00032849516719579697,
      "learning_rate": 3.959843837144451e-07,
      "loss": 0.0,
      "step": 52750
    },
    {
      "epoch": 2.9447852760736195,
      "grad_norm": 0.0003816589596681297,
      "learning_rate": 3.773935675776167e-07,
      "loss": 0.0,
      "step": 52800
    },
    {
      "epoch": 2.9475738984941438,
      "grad_norm": 0.0007562774699181318,
      "learning_rate": 3.588027514407883e-07,
      "loss": 0.008,
      "step": 52850
    },
    {
      "epoch": 2.950362520914668,
      "grad_norm": 0.000350456713931635,
      "learning_rate": 3.4021193530395987e-07,
      "loss": 0.0148,
      "step": 52900
    },
    {
      "epoch": 2.9531511433351927,
      "grad_norm": 0.00026759752654470503,
      "learning_rate": 3.2162111916713143e-07,
      "loss": 0.0001,
      "step": 52950
    },
    {
      "epoch": 2.9559397657557165,
      "grad_norm": 0.0003241908270865679,
      "learning_rate": 3.0303030303030305e-07,
      "loss": 0.0187,
      "step": 53000
    },
    {
      "epoch": 2.958728388176241,
      "grad_norm": 0.00029051624005660415,
      "learning_rate": 2.844394868934746e-07,
      "loss": 0.0037,
      "step": 53050
    },
    {
      "epoch": 2.961517010596765,
      "grad_norm": 0.00026741038891486824,
      "learning_rate": 2.6584867075664623e-07,
      "loss": 0.0,
      "step": 53100
    },
    {
      "epoch": 2.9643056330172897,
      "grad_norm": 0.00038449742714874446,
      "learning_rate": 2.472578546198178e-07,
      "loss": 0.0167,
      "step": 53150
    },
    {
      "epoch": 2.9670942554378135,
      "grad_norm": 0.0003559534379746765,
      "learning_rate": 2.286670384829894e-07,
      "loss": 0.0002,
      "step": 53200
    },
    {
      "epoch": 2.969882877858338,
      "grad_norm": 0.00024836810189299285,
      "learning_rate": 2.1007622234616102e-07,
      "loss": 0.0,
      "step": 53250
    },
    {
      "epoch": 2.9726715002788624,
      "grad_norm": 0.0009552609408274293,
      "learning_rate": 1.9148540620933259e-07,
      "loss": 0.0,
      "step": 53300
    },
    {
      "epoch": 2.9754601226993866,
      "grad_norm": 0.0003734176279976964,
      "learning_rate": 1.728945900725042e-07,
      "loss": 0.0,
      "step": 53350
    },
    {
      "epoch": 2.978248745119911,
      "grad_norm": 0.0002763625525403768,
      "learning_rate": 1.543037739356758e-07,
      "loss": 0.0,
      "step": 53400
    },
    {
      "epoch": 2.981037367540435,
      "grad_norm": 0.00029810884734615684,
      "learning_rate": 1.3571295779884738e-07,
      "loss": 0.0,
      "step": 53450
    },
    {
      "epoch": 2.9838259899609594,
      "grad_norm": 0.0002827595453709364,
      "learning_rate": 1.1712214166201897e-07,
      "loss": 0.0,
      "step": 53500
    },
    {
      "epoch": 2.9866146123814836,
      "grad_norm": 0.00023857460473664105,
      "learning_rate": 9.853132552519056e-08,
      "loss": 0.0,
      "step": 53550
    },
    {
      "epoch": 2.989403234802008,
      "grad_norm": 0.00024774763733148575,
      "learning_rate": 7.994050938836215e-08,
      "loss": 0.0,
      "step": 53600
    },
    {
      "epoch": 2.992191857222532,
      "grad_norm": 0.00035983044654130936,
      "learning_rate": 6.134969325153375e-08,
      "loss": 0.0001,
      "step": 53650
    },
    {
      "epoch": 2.9949804796430564,
      "grad_norm": 0.0003141739289276302,
      "learning_rate": 4.275887711470534e-08,
      "loss": 0.0,
      "step": 53700
    },
    {
      "epoch": 2.9977691020635806,
      "grad_norm": 0.0003637070767581463,
      "learning_rate": 2.416806097787693e-08,
      "loss": 0.0308,
      "step": 53750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.017218004912137985,
      "eval_runtime": 74.6989,
      "eval_samples_per_second": 480.047,
      "eval_steps_per_second": 60.014,
      "step": 53790
    }
  ],
  "logging_steps": 50,
  "max_steps": 53790,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 1,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.830410600258816e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
